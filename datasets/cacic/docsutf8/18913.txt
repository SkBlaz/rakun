Balanceo predictivo y distribuido del encaminamiento PR DRB
ï»¿ El desbalance en la carga de comunicaciones puede congestionar la 
red de interconexiÃ³n, incrementando la latencia y disminuyendo el throughput, 
degradando el rendimiento total del sistema paralelo. Las aplicaciones paralelas 
contienen etapas representativas durante su ejecuciÃ³n las cuales permiten 
caracterizarlas y obtener un patrÃ³n de comunicaciones. Este trabajo presenta el 
Balanceo Predictivo de Encaminamiento Distribuido (PR-DRB), un nuevo 
mÃ©todo desarrollado para controlar la congestiÃ³n en la red basado en la 
expansiÃ³n de caminos, la distribuciÃ³n de trÃ¡fico y carga efectiva, para mantener 
una latencia baja. PR-DRB monitorea la latencia de los mensajes en los 
encaminadores, elige los caminos alternativos a utilizar y registra la 
informaciÃ³n de la congestiÃ³n en base al patrÃ³n de comunicaciones detectado, 
para luego volver a aplicar la mejor soluciÃ³n cuando dicho patrÃ³n se repita. 
Experimentos de trÃ¡fico con congestiÃ³n fueron llevados a cabo para evaluar el 
rendimiento del mÃ©todo. 
 
Keywords: Redes de interconexiÃ³n, encaminamiento predictivo, 
encaminamiento adaptativo, latencia uniforme, aplicaciones paralelas, 
computaciÃ³n de alto desempeÃ±o. 
1 IntroducciÃ³n 
El comportamiento de aplicaciones cientÃ­ficas, que se ejecutan en paralelo sobre una 
red de interconexiÃ³n de alto rendimiento (HSIN), puede describirse como una 
colecciÃ³n de procesos asignados implÃ­citamente a cada procesador. El coste de las 
comunicaciones y su consumo energÃ©tico es  mayor respecto al de los procesadores y 
debe ser tratada por los mecanismos de control de congestiÃ³n [1]. Una distribuciÃ³n de 
carga inapropiada (HotSpot) genera puntos de saturaciÃ³n como si toda la red estÃ© 
colapsada. Para paliar esta situaciÃ³n se han desarrollado mecanismos de control de 
congestiÃ³n que mejoran el throughput utilizando una cantidad apropiada de recursos 
[1], como las tÃ©cnicas  de encaminamiento adaptativas que dinÃ¡micamente manejan 
los recursos a fin de reducir la congestiÃ³n. Este trabajo presenta el Balanceo 
Predictivo de Encaminamiento Distribuido (PR-DRB), una nueva estrategia de 
encaminamiento adaptativo basada en la utilizaciÃ³n de caminos alternativos ante la 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACIÃ“N                                                 112
Carlos NÃºÃ±ez1, Diego Lugones1, Daniel Franco2, Emilio Luque2 
presencia de congestiÃ³n a fin de mantener y mejorar  el ancho de banda disponible y 
reducir la latencia global para los patrones de comunicaciÃ³n repetitivos. Esta mejora 
se realiza a travÃ©s del uso de informaciÃ³n histÃ³rica sobre el patrÃ³n de comunicaciones 
que ocasionÃ³ la congestiÃ³n, y servirÃ¡ como base a toma de decisiones futuras.  
PR-DRB se basa en el DRB presentado en [2] pero mejora las prestaciones con el 
mÃ³dulo predictivo de monitorizaciÃ³n y registro. El modelo propuesto consta de tres 
fases: monitorizaciÃ³n, detecciÃ³n de la congestiÃ³n y patrÃ³n conflictivo, y el control de 
la congestiÃ³n. Este trabajo se basa en la repetitividad de etapas fundamentales en 
aplicaciones paralelas. En la fase de monitorizaciÃ³n se registra el valor de latencia de 
un mensaje y se guarda informaciÃ³n del patrÃ³n de trÃ¡fico que ocasionÃ³ la congestiÃ³n. 
Cuando el mensaje llega al nodo destino, se notifica al origen de la situaciÃ³n a travÃ©s 
de un mensaje de notificaciÃ³n (ACK), y el nodo origen es capaz de proceder a la 
apertura de caminos alternativos en base a la latencia. Si esta situaciÃ³n ya ha sido 
analizada previamente, se aplica la mejor soluciÃ³n aprendida y se actualiza su base de 
datos de histÃ³ricos apropiadamente. 
Cuando se detecta la congestiÃ³n, el algoritmo DRB va adaptÃ¡ndose a travÃ©s de la 
apertura de caminos alternativos, hasta que encuentra un valor de latencia global 
apropiado para todos los caminos abiertos, y en este proceso DRB invierte un tiempo 
considerable. Este trabajo propone almacenar la soluciÃ³n Ã³ptima encontrada y re 
aplicarla cuando se detecte una situaciÃ³n similar a la que originÃ³ la congestiÃ³n inicial. 
El artÃ­culo estÃ¡ organizado de la siguiente manera: La secciÃ³n 2 presenta los 
trabajos relacionados, la secciÃ³n 3 detalla la metodologÃ­a del PR-DRB. La 
experimentaciÃ³n se describe en la secciÃ³n 4, y resultados y trabajos futuros en la 
secciÃ³n 5. 
2 Trabajos Relacionados 
El control de congestiÃ³n se basa en la monitorizaciÃ³n, detecciÃ³n y el posterior control. 
Para evaluar la congestiÃ³n, generalmente son utilizados la latencia punto a punto [3], 
el nivel de ocupaciÃ³n de los buffers [4] o el â€œbackpressureâ€ [1], que una vez 
evaluados permiten a los nodos de cÃ³mputo disminuir y controlar la congestiÃ³n. 
Message Throttling [5] es una tÃ©cnica de correcciÃ³n que notifica al origen de la 
congestiÃ³n a fin de parar o disminuir la inyecciÃ³n de nuevos paquetes hasta mejorarse 
la situaciÃ³n. Esto controla la utilizaciÃ³n de los buffers, pero aumenta la latencia de los 
mensajes debido a la espera en el nodo origen hasta que se controle la congestiÃ³n. 
Otras tÃ©cnicas se basan en la administraciÃ³n de buffers, exclusivamente en los 
encaminadores [4], pero no consiguen un buen rendimiento ya que el nodo origen no 
es notificado. Existen tÃ©cnicas de control de congestiÃ³n basadas en algoritmos de 
encaminamiento adaptativo [2], [6], [7], que utilizan trayectorias alternativas para 
inyectar los mensajes. La distribuciÃ³n de trayectorias se realiza en forma dinÃ¡mica de 
acuerdo al estado actual de la red y pueden cambiar con el tiempo. Algunas 
desventajas serÃ­an la sobrecarga a la red debido a la monitorizaciÃ³n, garantizar la 
ausencia de interbloqueos y la entrega de mensajes en orden. Esta situaciÃ³n requiere 
una soluciÃ³n de compromiso entre la velocidad de monitorizaciÃ³n y la cantidad de 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACIÃ“N                                                 113
Balanceo Predictivo y Distribuido del Encaminamiento (PR-DRB)   
informaciÃ³n a analizarse. Por consiguiente, un algoritmo de encaminamiento eficiente 
debe ser capaz de obtener el mejor comportamiento ante una situaciÃ³n adversa, a fin 
de evitar introducir penalizaciones en las comunicaciones. 
Estudios del patrÃ³n de comunicaciones de las aplicaciones paralelas de HPC que 
son ejecutadas en las HSIN, demuestran que la mayorÃ­a poseen un comportamiento 
repetitivo y estÃ¡ enmarcado por cÃ³mputo y comunicaciones [8].  
En las HSIN, el desempeÃ±o del encaminamiento depende en gran medida del 
patrÃ³n de comunicaciones utilizado y de la relaciÃ³n con el mapeo de nodos a 
procesadores de una aplicaciÃ³n. Esto obliga al uso apropiado de recursos en redes 
HPC donde el costo global de los componentes es prohibitivo [9]. Algunas estrategias 
de encaminamiento utilizan informaciÃ³n de las aplicaciones como ser la tasa de 
transferencia para determinar mejores rutas que minimicen la latencia, nÃºmero de 
flujos por enlace, ancho de banda, deadlocks, etc., pero de manera estÃ¡tica [10]. 
Para mejorar el rendimiento de las comunicaciones, y aplicaciones, debe hallarse 
una tÃ©cnica que combine las soluciones de los algoritmos adaptativos y el patrÃ³n de 
comunicaciones utilizado, a fin de que el encaminamiento y control de congestiÃ³n 
apliquen rÃ¡pidamente las soluciones guardadas minimizando la monitorizaciÃ³n 
3 PR-DRB. Predecir el comportamiento del trÃ¡fico. 
PR-DRB busca mejorar el tiempo de respuesta del algoritmo DRB utilizando 
informaciÃ³n histÃ³rica de las comunicaciones. PR-DRB usa el concepto de MetaCaminos como alternativas a las trayectorias iniciales para enviar mensajes. La 
configuraciÃ³n de los Meta-Caminos define como se crean los caminos alternativos y 
cuÃ¡les de todos ellos son elegidos ante una situaciÃ³n de congestiÃ³n. Las fases del PRDRB se muestran en la siguiente figura: Fig. 1 (a). DetecciÃ³n y registro del valor de 
latencia y del patrÃ³n de comunicaciones que ocasionÃ³ la congestiÃ³n. Fig. 1 (b), 
muestra la ConfiguraciÃ³n de Meta-Caminos y la Fig. 1 (c) muestra caminos 
alternativos que forman el Camino Multi-Paso (MSP).  
La fase de monitorizaciÃ³n conlleva la medida del valor de latencia de un mensaje 
hasta su destino final. La congestiÃ³n se detecta en los encaminadores intermedios al 
superar un umbral de latencia mÃ¡ximo, se registra la latencia, el patrÃ³n de 
comunicaciones conflictivo, y el origen/destino involucrados. En el nodo destino, se 
envÃ­a un ACK al origen con la informaciÃ³n registrada a lo largo del trayecto.  
La cantidad de caminos alternativos a usar viene dada por el valor de latencia 
registrada, a efectos de distribuir todos los mensajes por estos caminos.  
PR-DRB a travÃ©s de su fase de ConfiguraciÃ³n de Meta-Caminos usa un esquema 
de tres pasos, llamado MSP, para encontrar el camino hacia el destino, partiendo del 
origen hacia un nodo intermedio 1, del nodo intermedio 1 al nodo intermedio 2, y 
desde Ã©ste Ãºltimo hacia el destino. Luego se actualiza la informaciÃ³n histÃ³rica con los 
nuevos valores de latencia y de caminos alternativos abiertos para este caso. AsÃ­ se 
logra que se registren los mejores caminos para cada par origen-destino especÃ­fico, 
bajo una congestiÃ³n dada, y que mÃ¡s adelante puedan ser aplicadas directamente 
acelerando y simplificando el proceso de ConfiguraciÃ³n de Meta-Caminos. 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACIÃ“N                                                 114
Carlos NÃºÃ±ez1, Diego Lugones1, Daniel Franco2, Emilio Luque2 
En la fase de SelecciÃ³n de Caminos Multi-Paso el nodo origen inyecta los 
mensajes en base al MSP calculado en la fase de ConfiguraciÃ³n de Meta-Caminos. 
Fig. 1. Fases del Algoritmo PR-DRB. 
3.1 Fase de MonitorizaciÃ³n y NotificaciÃ³n de la CongestiÃ³n 
Cada encaminador en la red es el encargado de la monitorizaciÃ³n del trÃ¡fico que lo 
atraviesa. AdemÃ¡s, el encaminador registra la informaciÃ³n que mÃ¡s adelante el nodo 
destino enviarÃ¡ en un ACK al origen. La Tabla 1 resume la monitorizaciÃ³n. 
Tabla 1. Fase de MonitorizaciÃ³n y NotificaciÃ³n. 
MonitorizaciÃ³n de Mensajes (Mensaje M, Umbral, MSP) 
/* En cada encaminador PR-DRB */ 
Begin 
Por cada mensaje M en cada salto, 
1. If (Primer Encaminador en el trayecto)  
âˆ’ Predictivo = FALSE; 
2. Acumular Latencia (tiempo de espera en la cola) 
If (Latencia > Umbral) AND NOT (Predictivo)  
âˆ’ Identificar flujos que intervienen en la congestiÃ³n 
âˆ’ Registrar patrÃ³n de comunicaciones de la congestiÃ³n (origen/destino). 
âˆ’ Predictivo = TRUE. 
3. Registrar en el mensaje la latencia acumulada en el enrutador actual. 
4. Re enviar mensaje M hacia el siguiente encaminador intermedio o el nodo destino. 
5. En el destino, la latencia y el patrÃ³n registrados es enviado al origen. 
End MonitorizaciÃ³n y NotificaciÃ³n 
 
La latencia de contenciÃ³n es el tiempo que un mensaje debe esperar en los buffers 
del encaminador antes de continuar hacia su destino, debido al bloqueo sometido por 
otros mensajes que tambiÃ©n ocupan el buffer. Esta latencia es incrementada en todos 
los encaminadores por donde atraviese el mensaje. Ante una contenciÃ³n, el 
encaminador guarda la informaciÃ³n de los nodos origen/destino que estÃ©n ocupando el 
mismo buffer, para determinar flujos que colisionan. El registro del patrÃ³n de 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACIÃ“N                                                 115
Balanceo Predictivo y Distribuido del Encaminamiento (PR-DRB)   
comunicaciones solo en el primer encaminador se debe a que la apertura de nuevos 
caminos alternativos ya disminuirÃ¡ la congestiÃ³n para el flujo analizado.  
Una vez en el destino se procede a enviar un ACK al origen, asÃ­ nuevos mensajes 
inyectados para el mismo destino puedan ser enviados por caminos alternativos. Un 
ACK tiene mayor prioridad en el encaminamiento, y su tamaÃ±o podrÃ­a considerarse 
despreciable, ya que solo transfiere informaciÃ³n de latencia y de flujos que 
colisionaron durante una contenciÃ³n. El registro y notificaciÃ³n se lleva a cabo en cada 
encaminador independientemente con informaciÃ³n local, incluyendo a otros mensajes 
actualmente en los buffers, lo que contribuye a un conocimiento global de la red.  
3.2 ConfiguraciÃ³n de los Meta-Caminos 
 
La configuraciÃ³n dinÃ¡mica de los meta caminos se basa en la informaciÃ³n registrada 
durante la monitorizaciÃ³n. El objetivo principal de esta fase es la de determinar, para 
cada para origen/destino, una cantidad apropiada de caminos alternativos en base al  
valor de latencia global registrada durante todo el trayecto. En la creaciÃ³n de caminos 
alternativos se seleccionan nodos intermedios (INs) disjuntos al camino original, y se 
tienen en cuenta nuevos valores de latencia registrados. La congestiÃ³n es controlada 
ampliando el ancho de banda a travÃ©s de apertura de caminos alternativos. La Tabla 2 
resume la ConfiguraciÃ³n de Meta-Caminos. La Fig. 2. da una visiÃ³n general del 
esquema de trabajo del PR-DRB. Durante la etapa 1 de la aplicaciÃ³n paralela, se  
Fig. 2. Procesos del PR-DRB 
observa que PR-DRB tiene una latencia elevada. Esto se debe a que el algoritmo estÃ¡ 
abriendo trayectorias alternativas para mantener el valor de las latencias controlada. 
Una vez que la cantidad de caminos alternativos para un par fuente/destino se ha 
estabilizado, entonces el algoritmo predictivo procede a guardar la mejor soluciÃ³n. En 
la etapa 2 esta soluciÃ³n se utilizarÃ¡ directamente al identificar una situaciÃ³n de 
congestiÃ³n similar a la ya encontrada en la etapa 1. Se observa que en las posteriores 
etapas de la aplicaciÃ³n, la latencia no llega a los picos registrados en la primera, esto 
se debe a que PR-DRB ha inyectado los mensajes a travÃ©s de los mejores caminos, 
evitando de esta manera congestiÃ³n en trayectorias no Ã³ptimas. AsÃ­ mismo cabe 
destacar que la zona de trabajo de PR-DRB a lo largo de toda la ejecuciÃ³n estÃ¡ 
enmarcada en el Ã¡rea de latencias estables. 
Tiempo (s)
Co
m
po
rta
m
ie
n
to
 
de
 
la
 
La
te
n
ci
a
TrÃ¡fico TrÃ¡fico TrÃ¡fico
 Etapa 1 Etapa nEtapa 2
(3)(1)
(2)
PR-DRB
TrÃ¡fico
(1) y (3) CongestiÃ³n Detectada
(2) y (4) EstabilizaciÃ³n de Latencias
(5)
Valor de latencia estable.
(4)
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACIÃ“N                                                 116
Carlos NÃºÃ±ez1, Diego Lugones1, Daniel Franco2, Emilio Luque2 
Tabla 2. FunciÃ³n de ConfiguraciÃ³n de Meta-Caminos 
ConfiguraciÃ³n de Meta-Caminos. 
/* Ejecutado en el nodo origen  cada vez que un mensaje ACK es recibido */ 
Begin 
âˆ’ Recibir el ACK con la Latencia del MSP y flujos involucrados en la congestiÃ³n. 
âˆ’ Calcular la latencia de los Meta-Caminos. 
 	
 âˆ—
 =   	

 
âˆ’ If ( 	
 âˆ—
 > 
  
If (Ya existe soluciÃ³n guardada para el MSP para el par origen/destino)  
âˆ’ Buscar en la Base de Datos el mejor MSP registrado. 
Else  
âˆ’ Incrementar nÃºmero de INs para proveer nuevos caminos alternativos. 
End If 
Else If  (Latencia (Mp*) < Umbral)  
âˆ’ Decrementar el nÃºmero de INs para disminuir el Meta-Camino. 
âˆ’ Guardar Latencia del (MP *) y los nodos origen/destino involucrados.  
   End If  
End  ConfiguraciÃ³n de Meta-Caminos. 
3.3 Fase de SelecciÃ³n de los Caminos Multi-Paso 
Al momento de la inyecciÃ³n de un nuevo mensaje, se tiene en cuenta el valor de 
latencia acumulada para determinar quÃ© camino alternativo utilizar en cada instante de 
tiempo, logrando de esta manera distribuir apropiadamente la carga de 
comunicaciones no solamente con la ampliaciÃ³n del ancho de banda efectivo sino que 
tambiÃ©n se utilizan con mayor frecuencia los mejores caminos. La expansiÃ³n de 
caminos es llevada a cabo en forma gradual, pudiendo tomar un tiempo para lograr 
encontrar el valor apropiado de caminos a utilizar y la distribuciÃ³n de carga para cada 
uno de ellos. Dado un nodo origen con N caminos alternativos, definimos Lci (i: 
1...N) como la latencia registrada para el camino Ci. El camino alternativo Cx serÃ¡ 
seleccionado para la prÃ³xima inyecciÃ³n en base a la probabilidad: 
	
 =  1  !â„#âˆ‘ 1  %â„&%' (
      	). 1
 
Encontrar la mejor combinaciÃ³n de cantidad de caminos/ancho de banda  puede 
llevar un tiempo considerable, y las aperturas intermedias hasta la Ã³ptima tambiÃ©n 
introducirÃ¡n una contenciÃ³n en los encaminadores y el posterior incremento de 
latencia. PR-DRB va guardando la informaciÃ³n de las aperturas y actualizando su 
base de datos de mejores caminos abiertos y el porcentaje de utilizaciÃ³n de cada uno 
de ellos como un atributo al par origen/destino, a efectos de volver a aplicarlos 
directamente cuando se detecte la congestiÃ³n, y asÃ­ evitar extender los picos de 
latencia al buscar la mejor soluciÃ³n posible.  La Tabla 3 resume la fase de SelecciÃ³n 
de Caminos Multi-Paso. 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACIÃ“N                                                 117
Balanceo Predictivo y Distribuido del Encaminamiento (PR-DRB)   
Tabla 3. Fase de SelecciÃ³n de Caminos Multi-Paso. 
SelecciÃ³n de Caminos Multi-Paso 
/* Ejecutado en el nodo origen  antes de inyectar un nuevo mensaje */ 
Begin 
âˆ’ Construir la funciÃ³n de distribuciÃ³n acumulativa y normalizaciÃ³n de ancho de banda 
de los MSP. 
âˆ’ Seleccionar un MSP utilizando la funciÃ³n de distribuciÃ³n acumulativa. 
âˆ’ Inyectar el mensaje en la red 
âˆ’ Armar encabezados  con informaciÃ³n de destinos intermedios y final. 
âˆ’ Concatenar los encabezados. 
âˆ’ Inyectar el mensaje con el formato PR-DRB. 
End  SelecciÃ³n de Caminos Multi-Paso. 
3.4 IntegraciÃ³n de todas las fases. 
  El esquema general de funcionamiento de PR-DRB se muestra en la Fig. 3. Cuando 
se genera por primera vez desde el origen un mensaje para un origen/destino 
especÃ­fico, este se inyecta directamente a la red, debido a que aÃºn no se tienen 
estadÃ­sticas sobre la situaciÃ³n de la red. A partir de este punto el mensaje va hacia su 
destino atravesando mÃºltiples encaminadores intermedios, donde se evalÃºa el valor de 
la latencia sufrida en cada encaminador y se determina si supera un umbral mÃ¡ximo a 
efectos de analizar el patrÃ³n de trÃ¡fico que estÃ¡ ocasionando dicha congestiÃ³n, y de 
esta manera guardar informaciÃ³n que lo identifique. En el nodo destino, se procede a 
enviar  al nodo fuente la informaciÃ³n registrada a travÃ©s de la inyecciÃ³n de un paquete 
especial de notificaciÃ³n (ACK), el cual contiene la latencia acumulada en todos los 
encaminadores por donde atravesÃ³ el mensaje asÃ­ como la informaciÃ³n del patrÃ³n de 
comunicaciones que causÃ³ la congestiÃ³n. Cuando el mensaje arriba al nodo origen, la 
fase de configuraciÃ³n de Meta-Caminos se lleva a cabo y se guardan los valores de 
latencia asÃ­ como del flujo que ocasionÃ³ la congestiÃ³n, junto con el par origen/destino 
del mensaje. Con esta informaciÃ³n actualizada, la fase de configuraciÃ³n de MetaCaminos puede analizar la apertura o cierre de nuevos caminos alternativos en caso 
que la latencia global de la red aÃºn no estÃ© en una situaciÃ³n estable. Cuando se 
requiera inyectar un nuevo mensaje en la red, la fase de SelecciÃ³n de Caminos MultiPaso toma el control  y procede a seleccionar una de las trayectorias alternativas 
disponibles. Como las aplicaciones paralelas presentan repetitividad en las fases de su 
ejecuciÃ³n, los patrones de comunicaciÃ³n tienden a repetirse en el tiempo. Para este 
caso concreto, la fase de ConfiguraciÃ³n de Meta-Caminos puede simplificarse a la 
tarea de buscar el mejor camino registrado durante la primera etapa de la ejecuciÃ³n de 
la aplicaciÃ³n paralela, con lo cual se aplica directamente la mejor soluciÃ³n encontrada 
y se ahorra considerablemente en tiempo de cÃ¡lculo y comunicaciones. Aplicaciones 
que requieran mantener el orden de los paquetes pueden usar el algoritmo de ventanas 
deslizantes, como es utilizado en [6]. 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACIÃ“N                                                 118
Carlos NÃºÃ±ez1, Diego Lugones1, Daniel Franco2, Emilio Luque2
4 
Se ha
sido comparado
que se puede obtener 
aplicar las polÃ­ticas predictivas
dicha mejora
comportamiento transitorio y 
Esta configuraciÃ³n establece 
saturadas
iniciales
herramienta de simulaciÃ³n y modelado OPNET modeler 
Toro 2D
bytes y 
4.1
Fig. 
la propuesta PR
mapa de latencias, donde cada punto (x
La 
latencias
encaminadores
trayectorias
PR
TambiÃ©n puede observarse que la distribuciÃ³n de carga es mejor que en el caso d
DRB, debido 
 
ExperimentaciÃ³n.
 
El 
Simulaciones fueron llevadas a cabo en una red de 64 nodos 
 
4
Fig. 
-DRB, 
analiza
trÃ¡fico 
 
.
 ancho de banda de los enlaces a 2 Gbps.
AnÃ¡lisis de HotSpot.
 (a) y (b)
4
 
. Se
encontrados 
 El control de flujo fue el Virtual Cut
 (a)
en la zona congestionada
 
donde se
do
, y 
es a rÃ¡fagas
 inyecta trÃ¡fico en otras Ã¡reas a efectos de que
 muestran  la superficie de latencias de la red, para el algoritmo DRB y 
 corresponde al 
 
como 
a que PR
 el comportamiento 
 satisfactoriamente
se presenta el mapa de latencia
-DRB.
(x,y)
caminos
Fig.
con
 0
 puede apreciar que el pico de latencia es inferior al del DRB.
 3
 
no sean Ã³ptimos.
 Se muestra la latencia de contenciÃ³n promedio a travÃ©s del 
,1, 
-DRB ha aplicado directamente las mejores soluciones y 
 Algoritmo PR
 
el mÃ³
 
D
6,2 y 6,4
 alternativ
dulo predictivo.
, asÃ­ como 
 y 
distribuciÃ³n de trÃ¡fico en situaciones extrema
nodos especÃ­ficos como destino a fin de conseguir Ã¡reas 
RB
 con otros de la literatura,
con
, donde se observa 
 
de PR
 
 
son
os
el
situaciones de 
 El 
,y) representa 
y 
 elevadas
. En la 
DRB con todas las fases integradas
DRB 
 throughput
modelo
que 
frente al DRB original
 Se analiza c
s. 
-through
 
la distribuciÃ³n de carga entre los 
Fig. 
 
 debido a que el DRB utiliza estas 
fue implementado
la latencia de 
un pico en 
4 (b)
 
 que no se ve perjudicado
H
[11
, tamaÃ±o de paquete 
 se observa
 para
Ã³mo 
otS
 los caminos alternativos
].  
 verificar la ganancia 
la
pot
el comportamiento de 
 latencia
, para
con
un encaminador
 [
 
 una topologÃ­a 
 el resultado 
2], 
 evaluar el 
s
utilizando la 
que 
 mejora
 de carga. 
de 1024 
 
ya
 
evitÃ³
 ha 
 al 
por
.
del
e 
 
 
 
 
 
 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACIÃ“N                                                 119
Balanceo Predictivo y Distribuido del Encaminamiento (PR-DRB)   
sobrecargar encaminadores hasta encontrar la soluciÃ³n. En la Fig. 5(a) se muestra la 
latencia durante los primeros instantes de la ejecuciÃ³n a efectos de analizar las 
consecuencias de la inyecciÃ³n de trÃ¡fico y reacciÃ³n de los algoritmos. En promedio el 
algoritmo PR-DRB tiene mejor desempeÃ±o, ya que llega a mejores valores de latencia 
global y en menor tiempo hasta estabilizarse, y las mejoras en la latencia no han 
introducido ninguna penalizaciÃ³n en el throughput. La latencia a lo largo de toda la 
simulaciÃ³n puede observarse en la Fig. 5 (b). El algoritmo DRB sufre un incremento 
al inicio, debido a las aperturas de trayectorias alternativas hasta el instante de tiempo 
0.5, donde prÃ¡cticamente los valores convergen. PR-DRB por el contrario exhibe un 
comportamiento mejor en su etapa inicial ya que ha evitado las trayectorias 
innecesarias y ha aplicado las mejores soluciones encontradas cuando vuelve a 
repetirse el patrÃ³n conflictivo, con lo que el valor promedio de ganancia de latencia 
puede reflejarse entre el tiempo 0 y 0.5. A partir de este instante, ambos valores de 
latencia tienden a estabilizarse y converger. 
(a) (b) 
Fig. 4. Mapa de Latencias 
(a) 
 (b) 
Fig. 5. Latencia de toda la red, instantÃ¡nea (a) y promedio (b) 
5 Conclusiones y Trabajos Futuros 
Este trabajo ha propuesto el Balanceo Predictivo y Distribuido del Encaminamiento 
PR-DRB, para las HSIN. Esta estrategia pretende utilizar caminos alternativos ante la 
presencia de congestiÃ³n, para mejorar valores de latencias y disponibilidad de ancho de 
banda, en el menor tiempo posible y dinÃ¡micamente. Las aplicaciones paralelas 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACIÃ“N                                                 120
Carlos NÃºÃ±ez1, Diego Lugones1, Daniel Franco2, Emilio Luque2 
presentan un comportamiento repetitivo, y PR-DRB es capaz de aprender y re aplicar 
las mejores soluciones encontradas cuando se detecte el mismo patrÃ³n. PR-DRB ha 
sido diseÃ±ado con HSIN para clusters en mente, donde la latencia debe ser uniforme 
bajo cualquier carga de trÃ¡fico. Experimentos muestran que la propuesta aumenta la 
ganancia de latencia, sin afectar el throughput. Como continuaciÃ³n de este trabajo se 
pretende predecir y evitar una futura congestiÃ³n analizando la tendencia de latencias y 
re aplicando las soluciones guardadas. TambiÃ©n se propone caracterizar y obtener 
patrones de aplicaciones paralelas para hacer al PR-DRB application aware.  
6
