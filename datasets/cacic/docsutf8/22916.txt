CÃ³mputo paralelo interclusters Herramientas y evaluaciÃ³n de rendimiento
ï»¿ 
Se presenta en este artÃ­culo la experiencia desarrollada referente a la utilizaciÃ³n de mÃºltiples clusters para 
cÃ³mputo paralelo. Inicialmente, se presentan algunas consideraciones importantes en cuanto la instalaciÃ³n y 
configuraciÃ³n del middleware o software de soporte necesario para realizar cÃ³mputo paralelo en este tipo de 
arquitectura que es relativamente nueva. Una de las premisas que se tiene en cuenta en este contexto es la de 
utilizar software herramientas relativamente estÃ¡ndar y estable. Una vez que se establece la configuraciÃ³n 
bÃ¡sica para ejecutar programas paralelos interclusters (en mÃ¡s de un cluster), se presentan los resultados 
obtenidos en lo referente a la caracterizaciÃ³n de las transferencias de datos entre los clusters intervinientes. 
El rendimiento de las comunicaciones interclusters puede ser considerado como una de las caracterÃ­sticas 
propias de este tipo de plataformas de cÃ³mputo paraelo y, por lo tanto, es importante tener una metodologÃ­a 
y/o herramienta de caracterizaciÃ³n de las mismas. Finalmente, se presentan algunos resultados interesantes 
de paralelizaciÃ³n de dos aplicaciones sencillas a ejecutarse en computadoras de diferentes clusters. Esta 
paralelizaciÃ³n muestra, por un lado, ejemplos especÃ­ficos reales de ejecuciÃ³n programas paralelos 
intercluster y por otro lado, la aplicaciÃ³n de algunas ideas preexistentes de balance de carga que son 
aplicables tambiÃ©n en este contexto.  
Palabras claves: ComunicaciÃ³n de Procesos, CaracterizaciÃ³n de Rendimiento, Sistemas Paralelos y 
Distribuidos, Paralelismo en Clusters e Interclusters.   
Abstract
This paper presents the experience developed using multiple clusters for parallel computing. Initially, some 
relevant considerations are presented in terms installation and configuration of middleware or supporting 
software necessary to carry out parallel computing over this relatively new type of architecture. One of the 
premises taken into account within this context is that of using relatively standard and stable software and 
tools. Once the basic configuration is established to run interclusters (on more than one cluster) parallel 
programs, the obtained results regarding the characterization of data transferences among clusters are 
presented. Interclusters communication performance can be considered as one of the typical characteristics 
of this type of parallel computing platforms and, thus, it is important to count with a characterization 
methodology and/or tool of them. Finally, some interesting results of parallelizing two simple applications 
run in machines of different clusters are presented. On the one hand, this parallelization shows actual and 
specific results of running interclusters parallel programs and, on the other, the application of some preexisting ideas of load balance, which are also applicable within this context. 
Keywords: Process Communication, Performance Characterization, Parallel and Distributed Systems, 
Parallelism in Clusters and Interclusters.  
â€  Investigador Principal CONICET. Profesor Titular D.E. Facultad de InformÃ¡tica UNLP 
â€¡ Investigador Asistente CICPBA 
XIII Congreso Argentino de Ciencias de la ComputaciÃ³n
Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯
 
VIII Workshop de Procesamiento Distribuido y Paralelo
_________________________________________________________________________
 
 
1169
1 INTRODUCCION
La utilizaciÃ³n de clusters para cÃ³mputo paralelo estÃ¡ bien establecida desde hace varios aÃ±os [3] y 
actualmente existe una gran cantidad de clusters instalados que estÃ¡n siendo utilizados con software 
paralelo en producciÃ³n. El modelo de programaciÃ³n de pasaje de mensajes tambiÃ©n ha madurado en 
definiciones tales como las de PVM (Parallel Virtual Machine) [5] y MPI (Message Passing 
Interface) [14]. La biblioteca MPI se convirtiÃ³ rÃ¡pidamente en uno de los  estÃ¡ndares mÃ¡s 
importantes para el desarrollo y la ejecuciÃ³n de programas paralelos. Esta biblioteca rÃ¡pidamente se 
ha implementado en los sistemas de cÃ³mputo paralelo mÃ¡s distribuidos o desacoplados como lo son 
los clusters. De hecho, desde hace varios aÃ±os existen al menos dos implementaciones de uso libre: 
MPICH [11] y LAM/MPI [4].
Aunque se puede asociar pasaje de mensajes y PVM y MPI en particular con hardware de cÃ³mputo 
distribuido o MIMD (Multiple Instruction Stream, Multiple Data Stream), PVM y MPI no imponen
o presuponen ninguna caracterÃ­stica sobre/de el hardware. Esto permite una gran independencia y 
portabilidad de los programas paralelos, incluyendo variantes como las de clusters de SMP 
(Symmetric MultiProcessing) y computadoras paralelas de memoria compartida [15]. En general, 
las bibliotecas de pasaje de mensajes resuelven bÃ¡sicamente dos problemas tÃ©cnicos de manera 
satisfactoria para ser utilizadas: 
1. IdentificaciÃ³n Ãºnica de procesos. Los programas paralelos no son mucho mÃ¡s que un conjunto 
de procesos que se pueden identificar de manera unÃ­voca, independientemente de que se 
ejecuten en un ambiente de memoria compartida o memoria distribuida, por ejemplo.  
2. Transferencia de datos entre los procesos. Si bien se reconoce que las primitivas bÃ¡sica de 
comunicaciÃ³n son del tipo send() y receive() punto a punto entre dos procesos, tambiÃ©n se 
suelen incluir otras variantes como las comunicaciones colectivas del tipo de broadcast(), por 
ejemplo, o variantes semÃ¡nticas de las comunicaciones punto a punto (haciendo alusiÃ³n 
explÃ­cita a buffers de memoria, por ejemplo). 
De hecho, en cualquier plataforma de cÃ³mputo donde se pueden resolver estos problemas, se podrÃ­a 
utilizar una implementaciÃ³n de MPI, por ejemplo. Evidentemente los clusters han sido apropiados 
desde la perspectiva de las implementaciones de bibliotecas de pasaje de mensajes para cÃ³mputo 
paralelo, y estos dos problemas se resuelven de manera relativamente sencilla. Todo lo relacionado 
con transferencias de comunicaciones se ha resuelto utilizando protocolos estÃ¡ndares como TCP/IP 
y no es necesario un gran esfuerzo para asignar y mantener una identificaciÃ³n de procesos para 
bibliotecas como la mÃ¡s utilizada actualmente de MPI 1.1, donde no hay creaciÃ³n dinÃ¡mica de 
procesos. De hecho, PVM tambiÃ©n incluye la creaciÃ³n dinÃ¡mica de procesos y tampoco en este caso 
es un gran problema mantener actualizada la asociaciÃ³n proceso-identificador en un ambiente 
distribuido. Evidentemente no es un problema en un ambiente centralizado (como la de un SMP), 
donde hay un Ãºnico sistema operativo y, de hecho, cualquier sistema operativo tiene identificaciÃ³n 
Ãºnica de procesos ademÃ¡s de muchos otros datos de informaciÃ³n de estado del sistema. 
La propuesta en este artÃ­culo es la de plantear la soluciÃ³n al problema planteado por la ejecuciÃ³n de 
un programa paralelo en mÃ¡s de un cluster o, lo que es igual: la utilizaciÃ³n de mÃ¡s de un cluster para 
ejecutar un programa paralelo, que se considerarÃ¡ sinÃ³nimo de â€œcÃ³mputo paralelo interclustersâ€. De 
una manera o de otra, hay varias alternativas de soluciÃ³n a este problema, algunas de ellas 
disponibles desde hace bastante tiempo. De hecho, se podrÃ­a resolver inicialmente con las mismas 
bibliotecas PVM o implementaciones de MPI si no fuera por los controles de seguridad que se 
imponen actualmente al trÃ¡fico sobre Internet de la mayorÃ­a (si no todas) de las instituciones que 
tienen clusters disponibles para cÃ³mputo paralelo. De hecho, la propuesta avanza un poco mÃ¡s en el 
sentido de no solamente utilizar mÃ¡s de un cluster para un programa paralelo sino de hacerlo con el 
mÃ­nimo costo de instalaciÃ³n y mantenimiento de software y, ademÃ¡s, con lo que se supone la menor 
XIII Congreso Argentino de Ciencias de la ComputaciÃ³n
Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯
 
VIII Workshop de Procesamiento Distribuido y Paralelo
_________________________________________________________________________
 
 
1170
sobrecarga (overhead) de cÃ³mputo y comunicaciones  posible. Justamente desde esta perspectiva se 
analizarÃ¡n las propuestas existentes (al menos las mÃ¡s importantes o consideradas suficientemente 
representativas) en la siguiente secciÃ³n.
Una vez resuelto el problema bÃ¡sico de cÃ³mputo paralelo interclusters (con la utilizaciÃ³n de mÃ¡s de 
un cluster) comienza, en realidad, un problema mayor desde la perspectiva de paralelizaciÃ³n de 
aplicaciones y la optimizaciÃ³n de rendimiento. En un ambiente de cÃ³mputo paralelo interclusters no 
se puede asumir que todas las comunicaciones punto a punto tienen el mismo rendimiento, por 
ejemplo. Desde la perspectiva de un proceso que envÃ­a, algunos receptores son locales (en la misma 
red local, el mismo cluster) y otros no, estÃ¡n en otro cluster, al que se llega, en el caso mÃ¡s usual,
por ruteo IP (normalmente). En cualquier caso, el rendimiento de las comunicaciones (el tiempo 
necesario para efectuar una transferencia de datos) no serÃ¡ el mismo. Otra de las caracterÃ­sticas 
inherentes del cÃ³mputo paralelo interclusters es la de heterogeneidad de las computadoras a utilizar. 
Si bien en un cluster normalmente todas las computadoras son iguales (y, en particular, con la 
misma potencia de cÃ¡lculo), es muy poco probable que las computadoras de dos o mÃ¡s clusters sean 
exactamente iguales entre sÃ­. Y esto afecta directamente el balance de carga para que el cÃ³mputo 
sea equilibrado en cuanto al tiempo necesario en cada una de las computadoras que se utilizan. Los 
problemas planteados en cuanto a rendimiento de comunicaciones y balance de carga 
computacional (y tiempo de cÃ³mputo asociado) serÃ¡n analizados en otra secciÃ³n de este mismo 
artÃ­culo.
2 TRABAJOS PREVIOS RELACIONADOS
Aunque la terminologÃ­a varÃ­a bastante, dado que no ha sido estandarizada, entre los primeros 
esfuerzos de utilizar computadoras en mÃ¡s de un cluster se puede encontrar la idea de â€œclusters 
geogrÃ¡ficamente distribuidosâ€. Entre los primeros esfuerzos se pueden encontrar herramientas o 
bibliotecas tales como MagPIe del proyecto Albatros [24]. La biblioteca MagPIe fue orientada 
directamente a la optimizaciÃ³n de las funciones de comunicaciones colectivas de MPI en redes de 
Ã¡rea extensa o extendida (WAN: Wide Area Network) [13] [12]. En algunos otros casos, se pueden 
encontrar los esfuerzos por hacer diferentes versiones de MPI interoperables, asumiendo que se 
tienen varios clusters, cada uno con su implementaciÃ³n propia (o propietaria o especÃ­ficamente 
orientada a un tipo de mÃ¡quina paralela o cluster). Entre estas iniciativas se pueden mencionar MPIConnect [7] con su precedente PVMPI [6] y tambiÃ©n IMPI [10], que se propuso con mayor 
generalidad para la interoperabilidad, con la definiciÃ³n de un protocolo apropiado. 
La gran mayorÃ­a de las propuestas son de finales de la dÃ©cada de 1990, mayormente entre los aÃ±os 
1995 y 2000. QuizÃ¡s por esta razÃ³n, de alguna manera o de otra estas propuestas han sido 
absorbidas o incluidas es lo que hoy se conoce como en Grid Computing [9]. Por ejemplo, el 
proyecto Albatross se asocia directamente con DAS [24] y el sitio web de DAS indica que ha sido 
sucedido por DAS-2 y DAS-3 [DAS-3], donde este Ãºltimo (DAS-3) se define como la 
infraestructura de Grid Computing en Holanda. Sin embargo, parece conveniente en ciertas 
aplicaciones mantener la propuesta de cÃ³mputo paralelo interclusters separado de Grid Computing 
por al menos dos razones: 
x Grid Computing estÃ¡ propuesto como una soluciÃ³n integral o completa para compartir recursos 
de cÃ³mputo y almacenamiento a gran escala de distribuciÃ³n y de capacidad. Obviamente esto 
incluye la utilizaciÃ³n de varios clusters, pero desde la perspectiva de compartir de manera 
controlada mÃºltiples recursos disponibles en mÃºltiples instituciones y/o instalaciones de 
cÃ³mputo. Esto incluye tambiÃ©n la idea de mantener un gran sistema distribuido mÃ¡s que un gran 
sistema paralelo (aunque el sistema distribuido pueda utilizarse para cÃ³mputo paralelo). 
x Grid Computing tiene mucho mÃ¡s que lo necesario para cÃ³mputo paralelo interclusters. Por 
XIII Congreso Argentino de Ciencias de la ComputaciÃ³n
Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯
 
VIII Workshop de Procesamiento Distribuido y Paralelo
_________________________________________________________________________
 
 
1171
ejemplo, se intenta proveer SSI (Single System Image) no solamente a nivel de Single Sign On
(o Ãºnico punto de identificaciÃ³n y conexiÃ³n) sino a nivel de proveer y obtener recursos para o 
de todo el sistema de Grid Computing. Esto implica, por ejemplo, un sistema muy elaborado y 
complejo para proveer adaptaciÃ³n a los diferentes sistemas de seguridad que se utilicen 
localmente en cada instalaciÃ³n/instituciÃ³n conectada a grid. 
La propuesta de este artÃ­culo consiste en mantener la posibilidad de utilizar computadoras de mÃ¡s 
de un cluster sin tener que instalar toda una infraestructura (o middleware) como la de Globus [8]. 
Un ejemplo sencillo puede ser la colaboraciÃ³n puntual de dos o mÃ¡s instituciones para resolver un 
problema especÃ­fico, donde esto no implique la definiciÃ³n e instalaciÃ³n de toda una infraestructura 
de software especÃ­fica para el desarrollo de la soluciÃ³n, ademÃ¡s de lo que realmente es necesario: 
desarrollar la soluciÃ³n. Cada una de las instituciones (o, mÃ¡s especÃ­ficamente, cada uno de los 
clusters a utilizar) no deberÃ­a ser mayormente afectado en cuanto a infraestructura de software para 
la colaboraciÃ³n en cuanto a cÃ³mputo paralelo. En cierta forma, puede considerarse que esto 
restringe o limita la escalabilidad de aplicaciones, pero sin lugar a dudas tambiÃ©n reduce la 
complejidad de instalaciÃ³n y mantenimiento de la infraestructura de software necesaria. En el otro 
extremo, se podrÃ­a mencionar la colaboraciÃ³n explÃ­citamente ad hoc como en [1], en el sentido de 
desarrollar no solamente la aplicaciÃ³n sino tambiÃ©n las comunicaciones y el control de la aplicaciÃ³n 
paralela. Aunque sin lugar a dudas esta es la forma con menor requerimiento de infraestructura de 
software a priori, tambiÃ©n involucra un alto costo de desarrollo extra sobre el programador. Las 
comunicaciones, por ejemplo, se deberÃ­an llevar a cabo usando mÃ©todos que son relativamente 
rudimentarios para cÃ³mputo paralelo como el desarrollo directo sobre la biblioteca de sockets BSD.
En este contexto, el objetivo es mantener un mÃ­nimo estable de desarrollo y ejecuciÃ³n de programas 
paralelos como el de MPI sin tener que recurrir a sus implementaciones para Grid Computing, por 
ejemplo, donde se requiere, ademÃ¡s, todo el soporte que corresponde, como el que provee 
especÃ­ficamente Globus.
Desde hace algÃºn tiempo, se han estudiado caracterÃ­sticas especÃ­ficas de cÃ³mputo paralelo 
interclusters tales como la del problema generado por las interconexiones no dedicadas y los 
problemas de seguridad involucrados [2] [18]. A modo de resumen, en estos trabajos previos se 
reportan algunos detalles tÃ©cnicos importantes a tener en cuenta para cÃ³mputo paralelo interclusters: 
x En los ambientes no dedicados, muchos de los problemas de disponibilidad de las 
computadoras de los clusters a utilizar son propios de la falta de control sobre los mismos, no 
de las comunicaciones o estabilidad de las computadoras.  
x Aunque la interconexiÃ³n de los clusters no es dedicada, siempre hay  conectividad entre los 
clusters a utilizar, salvo algunas excepciones relativamente muy poco frecuentes. Esto se debe 
bÃ¡sicamente a que la interconexiÃ³n estÃ¡ involucrada con el trÃ¡fico de Internet, que es mantenido 
y monitoreado independientemente de la utilizaciÃ³n de cÃ³mputo paralelo interclusters. 
x El rendimiento que se podrÃ­a considerar como raw (medido a partir de trÃ¡fico ICMP, por 
ejemplo) de las comunicaciones entre los clusters no es constante dado que no es dedicado, 
pero en general es muy cercano al mÃ¡ximo absoluto, al menos para transferencias de 
relativamente pocos datos (decenas de K Bytes, por ejemplo). Como es de esperar, el 
rendimiento para las comunicaciones interclusters fluctÃºa dependiendo de dÃ­as y horarios. 
x Los mecanismos bÃ¡sicos de seguridad que se imponen en las instituciones (y que son de uso 
comÃºn en casi todas las instalaciones de computadoras) normalmente impiden la utilizaciÃ³n 
directa de implementaciones de MPI como MPICH y LAM/MPI. Estas implementaciones 
imponen un patrÃ³n de trÃ¡fico TCP/IP que normalmente es cancelado por los firewalls y/o 
mecanismos de seguridad de las instituciones.  
XIII Congreso Argentino de Ciencias de la ComputaciÃ³n
Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯
 
VIII Workshop de Procesamiento Distribuido y Paralelo
_________________________________________________________________________
 
 
1172
3 UN SOPORTE SIMPLE PARA COMPUTO PARALELO INTERCLUSTERS
QuizÃ¡s el soporte mÃ¡s simple para el cÃ³mputo paralelo interclusters es el que proveen las propias 
implementaciones de MPI que, a priori, permiten la utilizaciÃ³n de mÃºltiples computadoras 
independientemente de su ubicaciÃ³n geogrÃ¡fica y/o en clusters. Esta posibilidad debe ser descartada 
de plano por los mÃºltiples problemas de seguridad y administraciÃ³n que involucra. Desde la 
perspectiva de seguridad, se deberÃ­an relajar los niveles de control, al menos desde la perspectiva 
de los firewalls que son de uso extendido en todas las instituciones. Como se reporta en [17], tanto 
el o los protocolos (TCP y/o UDP) como la cantidad y el tipo o clase (privilegiados o no) de puertos
a utilizar por las aplicaciones que utilizan implementaciones de MPI no es configurable. Esto 
llevarÃ­a a dejar sin protecciÃ³n o sin control el trÃ¡fico entre las computadoras involucradas de los 
diferentes clusters. AÃºn en el caso de considerar que eliminar el control de trÃ¡fico entre las 
mÃ¡quinas no es suficientemente peligroso, sÃ­ es un problema de administraciÃ³n. Al menos un 
administrador por instituciÃ³n debe encargarse de quitar estos controles para que las aplicaciones 
MPI puedan ser ejecutadas. Este problema se suele complicar debido a que normalmente los 
administradores de la seguridad no tienen relaciÃ³n directa con cÃ³mputo paralelo y que en las 
instituciones con control mÃ¡s distribuido se involucra a mÃ¡s de un administrador. Por lo tanto, 
mantener el uso directo de MPI no es sustentable desde el punto de vista tÃ©cnico por la seguridad ni 
operativo por la necesidad de recurrir a mÃºltiples administradores de las mÃºltiples instituciones 
involucradas.
La siguiente alternativa para ejecutar aplicaciones paralelas interclusters basadas en MPI podrÃ­a ser 
la utilizaciÃ³n de algunas de las herramientas enumeradas en la secciÃ³n anterior: MagPIE, MPIConnect, PVMPI, o IMPI. Algunas de las alternativas podrÃ­an considerarse con el costo agregado 
de instalaciÃ³n de la o las bibliotecas mÃ¡s la recompilaciÃ³n de los programas paralelos. Sin embargo, 
como se comentÃ³ en la secciÃ³n anterior, el problema mÃ¡s significativo es que la mayorÃ­a (sino 
todas) de estas herramientas simplemente se trasladaron al ambiente de Grid Computing. Esto 
significa que, como mÃ­nimo no tienen soporte ni actualizaciones para los clusters (o interclusters) 
actuales. De hecho, en el contexto de Grid Computing directamente existen implementaciones de 
MPI que evitarÃ­an el uso de otra biblioteca. Como tambiÃ©n se comenta en la secciÃ³n anterior, el 
objetivo es evitar la instalaciÃ³n de la infraestructura de una implementaciÃ³n para Grid Computing 
por el propio costo de la instalaciÃ³n y ademÃ¡s para evitar el costo en tiempo de ejecuciÃ³n para el 
acceso a recursos (CPU, memoria, etc.) vÃ­a Grid Computing. 
Tal como se adelanta en [18] a nivel preliminar, la idea es recurrir a la utilizaciÃ³n de una red 
privada virtual, o VPN (Virtual Private Network) como middleware asociado en cierta forma a la 
implementaciÃ³n de MPI que se utilice. Desde un punto de vista tÃ©cnico, todo lo que necesita MPI 
para ser utilizado en un cluster es que se tenga conectividad TCP/IP como en una red local. Esto es, 
justamente, lo que provee una VPN en cualquiera de sus versiones o implementaciones [25] [23]. 
Sin lugar a dudas, se tienen costos por la utilizaciÃ³n de una implementaciÃ³n de VPN para cÃ³mputo 
paralelo interclusters: 
x Se debe instalar y configurar el software de la implementaciÃ³n de VPN que se haya elegido. 
Normalmente no es muy complejo ni requiere muchos conocimientos previos. Casi todas las 
distribuciones de Linux tienen o incluyen alguna implementaciÃ³n. Este es el caso de OpenVPN, 
que es el que se utilizÃ³ para el trabajo de este artÃ­culo y cuya tarea de instalaciÃ³n y 
configuraciÃ³n se reporta en [19]. 
x Desde la perspectiva de seguridad o en realidad lo que se puede ver afectado por las controles 
de  seguridad existentes vÃ­a firewalls, las implementaciones de VPN no impone mayores 
complicaciones. Normalmente se tiene un esquema cliente/servidor con un puerto bien 
conocido para el servidor, al cual los clientes hacen requerimientos. Esto implica que todo el 
XIII Congreso Argentino de Ciencias de la ComputaciÃ³n
Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯
 
VIII Workshop de Procesamiento Distribuido y Paralelo
_________________________________________________________________________
 
 
1173
trÃ¡fico se â€œconcentraâ€ (de allÃ­ en parte el nombre de â€œtÃºnelâ€ o â€œentubamientoâ€ o tunnel que 
suele aparecer en la bibliografÃ­a de VPN) en un puerto bien conocido del servidor que se 
instale. Esto de hecho simplifica lo relacionado con la seguridad, dado que la configuraciÃ³n de 
los firewalls se orienta, justamente, al control sobre nÃºmeros de IP y puertos a ser utilizados en 
trÃ¡fico TCP/UDP sobre IP. Al establecer un Ãºnico IP (el del servidor) y un Ãºnico puerto (el 
puerto bien conocido del servicio de VPN, que de hecho es configurable) las tareas son 
mÃ­nimas. De hecho, los controles actuales de trÃ¡fico peer to peer se pueden evitar con cierta 
sencillez dado que el servidor de VPN se puede configurar para que utilice puertos 
privilegiados en vez de los no privilegiados que normalmente se utilizan y se filtran en los 
firewalls por el trÃ¡fico peer to peer.
x Evidentemente en tiempo de ejecuciÃ³n existe una sobrecarga de procesamiento y en cierto 
modo tambiÃ©n de trÃ¡fico de datos por el entubamiento de las comunicaciones sobre el esquema 
de cliente/servidor sobre un puerto bien conocido. En principio, en este artÃ­culo se pondrÃ¡ 
Ã©nfasis en la factibilidad, por lo tanto no se estudiarÃ¡ especÃ­ficamente el problema de la 
sobrecarga. Sin embargo, se puede estimar a priori que la utilizaciÃ³n de una VPN implica 
menor sobrecarga que una infraestructura como la de Grid Computing. 
La Fig. 1 muestra esquemÃ¡ticamente el ambiente de ejecuciÃ³n de programas con MPI a partir de la 
utilizaciÃ³n de una VPN. Desde la perspectiva del programador y sin tener en cuenta lo relacionado 
con el rendimiento de las comunicaciones, no hay ningÃºn cambio, ni siquiera es necesario 
recompilar, dado que los binarios generados son independientes de que se utilice VPN o se ejecute 
en un cluster de computadoras en una LAN. En la Fig. 1 no se muestran las conexiones reales (las 
que resuelve la implementaciÃ³n de VPN instalada) entre las mÃ¡quinas sino que con lÃ­neas de punto 
se muestran las conexiones vÃ­a VPN, como se utilizan desde los programas con MPI. El trÃ¡fico 
entre las computadoras de diferentes clusters se resuelve normalmente vÃ­a el que se define como 
servidor de VPN, dependiendo de la implementaciÃ³n y la configuraciÃ³n utilizadas. 
Figura 1: Infraestructura Sencilla para CÃ³mputo Paralelo Interclusters con VPN. 
4 EXPERIMENTACION: EVALUACION DE COMUNICACIONES 
Tal como se reporta en [18], se utiliza el mÃ©todo sencillo de ping-pong de mensajes para evaluar el 
rendimiento de las comunicaciones entre dos procesos (en este caso en dos clusters diferentes), 
siguiendo el modelo de tiempo para las transferencias de datos 
t(n) = D + E n
donde n es la cantidad de datos, D es el tiempo de latencia (mÃ­nimo tiempo siempre se necesita para 
las comunicaciones) y E es la inversa del ancho de banda, o costo en tiempo por dato a comunicar. 
Uno de los primeros problemas encontrados, fue que no es posible utilizar cualquiera de las 
implementaciones de MPI sobre la VPN. En particular, LAM/MPI tiene problemas de ejecuciÃ³n, 
probablemente por las transferencias de datos entre los procesos lamd que ejecuta en cada una de 
las mÃ¡quinas utilizadas. Para evitar el estudio de las razones de este problema, se recurriÃ³ a una 
implementaciÃ³n de MPI totalmente estÃ¡tica en el sentido de que no hay procesos de administraciÃ³n
Cluster 1 Cluster 2 
VPN
Aplicaciones con MPI 
Red Red
XIII Congreso Argentino de Ciencias de la ComputaciÃ³n
Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯
 
VIII Workshop de Procesamiento Distribuido y Paralelo
_________________________________________________________________________
 
 
1174
o intermedios (del tipo de los lamd para LAM/MPI) para la ejecuciÃ³n de aplicaciones, MPICH, 
versiÃ³n 1.2.4. Si bien en cierta forma se contradice la idea expresada en cuanto a que cualquier 
implementaciÃ³n de MPI se podrÃ­a usar sobre la VPN, siempre es posible: 
1. Encontrar el problema por el cual no funciona una implementaciÃ³n en particular y resolverlo (o 
hacer el requerimiento a quienes producen la implementaciÃ³n). 
2. Encontrar una implementaciÃ³n de MPI que funcione sobre la VPN. En este caso, al menos para 
se recurre a MPICH que es de las implementaciones de MPI mÃ¡s utilizadas y respetadas de 
entre las de uso libre.
El entorno de experimentaciÃ³n elegido fue el mÃ¡s sencillo posible en cuanto a cantidades de 
computadoras: dos PCs con Linux, cada una en una red local diferente. Las dos redes locales 
involucradas son en realidad dos subredes de la 163.10.xx.yy de la UNLP, una en el Ã¡mbito de la 
Facultad de InformÃ¡tica y la otra en el Ã¡mbito de la Facultad de IngenierÃ­a. La red de interconexiÃ³n 
entre las dos redes locales no es exclusiva y, por lo tanto, se comparte o compite por el ancho de 
banda disponible entre estas redes con el trÃ¡fico usual de otras aplicaciones relacionado con 
Internet. La cantidad de computadoras con el que se comparte esta interconexiÃ³n estÃ¡ en el orden de 
las centenas. La cantidad y el trÃ¡fico que involucran los experimentos ping-pong fueron 
determinados de forma tal que: 
x No utilicen mÃ¡s del 5% de 10Mb/s que se asume como el mÃ¡ximo ancho de banda disponible 
entre las redes locales, con mÃºltiples routers intermedios, algunos de los cuales utilizando 
placas Ethernet de 10 Mb/s. En cualquier caso, este trÃ¡fico es muy conservador en el sentido de 
evitar al mÃ¡ximo cualquier congestiÃ³n de trÃ¡fico en la red de interconexiÃ³n compartida. 
x Los experimentos se distribuyen de manera uniforme durante todo el tiempo de ejecuciÃ³n, de 
forma tal que se monitoricen tiempos de uso normal de las redes locales y de trÃ¡fico de Internet 
con el que se compite con otras aplicaciones en el tramo de interconexiÃ³n entre los clusters. 
x El 50% de los experimentos se orienta a identificar la latencia de los mensajes entre dos 
procesos de una aplicaciÃ³n paralela y el otro 50% se orienta a la identificaciÃ³n del ancho de 
banda disponible o posible entre los procesos. La longitud de los mensajes de los experimentos 
orientados a latencia se establece en 8 bytes y la longitud de los mensajes orientados a ancho de 
banda se establece en 20000 bytes (bÃ¡sicamente para no provocar rÃ¡fagas de uso muy intensivo 
sobre la red compartida, como se explica en el primer punto). 
x Los experimentos se llevaron a cabo durante aproximadamente 10 dÃ­as corridos, para tener 
datos de dÃ­as y horas de uso normal de las computadoras y las redes intermedias y tambiÃ©n de 
dÃ­as y horas con relativamente poco de uso de las computadoras y redes involucradas.  
La Fig. 2 muestra el histograma de la distribuciÃ³n de los tiempos de latencia de los experimentos, 
donde se puede observar que la gran mayorÃ­a de los mensajes tiene una latencia de entre 1 y 5 
milisegundos. Es claro que esta latencia es muy elevada para las capacidades de cÃ³mputo de las PCs 
actuales (que son del orden de Gflop/s), pero en cierto modo es muy importante identificar con 
experimentos tan sencillos que alrededor del 95% de las comunicaciones tienen valores de latencia 
en este rango. Esta informaciÃ³n es particularmente Ãºtil para las aplicaciones paralelas, dado que dan 
una idea de la granularidad mÃ­nima: no tiene sentido comunicarse entre tiempos de cÃ³mputo 
menores a los de la latencia. La Fig. 3 muestra la distribuciÃ³n del ancho de banda de los 
experimentos realizados con 20000 bytes, donde como en el caso de la latencia se puede observar 
que la mayorÃ­a estÃ¡ concentrado en un rango de valores relativamente pequeÃ±o. A modo de resumen 
de los valores mostrados en la Fig. 3, la gran mayorÃ­a (alrededor de 95%) de los experimentos se 
lleva a cabo con entre 50 y 58 KB/s. Es de destacar que durante todo el tiempo de ejecuciÃ³n de los 
experimentos no hubo que reinstalar ni reconfigurar OpenVPN, la conectividad entre las 
computadoras se mantuvo dentro de la VPN, a diferencia de lo que habÃ­a sucedido en los 
experimentos reportados en [20]. 
XIII Congreso Argentino de Ciencias de la ComputaciÃ³n
Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯
 
VIII Workshop de Procesamiento Distribuido y Paralelo
_________________________________________________________________________
 
 
1175
04000
8000
12000
16000
20000
<1 1-2 2-3 3-4 4-5 5-6 6-8 8-10 >10
Rango de Lantencia (ms)
C
an
tid
ad
Figura 2: DistribuciÃ³n de Tiempos de Latencia (Startup Time) con MPI en VPN. 
0
4000
8000
12000
16000
20000
< 48K/s 48-50K/s 50-52K/s 52-54K/s 54-56K/s 56-58K/s > 58K/s
Rango de Ancho de Banda (KB/s)
C
an
tid
ad
Figura 3: DistribuciÃ³n de Anchos de Banda con MPI en VPN. 
5 EXPERIMENTACION: PARALELIZACION DE APLICACIONES 
Como ya se ha comentado, el hecho de que sea factible el cÃ³mputo paralelo interclusters no 
resuelve los problemas asociados a la paralelizaciÃ³n de aplicaciones. De hecho se podrÃ­a afirmar 
que por un lado aporta un horizonte nuevo de paralelizaciÃ³n y sus problemas asociados. Uno de 
ellos es la asimetrÃ­a o diferencia en las comunicaciones intra e inter clusters que se ha comentado. 
A partir de los resultados que se muestran en la secciÃ³n anterior se tienen datos mÃ¡s precisos al 
menos del entorno sobre el que se llevÃ³ a cabo la experimentaciÃ³n: 
x El rendimiento de las comunicaciones interclusters no es constante, aunque los rangos son 
reducidos.
x El rendimiento de las comunicaciones interclusters es varias veces menor que el de las 
comunicaciones dentro de un mismo cluster. Solamente a modo de ejemplo, en un cluster 
interconectado con Ethernet de 100 Mb/s se tienen aproximadamente 10 MB/s entre procesos, 
lo cual es muy superior al rango de 50-58 KB/s que se muestra en la Fig. 3.  
Las aplicaciones denominadas altamente paralelas o embarazosamente paralelas (embarrassingly 
parallel) son las primeras opciones para ser resueltas en cualquier plataforma de cÃ³mputo paralelo. 
Esto se debe a que en realidad paralelizar estas aplicaciones no requiere casi ningÃºn esfuerzo mÃ¡s 
allÃ¡ de la propia codificaciÃ³n del programa, por ejemplo con MPI. Por otro lado, estas aplicaciones 
normalmente requieren muy pocas comunicaciones durante el tiempo de cÃ³mputo o, puesto de otra 
forma, se pueden paralelizar con granularidad muy gruesa. Esto las hace mejores en cuanto a la 
obtenciÃ³n de rendimiento Ã³ptimo o cercano al Ã³ptimo en ambientes con muy bajo rendimiento de 
XIII Congreso Argentino de Ciencias de la ComputaciÃ³n
Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯
 
VIII Workshop de Procesamiento Distribuido y Paralelo
_________________________________________________________________________
 
 
1176
comunicaciones, como el que se utiliza para la experimentaciÃ³n en este artÃ­culo.   
Se han elegido dos aplicaciones muy conocidas pero con diferentes caracterÃ­sticas de paralelizaciÃ³n 
con la finalidad de evaluar rendimiento: integraciÃ³n numÃ©rica (cÃ¡lculo del nÃºmero S) y cÃ¡lculos 
asociados con el conjunto de Mandelbrot. En ambos casos, los problemas de cÃ¡lculo asociados son 
muy sencillos de paralelizar dado que se pueden identificar partes de cÃ³mputo independiente de 
manera natural, sin recurrir a cambios en el tipo de cÃ³mputo secuencial bÃ¡sico. Nuevamente el 
ambiente de experimentaciÃ³n es el de mÃ­nima complejidad en cuanto a cantidad de computadoras: 
una computadora en cada uno de los clusters. Dado que es importante la capacidad de cÃ³mputo para 
estos experimentos, en la Tabla 1 se detallan las caracterÃ­sticas tÃ©cnicas mÃ¡s importantes de las dos 
computadoras utilizadas, donde se puede notar que son muy diferentes en cuanto a capacidad de 
procesamiento y almacenamiento. 
Tipo CPU Memoria RAM Sistema Operativo 
PC Pentium 4 2.4 GHz 1 GB Linux 2.4.18-14 
PC Pentium II 400 MHz 128 MB Linux 2.4.18-14 
Tabla 1: CaracterÃ­sticas de las Computadoras Utilizadas en los Experimentos. 
Un problema comÃºn en el contexto de cÃ³mputo paralelo interclusters es el de la heterogeneidad en 
cuanto a la capacidad de cÃ³mputo de las computadoras que se utilizan. Desde la perspectiva de la 
paralelizaciÃ³n, esto genera un problema de balance de carga implÃ­cito en la suposiciÃ³n de que a 
todos los procesadores se les asignarÃ¡ la misma cantidad de operaciones a realizar. Se debe notar 
que esto no es un problema de paralelizaciÃ³n sino de rendimiento (quizÃ¡s implÃ­cito) de la 
paralelizaciÃ³n. Para balancear la carga o, mÃ¡s especÃ­ficamente, para asignar la carga de 
procesamiento acorde a la capacidad relativa de cada procesador se tienen que resolver dos 
problemas: 
1. Conocer las diferencias relativas de capacidades de cÃ³mputo, es decir para cada par de 
computadoras cuÃ¡nto mejor o peor es una respecto de la otra. 
2. Asignar la cantidad de cÃ³mputo de cada computadora de acuerdo con su capacidad relativa 
respecto de las demÃ¡s.  
El primer problema es sencillo de resolver utilizando la idea ya planteada en [21] y [16], es decir 
ejecutando el mismo problema pero con tamaÃ±o reducido en cada una de las computadoras y 
relacionando directamente los tiempos de cÃ³mputo. Con estos cÃ¡lculos no solamente se puede 
definir el balance de carga sino tambiÃ©n la evaluaciÃ³n de rendimiento. El segundo de los problemas 
planteado normalmente depende de la aplicaciÃ³n, es decir que se resuelve caso por caso. 
5.1 CÃ¡lculo de S
Una forma numÃ©rica de calcular el nÃºmero S se lleva a cabo vÃ­a integraciÃ³n numÃ©rica con el cÃ¡lculo  
Â¦

 
u 
1
0
2 )1/(4
n
i
ixhS (1)
donde h = 1/n, n es la cantidad de puntos a utilizar en la integraciÃ³n numÃ©rica y xi = h Ã— (i + 0.5). En 
general, a mayor cantidad de puntos (n mayor) es mejor o mÃ¡s precisa la aproximaciÃ³n de S que se 
obtiene. Claramente, cada tÃ©rmino de la sumatoria puede ser calculado de manera absolutamente 
independiente de todos los demÃ¡s y, por lo tanto, estos cÃ¡lculos (y las sumas intermedias de los 
mismos) pueden ser paralelizados en tantos procesadores como se decida. Si bien la paralelizaciÃ³n 
es trivial, no sucede lo mismo con el balance de carga, dado que no se logra balancear la carga en p
XIII Congreso Argentino de Ciencias de la ComputaciÃ³n
Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯
 
VIII Workshop de Procesamiento Distribuido y Paralelo
_________________________________________________________________________
 
 
1177
procesadores realizando la suma parcial de n/p tÃ©rminos de la Ec. (1) en cada uno de ellos. En este 
caso particular, se puede aprovechar de manera directa otra de las caracterÃ­sticas del cÃ¡lculo 
planteado en la Ec. (1): todos los tÃ©rminos de la sumatoria implican el mismo costo en tÃ©rminos de 
operaciones numÃ©ricas. En este sentido, el problema no solamente es sencillo en cuanto a su 
divisiÃ³n en partes sino que tambiÃ©n es sencillo en cuanto a balance de carga en ambientes 
heterogÃ©neos: la cantidad de tÃ©rminos de la sumatoria de la Ec. (1) a resolver en cada computadora 
es directamente proporcional a su potencia de cÃ³mputo relativa. En el caso de las PCs de la Tabla 1, 
la capacidad de cÃ³mputo relativa es tal que una es casi tres veces mejor que la otra en tÃ©rminos de 
capacidad de cÃ¡lculo para S. Los resultados de los experimentos realizados con el cÃ¡lculo de S se 
resumen en la Tabla 2, donde se muestran las velocidades relativas normalizadas con respecto a la 
de mayor capacidad de cÃ³mputo. 
Velocidades Normalizadas 1 y 0,36 
Eficiencia de la ParalelizaciÃ³n 94% 
Tabla 2: Resumen de la ExperimentaciÃ³n con el CÃ¡lculo de S Interclusters. 
Aunque la cantidad de computadoras es la mÃ­nima, el hecho de obtener una eficiencia del 94% es 
muy satisfactorio dado el bajo rendimiento de las interconexiones entre los clusters utilizados. En el 
caso de estas aplicaciones muy sencillas de paralelizar y balancear en cuanto a carga de trabajo, es 
de esperar que la eficiencia se mantenga alta aumentando la cantidad de computadoras. 
5.2 CÃ¡lculos Asociados al Conjunto de Mandelbrot
La Fig. 4 muestra una de las formas mÃ¡s comunes de cÃ³mputo utilizado para el grÃ¡fico relacionado 
con el conjunto de Mandelbrot (mencionado en algunos casos como â€œescape time algorithmâ€ [26]) 
para un punto dado como (x0, y0) [22]. 
x = x0; y = y0; iter = 0; 
while ( x*x + y*y < (2*2)  AND  iter < max)  
{
    xtemp = x*x - y*y + x0; y = 2*x*y + y0; 
    x = xtemp; iter = iter + 1; 
}
color = iter
Figura 4: CÃ³mputo Relacionado con el Conjunto de Mandelbrot. 
ComparÃ¡ndolo con el cÃ³mputo de S anterior, el que se muestra en la Fig. 4: 
x Es similar en cuanto a que el valor de un punto en particular es totalmente independiente de 
todos los demÃ¡s valores. 
x Es diferente en cuanto a que la cantidad de operaciones necesarias para el cÃ¡lculo del valor de 
un punto en particular no es conocida a priori, depende del punto mismo (iteraciÃ³n while).
Normalmente, lo que se paraleliza es el cÃ¡lculo de los diferentes puntos y evidentemente no 
requiere mucho esfuerzo. No es tan directo el balance de carga, aÃºn cuando se conozcan las 
velocidades relativas de las computadoras a utilizar. Tampoco es demasiado complejo, dado que se 
puede recurrir a un esquema similar al utilizado en cÃ³mputos de Ã¡lgebra lineal, por ejemplo, donde 
se distribuye el cÃ¡lculo de forma tal que cada proceso debe obtener valores relativamente dispersos 
en el espacio total a calcular [16]. En el caso de Ã¡lgebra lineal, esto se aplica sobre la matriz a 
factorizar en L y U, por ejemplo, y en este caso se aplicarÃ¡ al conjunto de puntos a calcular. Visto 
como una matriz, el conjunto de puntos a calcular se puede dividir en mÃºltiples bloques de 
relativamente pocas filas o columnas y estos bloques se asignan a las diferentes computadoras. 
XIII Congreso Argentino de Ciencias de la ComputaciÃ³n
Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯
 
VIII Workshop de Procesamiento Distribuido y Paralelo
_________________________________________________________________________
 
 
1178
Teniendo una cantidad de bloques suficientemente grandes, la cantidad de bloques asignados a cada 
computadora es directamente proporcional a su velocidad relativa. En el caso especÃ­fico del 
conjunto de Mandelbrot, se llevÃ³ a cabo el cÃ¡lculo para un espacio de 800x800 puntos que se 
dividiÃ³ en bloques de 100x800 puntos (bloques de 100 filas) y de cada uno de estos bloques, la 
cantidad de filas asignadas a cada computadora es proporcional a la velocidad relativa de las 
mismas. La Tabla 3 muestra el resumen de los experimentos realizados con este problema, 
aplicando el balance de carga que se describiÃ³ previamente. Una vez mÃ¡s, la eficiencia de la 
paralelizaciÃ³n es muy satisfactoria para la plataforma de cÃ³mputo subyacente. 
Velocidades Normalizadas 1 y 0,36 
Eficiencia de la ParalelizaciÃ³n 89% 
Tabla 2: Resumen de la ExperimentaciÃ³n con el CÃ¡lculo de S Interclusters. 
6 CONCLUSIONES Y TRABAJO FUTURO 
En este artÃ­culo se ha mostrado la utilizaciÃ³n de una VPN para cÃ³mputo paralelo interclusters 
utilizando una implementaciÃ³n especÃ­fica de MPI. Esto muestra que, al menos en principio, no es 
necesaria una infraestructura muy compleja sino middleware estÃ¡ndar para cÃ³mputo paralelo 
interclusters. Los experimentos han mostrado que es posible caracterizar satisfactoriamente el 
rendimiento de las comunicaciones interclusters de manera sencilla, y a partir de esta informaciÃ³n 
se pueden tomar decisiones importantes de paralelizaciÃ³n. TambiÃ©n se ha mostrado que no 
solamente es factible paralelizar aplicaciones, (al menos las del tipo embarrassingly parallel), sino 
que se puede obtener rendimiento muy satisfactorio, con eficiencia de la paralelizaciÃ³n de alrededor 
del 90% o mayor. TambiÃ©n se ha mostrado que las estrategias conocidas de balance de carga dan 
resultados satisfactorios, al menos en las aplicaciones que se mostraron. 
Una de las extensiones inmediatas de este trabajo consiste en la utilizaciÃ³n de mÃ¡s de una 
computadora en cada cluster involucrado. Sin lugar a dudas el objetivo final de cÃ³mputo paralelo 
interclusters deberÃ­a ser el de utilizar todos los clusters de manera completa, para aprovechar al 
mÃ¡ximo la capacidad de cÃ¡lculo disponible. En caso contrario, se deberÃ­a establecer una estrategia o 
polÃ­tica de utilizaciÃ³n de las computadoras de cada cluster que justifique el hecho de no utilizar las 
computadoras disponibles de los clusters.  
