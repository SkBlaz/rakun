TypeCase: A Design Pattern for Type-Indexed Functions
Abstract
A type-indexed function is a function that is defined for each
member of some family of types. Haskell's type class mechanism
provides collections of open type-indexed functions, in which
the indexing family can be extended by defining a new type class
instance but the collection of functions is fixed. The purpose of this
paper is to present TypeCase: a design pattern that allows the definition
of closed type-indexed functions, in which the index family
is fixed but the collection of functions is extensible. It is inspired
by Cheney and Hinze's work on lightweight approaches to generic
programming. We generalise their techniques as a design pattern
. Furthermore, we show that type-indexed functions with type-indexed
types, and consequently generic functions with generic
types, can also be encoded in a lightweight manner, thereby overcoming
one of the main limitations of the lightweight approaches.
Categories and Subject Descriptors
D.3.3 [Programming Languages
]: Language Constructs and Features
General Terms
Languages

Introduction
A type-indexed function is a function that is defined for each member
of a family of types. One of the most popular mechanisms
implementing this notion is the Haskell [31] type class system. A
type class consists of a collection of related type-indexed functions;
the family of index types is the set of instances of the type class.
Type classes provide just one possible interpretation of the notion
of type-indexed functions. In particular, they assume an open-world
perspective: the family of index types is extensible, by defining a
new type class instance for that type, but the collection of type-indexed
functions is fixed in the type class interface so needs to
be known in advance. For some applications -- particularly when
providing a framework for generic programming -- the family of
index types is fixed (albeit large) and the collection of type-indexed
functions is not known in advance, so a closed-world perspective
would make more sense.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. To copy otherwise, to republish, to post on servers or to redistribute
to lists, requires prior specific permission and/or a fee.
Haskell'05
September 30, 2005, Tallinn, Estonia.
Copyright c 2005 ACM 1-59593-071-X/05/0009. . . $5.00.
The original concept of a design pattern has its origins in Christopher
Alexander's work in architecture, but it has been picked up
with enthusiasm by the object-oriented programming community.
The idea of design patterns is to capture, abstract and record beneficial
recurring patterns in software design. Sometimes those patterns
can be captured formally, as programming language constructs
or software library fragments. Often, however, the appropriate
abstraction cannot be directly stated, either because of a lack
of expressiveness in the language, or because there is inherent ambiguity
in the pattern -- Alexander describes a pattern as a solution
`you can use [. . . ] a million times over, without ever doing it the
same way twice' [1]. In this case, one must resort to an informal
description. Even if the abstraction itself can be captured formally,
one might argue that a complete description of the pattern includes
necessarily informal information: a name, motivation, examples,
consequences, implementation trade-offs, and so on.
In this paper, we present a technique that allows the definition of
closed type-indexed functions, as opposed to the open type-indexed
functions provided by type classes; we do so in the format of a
design pattern. Our inspiration comes from previous research on
lightweight approaches to generic programming (LAGP). In particular
, Hinze's two papers "A Lightweight Implementation of Generics
and Dynamics" [4] (LIGD, with James Cheney) and "Generics
for the Masses" [19] (GM) provide our motivation and basis.
Those two papers focus on the particular context of generic
programming, and provide a number of techniques that can be used
to encode first-class generic functions in Haskell. However, those
techniques have a wider applicability, not addressed by Hinze. We
propose a generalisation of the technique, and demonstrate its use
in a variety of applications. Our specific contributions are:
Generalisation of the lightweight approaches. We provide templates
for designing closed type-indexed functions, abstracting
away from generic programming. The techniques in LIGD and
GM are instances of these templates.
A design pattern for type-indexed functions. We document this
generalisation as a design pattern.
Type-indexed functions with type-indexed types. We show that
with our more general interpretation of the design pattern, type-indexed
functions with type-indexed types are also instances of
the design pattern. As a consequence, generic functions with
generic types can also be encoded in a lightweight manner.
Thus, we remove one of the main limitations of the lightweight
approaches.
Other applications. We present two other interesting applications
of the pattern: PolyP in Haskell 98, and a very flexible printf
function.
The remainder of this paper is structured as follows. In Section 2
we review the lightweight approaches to generic programming. In
Section 3 we abstract the essence of the technique as a design pattern
. Section 4 presents two other small applications of the design
98
pattern, and Section 5 uses it to model type-indexed functions with
type-indexed types. Section 6 concludes.
Lightweight generic programming
We start by summarising the earlier work on lightweight approaches
to generic programming underlying our generalisation.
2.1
"A Lightweight Implementation of Generics and
Dynamics"
Cheney and Hinze [4] show how to do a kind of generic programming
, using only the standard Hindley-Milner type system extended
with existential types. The index family consists of hierarchical
sums and products of integers and characters. This family is enough
to represent a large subset of Haskell 98 datatypes (including mutually
recursive and nested datatypes).
data Sum a b
= Inl a | Inr b
data Prod a b
= Prod a b
data Unit
= Unit
This style of generic programming requires a representation of
types as values in order to support typecase analysis. The key idea
of the LIGD paper is to use a parametrised type as the type representation
, ensuring that the type parameter reflects the type being
represented. Some Haskell implementations have recently been extended
with generalised algebraic datatypes (GADTs) [32], which
can be used for this purpose; but LIGD predates that extension, and
depends only on existential quantification.
data Rep t
=
RUnit
(t  Unit)
| RInt
(t  Int)
| RChar
(t  Char)
|  a b. RSum (Rep a) (Rep b) (t  (Sum a b))
|  a b. RProd (Rep a) (Rep b) (t  (Prod a b))
data a
b = EP{from :: a  b,to :: b  a}
(Note that the universal quantifications are in contravariant positions
, so act existentially.)
The intention is that the equivalence type a
b represents embedding/projection
pairs witnessing to an isomorphism between
types a and b, thereby enforcing a correspondence between types t
and Rep t. Of course, within Haskell, it is not possible to automatically
verify the isomorphisms (from
to = id and to  from = id), so
these laws should be externally checked. Furthermore, we follow
the convention of ignoring the `ugly fact' of bottom values destroying
the `beautiful theory' of many such isomorphisms [8].
A common case is with the trivial embedding/projections.
self :: a
a
self
= EP{from = id,to = id}
Using self , we can provide a set of smart constructors for the Rep
type, yielding representations of types by themselves.
rUnit :: Rep Unit
rUnit
= RUnit self
rInt :: Rep Int
rInt
= RInt self
rChar :: Rep Char
rChar
= RChar self
rSum :: Rep a
Rep b  Rep (Sum a b)
rSum ra rb
= RSum ra rb self
rProd :: Rep a
Rep b  Rep (Prod a b)
rProd ra rb
= RProd ra rb self
Using these smart constructors, we can build representations for
recursive datatypes, by making explicit the structure isomorphism
of the datatype. For instance, the isomorphism defining lists is
[a]
= 1 + a × [a], and so the corresponding type representation is
as follows.
rList ::
a. Rep a  Rep [a]
rList ra
= RSum rUnit (rProd ra (rList ra)) (EP from to)
where from
[ ]
= Inl Unit
from
(x : xs)
= Inr (Prod x xs)
to
(Inl Unit)
= [ ]
to
(Inr (Prod x xs)) = x : xs
Note that the representation of a recursive datatype is an infinite
value; but, because of laziness, this poses no problem.
Having constructed representation values for arbitrary types, the
final step is to define generic functions. Using the representation
as a basis for structural case analysis, it is possible to simulate a
typecase [16]. For example, here is a definition of generic equality:
eq ::
t. Rep t  t  t  Bool
eq
(RInt ep)
t
1
t
2
= from ep t
1
from ep t
2
eq
(RChar ep)
t
1
t
2
= from ep t
1
from ep t
2
eq
(RUnit ep)
= True
eq
(RSum ra rb ep) t
1
t
2
= case (from ep t
1
,from ep t
2
) of
(Inl x,Inl y)  eq ra x y
(Inr x,Inr y)  eq rb x y
False
eq
(RProd ra rb ep) t
1
t
2
= case (from ep t
1
,from ep t
2
) of
(Prod x y,Prod x y )
eq ra x x
eq rb y y
Using Haskell type classes, it is possible to make the use of generic
functions even more convenient: the class TypeRep can be used to
build values of type Rep t implicitly.
class TypeRep t where
rep :: Rep t
instance TypeRep Unit where
rep
= rUnit
instance TypeRep Int where
rep
= rInt
instance TypeRep Char where
rep
= rChar
instance
(TypeRep a,TypeRep b)  TypeRep (Sum a b) where
rep
= rSum rep rep
instance
(TypeRep a,TypeRep b)  TypeRep (Prod a b) where
rep
= rProd rep rep
instance TypeRep a
TypeRep [a] where
rep
= rList rep
For example, we can now express generic equality with an implicit
rather than explicit dependence on the representation.
ceq ::
t. TypeRep t  t  t  Bool
ceq t
1
t
2
= eq rep t
1
t
2
2.2
"Generics for the Masses"
Hinze's later GM approach [19] has a very similar flavour to LIGD;
however, somewhat surprisingly, Hinze shows how to do generic
programming strictly within Haskell 98, which does not support
rank-n types or even existential types. Nevertheless, there is a close
relationship between type classes and polymorphic records (for
example, one possible translation of type classes into System F uses
polymorphic records), and these require something like existential
types for their encoding. Thus, type class instances can be seen
as implicitly-passed records. Hinze uses this observation to deliver
two implementations of generics.
2.2.1
Generic functions on types
The first implementation of generics in GM ("GM1", from now
on) can be seen as a direct descendent of LIGD. Instead of using a
datatype with an existential quantification, Hinze uses a type class
Generic.
99
class Generic g where
unit
:: g Unit
sum
::
(TypeRep a,TypeRep b)  g (Sum a b)
prod
::
(TypeRep a,TypeRep b)  g (Prod a b)
datatype :: TypeRep a
(b  a)  g b
char
:: g Char
int
:: g Int
The parameter g of the type class represents the generic function,
and each of the member functions of the type class encodes the
behaviour of that generic function for one structural case. Generic
functions over user-defined types can also be defined using the
datatype type case. In this case, the isomorphism between the
datatype and its structural representation must be provided.
The type class TypeRep is used to select the appropriate behaviour
of the generic function, based on the type structure of its argument
. The role of this type class is somewhat analogous to the
synonymous one in Section 2.1. One contrast with LIGD is that
TypeRep for GM1 is not optional, because the type representations
are always implicitly passed.
class TypeRep a where
typeRep :: Generic g
g a
instance TypeRep Unit where
typeRep
= unit
instance
(TypeRep a,TypeRep b)  TypeRep (Sum a b) where
typeRep
= sum
instance
(TypeRep a,TypeRep b)  TypeRep (Prod a b) where
typeRep
= prod
instance TypeRep Char where
typeRep
= char
instance TypeRep Int where
typeRep
= int
For GM, the type class TypeRep directly selects the appropriate
behaviour for a particular structural case from the generic function.
In contrast, for LIGD, the corresponding type class TypeRep builds
a value as a type representation for a particular structural case,
and this representation is then used by a generic function to select
the appropriate behaviour. The effect is the same, but GM is more
direct.
A new generic function is defined via an instance of Generic,
providing an implementation for each structural case. For instance,
the generic function gSize that counts all the elements of type Int
and Char in some structure could be encoded as follows.
newtype GSize a
= GSize{appGSize :: a  Int}
instance Generic GSize where
unit
= GSize (  0)
sum
= GSize (t  case t of
Inl x
gSize x
Inr y
gSize y)
prod
= GSize (t  case t of
Prod x y
gSize x + gSize y)
datatype iso
= GSize (t  gSize (from iso t))
char
= GSize (  1)
int
= GSize (  1)
gSize :: TypeRep a
a  Int
gSize
= appGSize typeRep
A record of type GSize a contains a single function appGSize of
type a
Int, which can be used to compute the number of elements
in some structure of type a. The function gSize, which is the actual
generic function, simply extracts the sole appGSize field from a
record of the appropriate type, built automatically by typeRep.
2.2.2
Generic functions on type constructors
The second implementation of generics in GM ("GM2") permits
parametrisation by type constructors rather than by types. For example
, whereas the generic function gSize of the previous section
has type a
Int for all first-order types a in the type class TypeRep,
in this section we show a generic function gSize with type f a
Int
for all type constructors f in the constructor class FunctorRep.
Lifting in this fashion introduces the possibility of ambiguity:
a type g
(f a) may be considered a type constructor g applied
to a type f a, or the composition of constructors g and f applied
to type a. Therefore we must explicitly pass type representations,
increasing flexibility but decreasing brevity. This is reflected in the
analogous type class Generic, where the implicitly-passed TypeRep
contexts are now changed to explicitly-passed functions.
class Generic g where
unit
:: g Unit
sum
:: g a
g b  g (Sum a b)
prod
:: g a
g b  g (Prod a b)
datatype ::
(b  a)  g a  g b
char
:: g Char
int
:: g Int
However, this modification of the type class restricts expressivity,
since the only generic function we can call is the one being defined,
recursively. Consequently, generic functions that perform calls to
other generic functions (as when defining generic membership in
terms of generic equality) become harder to define.
With the new Generic class it is also possible to build the
values for type representations automatically, using another type
class TypeRep. Just as with LIGD, this class now becomes optional.
Alternatively, we can use a type class FunctorRep to capture the
notion of unary type constructor or functor.
class FunctorRep f where
functorRep :: Generic g
g a  g (f a)
We have to define similar classes for each arity of type constructor.
Generic functions are defined in a very similar fashion to GM1.
For instance, the type Count a below represents a generic function
that counts zero for each occurrence of a value of type Int or Char
in some structure of type a.
newtype Count a
= Count{applyCount :: a  Int}
instance Generic Count where
unit
= Count (  0)
sum a b
= Count (x  case x of
Inl l
applyCount a l
Inr r
applyCount b r)
prod a b
= Count ((Prod x y)
applyCount a x
+ applyCount b y)
datatype iso a
= Count (x
applyCount a
(from iso x))
char
= Count (  0)
int
= Count (  0)
While this function by itself approximates const 0, it is the basis
for other more useful functions that really count the number of elements
in some structure in some way, by overriding the behaviour
of the basic generic function for occurrences of the type parameter:
gSize :: FunctorRep f
f a  Int
gSize
= applyCount (functorRep (Count (  1)))
The payback of using FunctorRep is that we can define the
behaviour of the generic function for its parameters. For instance,
we could sum all the integers in some integer-parametrised datatype
by using the identity function to define the behaviour of the generic
function for the type parameter.
gSum :: FunctorRep f
f Int  Int
gSum
= applyCount (functorRep (Count id))
100
Closed type-indexed functions
In LIGD and GM, we are shown three methods for implementing
closed type-indexed functions. Those three variations give us different
expressive power, and impose different constraints on the
type system. A choice of implementation techniques, together with
technical trade-offs making no one method superior in all circumstances
, is characteristic of design patterns.
In this section, we introduce the TypeCase design pattern,
capturing the different techniques for implementing closed type-indexed
functions.
The TypeCase design pattern
Intent:
Allowing the definition of closed type-indexed functions.
Motivation:
The typecase design pattern captures a closed-world
view of ad-hoc polymorphism. In Haskell, the type class system
is a mechanism that supports ad-hoc polymorphism, but from an
open-world point of view: they can be extended with cases for
new datatypes, at the cost of a non-extensible set of functions.
Under the closed-world assumption, there is a fixed set of type-structural
cases but arbitrarily many type-indexed functions ranging
over those cases. An example where the closed-world perpective
works better than the open-world one is generic programming, in
which we take a structural perspective on types as opposed to the
more traditional nominal one. Using just a few operations on types,
it is possible to represent the whole family of structural definitions
of interest. For instance, here is a possible definition for a generic
function that counts all the elements of some structure t:
gsize t ::
:: t
Int
gsize Unit
= 0
gsize Int
= 1
gsize Sum
(Inl x)
= gsize  x
gsize Sum
(Inr y)
= gsize  y
gsize Prod
(Prod x y) = gsize  x + gsize  y
With an open-world perspective, we can present a fixed number
of type-indexed definitions that range over those few cases; but
we cannot easily introduce new definitions. This is clearly not
appropriate for generic programming. In fact, what we expect from
a generic programming facility is the ability to a introduce new
generic definition without affecting the surrounding context. This
is precisely what the closed-world perspective provides us.
Applicability:
Use this pattern:
·
to encode collections of definitions that are indexed by some
fixed family of types, while allowing new definitions to be added
to the collection without affecting modularity;
·
when a definition is variadic, that is, it has a variable number of
arguments (see Section 4.2 for an example);
·
to try to avoid type-class trickery, such as multiple-parameter
type classes, functional dependencies, overlapping instances or
even duplicate instances (just consider a direct encoding of the
examples presented in the paper into type classes [30]);
·
to capture some shape invariants, like the ones captured by
some nested types or phantom types [29, 18].
Structure:
See Figure 1.
Participants:
·
Structural Cases: a set of datatypes which represent the possible
structural cases for the type-indexed function;
·
Typecase: representing the structure of a type-indexed function;
·
Dispatcher: a type class, containing a single function, that is
responsible for dispatching a value of one of the structural cases
into the corresponding branch of the typecase, based on the type
of the value;
·
Type-indexed function: defining the type-indexed function using
an instance of the typecase.
Collaborations:
·
The typecase uses the structural cases in order to create a
corresponding number of cases that can be used to define the
type-indexed function.
·
The dispatcher uses the structural cases in order to create
a corresponding number of instances that will forward some
value of that family of structural cases into the corresponding
case in the typecase component.
·
The type-indexed function (TIF) uses an instance of the typecase
in order to implement the desired functionality for the type-indexed
function.
Implementation:
Typically, a typecase component is created using
the structural cases. There are three main variations for the implementation
of a typecase: two of them are based on type classes
and the other one on a smart datatype. A smart datatype is a parametrised
type where the type parameters are dependent on the constructors
. The idea of a smart datatype can be represented in various
forms: existential datatypes with an equivalence type (à la LIGD),
GADTs, phantom types, among others.
The goal of this design pattern is to simulate a closed type-indexed
function. In general, a type-indexed function f has the
following structure.
f t ::
| d
1
... d
k
::
f t
1
a
1
... a
i
=  x
11
... x
1n
e
1
.
.
.
f t
m
z
1
... z
j
=  x
m1
... x
mn
e
m
The type signature tells us that f has one type parameter t and
optional type parameters d
1
... d
k
with the same structure and kind
as t. The type  of the TIF may depend on t and d
1
... d
k
.
We should note that this is not the same as having a TIF with
multiple type arguments. There is no problem, in principle, in having
multiple-parameter type arguments, but it would lead to an explosion
in the number of typecases. This would be a generalisation
of this design pattern. For simplicity, we will only consider type
parameters with the same structure. The usefulness of this simpler
case is reflected in applications such as generic map where the input
and output structures of the generic map function are the same.
The body of f contains (at least) m branches, providing the
behaviour of the TIF for each member of the family of types t
(that is, t
1
a
1
... a
i
,...,t
m
z
1
... z
j
). This family of types corresponds
to the structural cases participant of the design pattern
. For each branch of the definition, we bind possible variables
x
11
... x
1n
,...,x
m1
... x
mn
and define each typecase of f with
e
1
,...,e
m
.
We now discuss the three main variations of the design pattern.
1. Smart datatypes: This variation is inspired by the LIGD approach
. Hindley-Milner typing extended with existential datatypes
(supported in most Haskell compilers) is enough to encode
it. However, with extensions such as GADTs (supported
by GHC 6.4) the encoding becomes much more direct. Unfortu-nately
, neither of those extensions conforms to Haskell 98. We
will present this version of the design pattern using a GADT
syntax for simplicity.
Using the structural cases given by t
1
a
1
... a
i
,...,t
m
z
1
... z
j
,
we can derive the typecase and dispatcher seen in Figure 1.
Since there are m structural cases in a standard instance of the
design pattern, one would create m constructors c
t
1
,...,c
t
m
and
also m instances for Rep

. TIFs can now be defined using those
components, by creating some function f that takes a first argument
of type Rep

and returns a value of type .
101
Smart Datatype
Implicit/Explicit Representations
Typecase
data  t d
1
... d
k
where
c
t
1
::
(a
1
... a
i
)

(t
1
a
1
... a
i
) d
11
... d
1k
.
.
.
c
t
m
::
(z
1
... z
j
)

(t
m
z
1
... z
j
) d
m1
... d
mk
class
(g ::
k
+1
) where
case
t
1
::
(a
1
... a
i
)
g
(t
1
a
1
... a
i
) d
11
... d
1k
.
.
.
case
t
m
::
(z
1
... z
j
)
g
(t
m
z
1
... z
j
) d
m1
... d
mk
Dispatcher
class Rep

t d
1
... d
k
where
rep :: Rep

t d
1
... d
k
instance
(a
1
... a
i
)

Rep

(t
1
a
1
... a
i
) d
11
... d
1k
where
rep
= c
t
1
rep
i
.
.
.
instance
(z
1
... z
j
)

Rep

(t
m
z
1
... z
j
) d
m1
... d
mk
where
rep
= c
t
m
rep
j
class Rep

t d
1
... d
k
where
rep ::  g
g t d
1
... d
k
instance
(a
1
... a
i
)

Rep

(t
1
a
1
... a
i
) d
11
... d
1k
where
rep
= case
t
1
{rep
i
}
.
.
.
instance
(z
1
... z
j
)

Rep

(t
m
z
1
... z
j
) d
m1
... d
mk
where
rep
= case
t
m
{rep
j
}
Type-indexed
function
f ::  t d
1
... d
k

f
(c
t
1
r
a
1
... r
a
i
) =  x
11
... x
1n
[[e
1
]]
.
.
.
f
(c
t
m
r
z
1
... r
z
j
) =  x
m1
... x
mn
[[e
m
]]
f :: Rep

t d
1
... d
k

f
= f rep
newtype F t d
1
... d
k
= F{f :: }
f :: Rep

t d
1
... d
k

f
= f rep
instance Rep

F where
case
t
1
{r
a
1
... r
a
i
} =  x
11
... x
1n
[[e
1
]]
.
.
.
case
t
m
{r
z
1
... r
z
j
} =  x
m1
... x
mn
[[e
m
]]
Figure 1. The structure of the TypeCase design pattern.
The dispatcher component is optional in this variation. The
TIFs created with this variation are fully closed to extension;
no customisation is possible. This means that if we want to add
extra functionality we need to modify the smart datatype (and
the dispatcher if we have one). However, TIFs that call other
TIFs are trivial to achieve; there is no need for tupling.
2. Implicit representations: The implicit representation version
of the design pattern is inspired by GM1. Perhaps surprisingly,
some implementations of this instance require only Haskell 98.
However, if we need to have structurally-dependent variables,
then we also require multiple-parameter type classes.
Proceeding in a similar fashion to the smart datatype approach
, we use the structural cases to derive the typecase and
dispatcher seen in Figure 1. Again, because we have m structural
cases, we create m functions case
t
1
,...,case
t
m
and m instances
of Rep

.
The dispatcher is not an optional component: it always
needs to be defined in this variation. As with the smart datatype
variation, TIFs defined in this way are fully closed to extension,
and calls to other TIFs are trivial.
3. Explicit representations: The explicit representation variation
of the design pattern is inspired by GM2. Like the implicit
approach, Haskell 98 is enough to handle the simpler forms
(one type parameter). However, if we discard the optional dispatcher
, then Haskell 98 can handle all forms.
Using the structural cases to derive the typecase and dispatcher
seen in Figure 1, we would obtain a very similar structure
to the implicit representation version. The most noticeable
difference is that, with the explicit representation, the definition
of rep needs to provide the corresponding case function with
the representations for each of its type parameters. The second
difference is that , which corresponds to the representations
of the type parameters, reflects the fact that we are providing
explicit representations. Thus,  corresponds in this instance
to explicit arguments of the function, while with the implicit
representation it corresponds to (implicitly passed) type class
constraints. The dispatcher is an optional component.
Variations of this instance of the design pattern can also be
found in the literature [10, 37], as described in Section 4.2. TIFs
defined in this fashion are not fully closed to extension: it is possible
to override default behaviour. However, the extra flexibility
comes at a cost: recursive calls to other TIFs are not possible.
One common solution for this problem is to tuple together into
a record the mutually-dependent functions. Another possibility
would be to have a notion of dependencies: if a TIF f requires
calls to another TIF g, then the record that defines f has a field
that is an instance of g. Although this work is quite tedious, Löh
[26] shows how a type system can lighten the burden.
An associated problem for TIFs in this setting is the issue
of composability. If two TIFs are defined using different instances
(this is, they are not tupled together), then we cannot, in
a straightforward manner, use the same representation to compose
them. To illustrate the problem, consider:
newtype F v
1
... v
n
= F{f :: }
newtype G v
1
... v
n
= G{g :: }
instance Generic F where
...
instance Generic G where
...
Now let us suppose that we define a type-indexed abstraction
(that is, a function that uses one or more TIFs and is not defined
over the structure of types):
h rep
= ... f rep ... g rep ...
The interpretation of this definition as a type-indexed function
could be thought of as: h a
= ... f a ... g a .... While this
is a perfectly reasonable interpretation, in practice f requires
inconsistent types F v
1
... v
n
and G v
1
... v
n
for rep: F and
G are two different type constructors, so in a Hindley-Milner
type system, unification obviously fails. However, F and G
do have something in common. In particular, they are both
102
instances of Generic. So, in Haskell extended with higher-order
polymorphism, we can capture this relation with a rank-2
type, thus providing a possible solution for the problem of
composability.
h ::
( g. Generic g  g v
1
... v
n
)
h rep
= ... f rep ... g rep ...
We should note that even though we have presented three main
variations of the design pattern, the concept of a design pattern is,
by itself, quite informal and thus prone to different interpretations.
For instance, as we will see later, applications of the pattern (such
as GM) can have more type cases than there are datatype variants,
because some cases overlap. It is important to note that, depending
on the context of a problem, a design pattern can be adapted to
better fit that problem.
Applications
We present two applications of the design pattern. In Section 4.1,
still within the context of generic programming, we show how
one can build a library inspired by PolyP [21, 22] but working in
Haskell 98. In Section 4.2, we present a very flexible version of a
C-style printf function.
4.1
Light PolyP
It probably comes as no surprise to the reader that the technique
introduced in GM and LIGD can be applied to other generic programming
approaches as well. PolyP was one of the first attempts to
produce a generic programming language. It is a simpler language
than Generic Haskell, working in a much more restricted family
of datatypes, namely one-parameter regular types. But this restriction
allows stronger properties to be stated: its simplicity and strong
theoretical background make it an appropriate language for teaching
both the theory [3] and practice of generic programming. Our
proposal Light PolyP encourages this, because no external PolyP
compiler is required (although one might still be desirable, for a
more convenient syntax).
Norell [30] shows how to use the Haskell type class system (extended
with multiple-parameter type classes and functional dependencies
) to obtain first-class PolyP generic functions in Haskell. In
this section, we will present a "lighter" version of PolyP, requiring
only Haskell 98 (without extensions such as multiple-parameter
type classes and functional dependencies) but with the same expressive
power.
Instead of using sums of products like LAGP or Generic
Haskell, PolyP uses lifted pattern functors as structural cases. The
pattern functors Empty, Plus and Prod have counterparts in LAGP.
The pattern functors Rep and Par correspond respectively to the recursive
argument and the parameter of the unary regular datatype.
The pattern functor Const t for some type t represents the constant
functor, and Comp handles the composition of functors required
for regular types.
data Empty p r
= Empty
data Plus g h p r
= Inl (g p r) | Inr (h p r)
data Prod g h p r
= Prod (g p r) (h p r)
newtype Par p r
= Par{unPar ::p}
newtype Rec p r
= Rec{unRec :: r}
newtype Comp d h p r
= Comp{unComp :: d (h p r)}
newtype Const t p r
= Const{unConst :: t}
The equivalence type is used to establish the isomorphism
between a regular datatype and its top-level structure. The embedding/projection
functions are traditionally called inn and out.
data Iso a b
= Iso{inn :: a  b,out :: b  a}
listIso
= Iso inL outL
where
inL
(Inl Empty)
= [ ]
inL
(Inr (Prod (Par x) (Rec xs))) = x : xs
outL
[ ]
= Inl Empty
outL
(x : xs) = Inr (Prod (Par x) (Rec xs))
In PolyP no generic customisation is allowed, thus we can use
an implicit representation version of the design pattern and consequently
, it is possible for one generic function to use other generic
functions in its definition. The typecase component corresponds to:
class Generic f where
empty
:: f Empty
plus
::
(Rep g,Rep h)  f (Plus g h)
prod
::
(Rep g,Rep h)  f (Prod g h)
par
:: f Par
rec
:: f Rec
comp
::
(Functor d,Rep h)  f (Comp d h)
constant :: f
(Const t)
The dispatcher simply selects the corresponding case based on
the type of the argument of the generic function g.
class Rep g where
rep :: Generic f
f g
instance Rep Empty where
rep
= empty
instance
(Rep g,Rep h)  Rep (Plus g h) where
rep
= plus
instance
(Rep g,Rep h)  Rep