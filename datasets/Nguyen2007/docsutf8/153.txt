Protected Interactive 3D Graphics Via Remote Rendering
Abstract
Valuable 3D graphical models, such as high-resolution digital scans
of cultural heritage objects, may require protection to prevent piracy
or misuse, while still allowing for interactive display and manipulation
by a widespread audience. We have investigated techniques
for protecting 3D graphics content, and we have developed a remote
rendering system suitable for sharing archives of 3D models
while protecting the 3D geometry from unauthorized extraction
. The system consists of a 3D viewer client that includes low-resolution
versions of the 3D models, and a rendering server that
renders and returns images of high-resolution models according to
client requests. The server implements a number of defenses to
guard against 3D reconstruction attacks, such as monitoring and
limiting request streams, and slightly perturbing and distorting the
rendered images. We consider several possible types of reconstruction
attacks on such a rendering server, and we examine how these
attacks can be defended against without excessively compromising
the interactive experience for non-malicious users.
CR Categories: I.3.2 [Computer Graphics]: Graphics Systems-Remote
systems
Introduction
Protecting digital information from theft and misuse, a subset of the
digital rights management problem, has been the subject of much
research and many attempted practical solutions. Efforts to protect
software, databases, digital images, digital music files, and other
content are ubiquitous, and data security is a primary concern in
the design of modern computing systems and processes. However,
there have been few technological solutions to specifically protect
interactive 3D graphics content.
The demand for protecting 3D graphical models is significant. Contemporary
3D digitization technologies allow for the reliable and
efficient creation of accurate 3D models of many physical objects,
and a number of sizable archives of such objects have been created.
The Stanford Digital Michelangelo Project [Levoy et al. 2000], for
example, has created a high-resolution digital archive of 10 large
statues of Michelangelo, including the David. These statues represent
the artistic patrimony of Italy's cultural institutions, and the
contract with the Italian authorities permits the distribution of the
3D models only to established scholars for non-commercial use.
Though all parties involved would like the models to be widely
available for constructive purposes, were the digital 3D model of
the David to be distributed in an unprotected fashion, it would soon
be pirated, and simulated marble replicas would be manufactured
outside the provisions of the parties authorizing the creation of the
model.
Digital 3D archives of archaeological artifacts are another example
of 3D models often requiring piracy protection. Curators of such
artifact collections are increasingly turning to 3D digitization as a
way to preserve and widen scholarly usage of their holdings, by allowing
virtual display and object examination over the Internet, for
example. However, the owners and maintainers of the artifacts often
desire to maintain strict control over the use of the 3D data and
to guard against theft. An example of such a collection is [Stanford
Digital Forma Urbis Project 2004], in which over one thousand
fragments of an ancient Roman map were digitized and are being
made available through a web-based database, providing that the
3D models can be adequately protected.
Other application areas such as entertainment and online commerce
may also require protection for 3D graphics content. 3D character
models developed for use in motion pictures are often repurposed
for widespread use in video games and promotional materials. Such
models represent valuable intellectual property, and solutions for
preventing their piracy from these interactive applications would be
very useful. In some cases, such as 3D body scans of high profile
actors, content developers may be reluctant to distribute the 3D
models without sufficient control over reuse. In the area of online
commerce, a number of Internet content developers have reported
an unwillingness of clients to pursue 3D graphics projects specifically
due to the lack of ability to prevent theft of the 3D content
[Ressler 2001].
Prior technical research in the area of intellectual property protections
for 3D data has primarily concentrated on 3D digital watermarking
techniques. Over 30 papers in the last 7 years describe
steganographic approaches to embedding hidden information into
3D graphical models, with varying degrees of robustness to attacks
that seek to disable watermarks through alterations to the 3D shape
or data representation. Many of the most successful 3D watermarking
schemes are based on spread-spectrum frequency domain
transformations, which embed watermarks at multiple scales by introducing
controlled perturbations into the coordinates of the 3D
model vertices [Praun et al. 1999; Ohbuchi et al. 2002]. Complementary
technologies search collections of 3D models and examine
them for the presence of digital watermarks, in an effort to detect
piracy.
We believe that for the digital representations of highly valuable
3D objects such as cultural heritage artifacts, it is not sufficient to
detect piracy after the fact; we must instead prevent it. The computer
industry has experimented with a number of techniques for
preventing unauthorized use and copying of computer software and
digital data. These techniques have included physical dongles, software
access keys, node-locked licensing schemes, copy prevention
software, program and data obfuscation, and encryption with embedded
keys. Most such schemes are either broken or bypassed by
determined attackers, and cause undue inconvenience and expense
for non-malicious users. High-profile data and software is particularly
susceptible to being quickly targeted by attackers.
695
© 2004 ACM 0730-0301/04/0800-0695 $5.00
Fortunately, 3D graphics data differs from most other forms of digital
media in that the presentation format, 2D images, is fundamen-tally
different from the underlying representation (3D geometry).
Usually, 3D graphics data is displayed as a projection onto a 2D
display device, resulting in tremendous information loss for single
views. This property supports an optimistic view that 3D graphics
systems can be designed that maintain usability and utility, while
not being as vulnerable to piracy as other types of digital content.
In this paper, we address the problem of preventing the piracy of 3D
models, while still allowing for their interactive display and manipulation
. Specifically, we attempt to provide a solution for maintainers
of large collections of high-resolution static 3D models, such as
the digitized cultural heritage artifacts described above. The methods
we develop aim to protect both the geometric shape of the 3D
models, as well as their particular geometric representation, such
as the 3D mesh vertex coordinates, surface normals, and connectivity
information. We accept that the coarse shape of visible objects
can be easily reproduced regardless of our protection efforts, so we
concentrate on defending the high-resolution geometric details of
3D models, which may have been most expensive to model or measure
(perhaps requiring special access and advanced 3D digitizing
technology), and which are most valuable in exhibiting fidelity to
the original object.
In the following paper sections, we first examine the graphics
pipeline to identify its possible points of attack, and then propose
several possible techniques for protecting 3D graphics data from
such attacks. Our experimentation with these techniques led us to
conclude that remote rendering provides the best solution for protecting
3D graphical models, and we describe the design and implementation
of a prototype system in Section 4. Section 5 describes
some types of reconstruction attacks against such a remote rendering
system and the initial results of our efforts to guard against
them.
Possible Attacks in the Graphics Pipeline
Figure 1 shows a simple abstraction of the graphics pipeline for
purposes of identifying possible attacks to recover 3D geometry.
We note several places in the pipeline where attacks may occur:
3D model file reverse-engineering. Fig. 1(a). 3D graphics models
are typically distributed to users in data streams such as files in
common file formats. One approach to protecting the data is to
obfuscate or encrypt the data file. If the user has full access to the
data file, such encryptions can be reverse-engineered and broken,
and the 3D geometry data is then completely unprotected.
Tampering with the viewing application. Fig. 1(b). A 3D viewer
application is typically used to display the 3D model and allow for
its manipulation. Techniques such program tracing, memory dumping
, and code replacement are practiced by attackers to obtain access
to data in use by application programs.
Graphics driver tampering. Fig. 1(c). Because the 3D geometry
usually passes through the graphics driver software on its way to
the GPU, the driver is vulnerable to tampering. Attackers can replace
graphics drivers with malicious or instrumented versions to
capture streams of 3D vertex data, for example. Such replacement
drivers are widely distributed for purposes of tracing and debugging
graphics programs.
Reconstruction from the framebuffer. Fig. 1(d). Because the
framebuffer holds the result of the rendered scene, its contents can
be used by sophisticated attackers to reconstruct the model geometry
, using computer vision 3D reconstruction techniques. The
Figure 1: Abstracted graphics pipeline showing possible attack locations
(a-e). These attacks are described in the text.
framebuffer contents may even include depth values for each pixel,
and attackers may have precise control over the rendering parameters
used to create the scene (viewing and projection transformations
, lighting, etc.). This potentially creates a perfect opportunity
for computer vision reconstruction, as the synthetic model data and
controlled parameters do not suffer from the noise, calibration, and
imprecision problems that make robust real world vision with real
sensors very difficult.
Reconstruction from the final image display. Fig. 1(e). Regardless
of whatever protections a graphics system can guarantee
throughout the pipeline, the rendered images finally displayed to
the user are accessible to attackers. Just as audio signals may be
recorded by external devices when sound is played through speakers
, the video signals or images displayed on a computer monitor
may be recorded with a variety of video devices. The images so
gathered may be used as input to computer vision reconstruction
attacks such as those possible when the attacker has access to the
framebuffer itself, though the images may be of degraded quality,
unless a perfect digital video signal (such as DVI) is available.
Techniques for Protecting 3D Graphics
In light of the possible attacks in the graphics pipeline as described
in the previous section, we have considered a number of approaches
for sharing and rendering protected 3D graphics.
Software-only rendering. A 3D graphics viewing system that does
not make use of hardware acceleration may be easier to protect from
the application programmer's point of view. Displaying graphics
with a GPU can require transferring the graphics data in precisely
known and open formats, through a graphics driver and hardware
path that is often out of the programmer's control. A custom 3D
viewing application with software rendering allows the 3D content
distributor to encrypt or obfuscate the data in a specific manner, all
the way through the graphics pipeline until display.
Hybrid hardware/software rendering. Hybrid hardware and software
rendering schemes can be used to take at least some advantage
of hardware accelerated rendering, while benefiting from software
rendering's protections as described above. In one such scheme, a
small but critically important portion of a protected model's geometry
(such as the nose of a face) is rendered in software, while the
rest of the model is rendered normally with the accelerated GPU
hardware. This technique serves as a deterrent to attackers tampering
with the graphics drivers or hardware path, but the two-phase
drawing with readback of the color and depth buffers can incur a
696
performance hit, and may require special treatment to avoid artifacts
on the border of the composition of the two images.
In another hybrid rendering scheme, the 3D geometry is transformed
and per-vertex lighting computations are performed in software
. The depth values computed for each vertex are distorted in
a manner that still preserves the correct relative depth ordering,
while concealing the actual model geometry as much as possible.
The GPU is then used to complete rendering, performing rasteri-zation
, texturing, etc. Such a technique potentially keeps the 3D
vertex stream hidden from attackers, but the distortions of the depth
buffer values may impair certain graphics operations (fog computation
, some shadow techniques), and the geometry may need to be
coarsely depth sorted so that Z-interpolation can still be performed
in a linear space.
Deformations of the geometry. Small deformations in large 2D
images displayed on the Internet are sometimes used as a defense
against image theft; zoomed higher resolution sub-images with
varying deformations cannot be captured and easily reassembled
into a whole. A similar idea can be used with 3D data: subtle 3D
deformations are applied to geometry before the vertices are passed
to the graphics driver. The deformations are chosen so as to vary
smoothly as the view of the model changes, and to prohibit recovery
of the original coordinates by averaging the deformations over
time. Even if an attacker is able to access the stream of 3D data after
it is deformed, they will encounter great difficulty reconstructing
a high-resolution version of the whole model due to the distortions
that have been introduced.
Hardware decryption in the GPU. One sound approach to providing
for protected 3D graphics is to encrypt the 3D model data with
public-key encryption at creation time, and then implement custom
GPUs that accept encrypted data, and perform on-chip decryption
and rendering. Additional system-level protections would need to
be implemented to prevent readback of framebuffer and other video
memory, and to place potential restrictions on the command stream
sent to the GPU, in order to prevent recovery of the 3D data.
Image-based rendering. Since our goal is to protect the 3D geometry
of graphic models, one technique is to distribute the models
using image-based representations, which do not explicitly include
the complete geometry data. Examples of such representations
include light fields and Lumigraphs [Levoy and Hanrahan
1996; Gortler et al. 1996], both of which are highly amenable to
interactive display.
Remote rendering. A final approach to secure 3D graphics is to
retain the 3D model data on a secure server, under the control of
the content owner, and pass only 2D rendered images of the models
back to client requests. Very low-resolution versions of the models,
for which piracy is not a concern, can be distributed with special
client programs to allow for interactive performance during manipulation
of the 3D model. This method relies on good network
bandwidth between the client and server, and may require significant
server resources to do the rendering for all client requests, but
it is vulnerable primarily only to reconstruction attacks.
Discussion. We have experimented with several of the 3D model
protection approaches described above. For example, our first protected
3D model viewer was an encrypted version of the "QS-plat"
[Rusinkiewicz and Levoy 2000] point-based rendering system
, which omits geometric connectivity information.
The 3D
model files were encrypted using a strong symmetric block cipher
scheme, and the decryption key was hidden in a heavily obfuscated
3D model viewer program, using modern program obfuscation
techniques [Collberg and Thomborson 2000]. Vertex data was
decrypted on demand during rendering, so that only a very small
portion of the decrypted model was ever in memory, and only software
rendering modes were used.
Unfortunately, systems such as this ultimately rely on "security
through obfuscation," which is theoretically unsound from a computer
security point of view. Given enough time and resources, an
attacker will be able to discover the embedded encryption key or
otherwise reverse-engineer the protections on the 3D data. For this
reason, any of the 3D graphics protection techniques that make the
actual 3D data available to potential attackers in software can be
broken [Schneier 2000]. It is possible that future "trusted comput-ing"
platforms for general purpose computers will be available that
make software tampering difficult or impossible, but such systems
are not widely deployed today. Similarly, the idea of a GPU with
decryption capability has theoretical merit, but it will be some years
before such hardware is widely available for standard PC computing
environments, if ever.
Thus, for providing practical, robust, anti-piracy protections for 3D
data, we gave strongest consideration to purely image-based representations
and to remote rendering. Distributing light fields at
the high resolutions necessary would involve huge, unwieldy file
sizes, would not allow for any geometric operations on the data
(such as surface measurements performed by archaeologists), and
would still give attackers unlimited access to the light field for purposes
of performing 3D reconstruction attacks using computer vision
algorithms. For these reasons, we finally concluded that the
last technique, remote rendering, offers the best solution for protecting
interactive 3D graphics content.
Remote rendering has been used before in networked environments
for 3D visualization, although we are not aware of a system specifically
designed to use remote rendering for purposes of security
and 3D content protection. Remote rendering systems have been
previously implemented to take advantage of off-site specialized
rendering capabilities not available in client systems, such as intensive
volume rendering [Engel et al. 2000], and researchers have
developed special algorithmic approaches to support efficient distribution
of rendering loads and data transmission between rendering
servers and clients [Levoy 1995; Yoon and Neumann 2000].
Remote rendering of 2D graphical content is common for Internet
services such as online map sites; only small portions of the whole
database are viewed by users at one time, and protection of the entire
2D data corpus from theft via image harvesting may be a factor
in the design of these systems.
Remote Rendering System
To test our ideas for providing controlled, protected interactive access
to collections of 3D graphics models, we have implemented
a remote rendering system with a client-server architecture, as described
below.
4.1
Client Description
Users of our protected graphics system employ a specially-designed
3D viewing program to interactively view protected 3D content
.
This client program is implemented as an OpenGL and
wxWindows-based 3D viewer, with menus and GUI dialogs to control
various viewing and networking parameters (Figure 2). The
client program includes very low-resolution, decimated versions of
the 3D models, which can be interactively rotated, zoomed, and re-lit
by the user in real-time. When the user stops manipulating the
low-resolution model, detected via a "mouse up" event, the client
program queries the remote rendering server via the network for a
697
Figure 2: Screenshot of the client program.
high-resolution rendered image corresponding to the selected rendering
parameters. These parameters include the 3D model name,
viewpoint position and orientation, and lighting conditions. When
the server passes the rendered image back to the client program, it
replaces the low-resolution rendering seen by the user (Figure 3).
On computer networks with reasonably low latencies, the user thus
has the impression of manipulating a high-resolution version of
the model. In typical usage for cultural heritage artifacts, we use
models with approximately 10,000 polygons for the low resolution
version, whereas the server-side models often contain tens of millions
polygons. Such low-resolution model complexities are of little
value to potential thieves, yet still provide enough clues for the
user to navigate. The client viewer could be further extended to
cache the most recent images returned from the server and projec-tively
texture map them onto the low-resolution model as long as
they remain valid during subsequent rotation and zooming actions.
4.2
Server Description
The remote rendering server receives rendering requests from
users' client programs, renders corresponding images, and passes
them back to the clients. The rendering server is implemented as
a module running under the Apache 2.0 HTTP Server; as such,
the module communicates with client programs using the standard
HTTP protocol, and takes advantage of the wide variety of access
protection and monitoring tools built into Apache. The rendering
server module is based upon the FastCGI Apache module, and allows
for multiple rendering processes to be spread across any number
of server hardware nodes.
As render requests are received from clients, the rendering server
checks their validity and dispatches the valid requests to a GPU for
OpenGL hardware-accelerated rendering. The rendered images are
read back from the framebuffer, compressed using JPEG compression
, and returned to the client. If multiple requests from the same
client are pending (such as if the user rapidly changes views while
on a slow network), earlier requests are discarded, and only the
most recent is rendered. The server uses level-of-detail techniques
to speed the rendering of highly complex models, and lower level-of
-detail renderings can be used during times of high server load
to maintain high throughput rates. In practice, an individual server
node with a Pentium 4 CPU and an NVIDIA GeForce4 video card
can handle a maximum of 8 typical client requests per second; the
Figure 3: Client-side low resolution (left) and server-side high resolution
(right) model renderings.
bottlenecks are in the rendering and readback (about 100 milliseconds
), and in the JPEG compression (approximately 25 milliseconds
). Incoming request sizes are about 700 bytes each, and the
images returned from our deployed servers average 30 kB per request
.
4.3
Server Defenses
In Section 2, we enumerated several possible places in the graphics
pipeline that an attacker could steal 3D graphics data. The benefit of
using remote rendering is that it leaves only 3D reconstruction from
2D images in the framebuffer or display device as possible attacks.
General 3D reconstruction from images constitutes a very difficult
computer vision problem, as evidenced by the great amount of research
effort being expended to design and build robust computer
vision systems. However, synthetic 3D graphics renderings can be
particularly susceptible to reconstruction because the attacker may
be able to exactly specify the parameters used to create the images,
there is a low human cost to harvest a large number of images, and
synthetic images are potentially perfect, with no sensor noise or
miscalibration errors. Thus, it is still necessary to defend the remote
rendering system from reconstruction attacks; below, we describe a
number of such defenses that we have implemented in combination
for our server.
Session-based defenses. Client programs that access the remote
rendering system are uniquely identified during the course of a usage
session. This allows the server to monitor and track the specific
sequence of rendering requests made by each client. Automatic
analysis of the server logs allows suspicious request streams to be
classified, such as an unusually high number of requests per unit
time, or a particular pattern of requests that is indicative of an image
harvesting program. High quality computer vision reconstructions
often require a large number of images that densely sample
the space of possible views, so we are able to effectively identify
such access patterns and terminate service to those clients. We can
optionally require recurrent user authentication in order to further
deter some image harvesting attacks, although a coalition of users
mounting a low-rate distributed attack from multiple IP addresses
could still defeat such session-based defenses.
Obfuscation. Although we do not rely on obfuscation to protect the
3D model data, we do use obfuscation techniques on the client side
of the system to discourage and slow down certain attacks. The
low-resolution models that are distributed with the client viewer
program are encrypted using an RC4-variant stream cipher, and the
keys are embedded in the viewer and heavily obfuscated. The rendering
request messages sent from the client to the server are also
encrypted with heavily obfuscated keys. These encryptions simply
serve as another line of defense; even if they were broken, attackers
would still not be able to gain access to the high resolution 3D data
except through reconstruction from 2D images.
698
Limitations on valid rendering requests. As a further defense,
we provide the capability in our client and remote server to constrain
the viewing conditions. Some models may have particular
"stayout" regions defined that disallow certain viewing and lighting
angles, thus keeping attackers from being able to reconstruct a
complete model. For the particular purpose of defending against the
enumeration attacks described in Section 5.1, we put restrictions on
the class of projection transformations allowed to be requested by
users (requiring a perspective projection with particular fixed field
of view and near and far planes), and we prevent viewpoints within
a small offset of the model surface.
Perturbations and distortions. Passive 3D computer vision reconstructions
of real-world objects from real-world images are usually
of relatively poor quality compared to the original object. This failure
inspires the belief that we can protect our synthetically rendered
models from reconstruction by introducing into the images the same
types of obstacles known to plague vision algorithms. The particular
perturbations and distortions that we use are described below;
we apply these defenses to the images only to the degree that they
do not distract the user viewing the models. Additionally, these defenses
are applied in a pseudorandomly generated manner for each
different rendering request, so that attackers cannot systematically
determine and reverse their effects, even if the specific form of the
defenses applied is known (such as if the source code for the rendering
server is available). Rendering requests with identical parameters
are mapped to the same set of perturbations, in order to
deter attacks which attempt to defeat these defenses by averaging
multiple images obtained under the same viewing conditions.
· Perturbed viewing parameters We pseudorandomly introduce
subtle perturbations into the view transformation matrix
for the images rendered by the server; these perturbations
have the effect of slightly rotating, translating, scaling, and
shearing the model. The range of these distortions is bounded
such that no point in the rendered image is further than either
m
object space units or n pixels from its corresponding point
in an unperturbed view. In practice, we generally set m proportional
to the size of the model's geometry being protected,
and use values of n = 15 pixels, as experience has shown that
users can be distracted by larger shifts between consecutively
displayed images.
· Perturbed lighting parameters We pseudorandomly introduce
subtle perturbations into the lighting parameters used
to render the images; these perturbations include modifying
the lighting direction specified in the client request, as well
as addition of randomly changing secondary lighting to illuminate
the model. Users are somewhat sensitive to shifts in
the overall scene intensity and shading, so the primary light
direction perturbations used are generally fairly small (maximum
of 10

for typical models, which are rendered using the
OpenGL local lighting model).
· High-frequency noise added to the images We introduce
two types of high-frequency noise artifacts into the rendered
images. The first, JPEG artifacts, are a convenient result of
the compression scheme applied to the images returned from
the server. At high compression levels (we use a maximum
libjpeg quality factor of 50), the quantization of DCT coefficients
used in JPEG compression creates "blocking" discontinuities
in the images, and adds noise in areas of sharp contrast.
These artifacts create problems for low-level computer vision
image processing algorithms, while the design of JPEG compression
specifically seeks to minimize the overall perceptual
loss of image quality for human users.
Additionally, we add pseudorandomly generated monochromatic
Gaussian noise to the images, implemented efficiently
by blending noise textures during hardware rendering on the
server. The added noise defends against computer vision attacks
by making background segmentation more difficult, and
by breaking up the highly regular shading patterns of the synthetic
renderings. Interestingly, users are not generally distracted
by the added noise, but have even commented that the
rendered models often appear "more realistic" with the high-frequency
variations caused by the noise. One drawback of
the added noise is that the increased entropy of the images can
result in significantly larger compressed file sizes; we address
this in part by primarily limiting the application of noise to the
non-background regions of the image via stenciled rendering.
· Low-frequency image distortions Just as real computer vision
lens and sensor systems sometimes suffer from image
distortions due to miscalibration, we can effectively simulate
and extend these distortions in the rendering server. Subtle
non-linear radial distortions, pinching, and low-frequency
waves can be efficiently implemented with vertex shaders, or
with two-pass rendering of the image as a texture onto a non-uniform
mesh, accelerated with the "render to texture" capabilities
of modern graphics hardware.
Due to the variety of random perturbations and distortions that are
applied to the images returned from the rendering server, there is
a risk of distracting the user, as the rendered 3D model exhibits
changes from frame to frame, even when the user makes very minor
adjustments to the view. However, we have found that the
brief switch to the lower resolution model in between display of the
high resolution perturbed images, inherent to our remote rendering
scheme, very effectively masks these changes. This masking of
changes is attributed to the visual perception phenomenon known
as change blindness [Simons and Levin 1997], in which significant
changes occurring in full view are not noticed due to a brief disruption
in visual continuity, such as a "flicker" introduced between
successive images.
Reconstruction Attacks
In this section we consider several classes of attacks, in which sets
of images may be gathered from our remote rendering server to
make 3D reconstructions of the model, and we analyze their efficacy
against the countermeasures we have implemented.
5.1
Enumeration Attacks
The rendering server responds to rendering requests from users
specifying the viewing conditions for the rendered images. This
ability for precise specification can be exploited by attackers, as
they can potentially explore the entire 3D model space, using the returned
images to discover the location of the 3D model to any arbitrary
precision. In practice, these attacks involve enumerating many
small cells in a voxel grid, and testing each such voxel to determine
intersection with the remote high-resolution model's surface; thus
we term them enumeration attacks. Once this enumeration process
is complete, occupied cells of the voxel grid are exported as a point
cloud and then input to a surface reconstruction algorithm.
In the plane sweep enumeration attack, the view frustum is specified
as a rectangular, one-voxel-thick "plane," and is swept over the
model (Figure 4(a)). Each requested image represents one slice of
the model's su