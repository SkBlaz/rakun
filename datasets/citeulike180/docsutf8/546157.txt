An fMRI Investigation of Emotional Engagement in Moral Judgment Joshua D. Greene, et al. Science 293, 2105 (2001); DOI: 10.1126/science.1062872 The following resources related to this article are available online at www.sciencemag.org (this information is current as of May 7, 2008 ):
Updated information and services, including high-resolution figures, can be found in the online version of this article at: http://www.sciencemag.org/cgi/content/full/293/5537/2105 Supporting Online Material can be found at: http://www.sciencemag.org/cgi/content/full/293/5537/2105/DC1 This article cites 10 articles, 2 of which can be accessed for free: http://www.sciencemag.org/cgi/content/full/293/5537/2105#otherarticles This article has been cited by 238 article(s) on the ISI Web of Science. This article has been cited by 45 articles hosted by HighWire Press; see: http://www.sciencemag.org/cgi/content/full/293/5537/2105#otherarticles This article appears in the following subject collections: Psychology http://www.sciencemag.org/cgi/collection/psychology Information about obtaining reprints of this article or about obtaining permission to reproduce this article in whole or in part can be found at: http://www.sciencemag.org/about/permissions.dtl

Science (print ISSN 0036-8075; online ISSN 1095-9203) is published weekly, except the last week in December, by the American Association for the Advancement of Science, 1200 New York Avenue NW, Washington, DC 20005. Copyright 2001 by the American Association for the Advancement of Science; all rights reserved. The title Science is a registered trademark of AAAS.

Downloaded from www.sciencemag.org on May 7, 2008

REPORTS
matic assays using a wide range of in vitro conditions. Furthermore, once the proteins are prepared, proteome screening is significantly faster and cheaper. Using similar procedures, it is clearly possible to prepare protein arrays of 10 to 100,000 proteins for global proteome analysis in humans and other eukaryotes.
1. S. Fields, Y. Kohara, D. J. Lockhart, Proc. Natl. Acad. Sci. U.S.A. 96, 8825 (1999); A. Goffeau et al., Science 274, 546 (1996). 2. P. Ross-Macdonald et al., Nature 402, 413 (1999); J. L. DeRisi, V. R. Iyer, P. O. Brown, Science 278, 680 (1997); E. A. Winzeler et al., Science 285, 901 (1999); P. Uetz et al., Nature 403, 623 (2000); T. Ito et al., Proc. Natl. Acad. Sci. U.S.A. 97, 1143 (2000). 3. H. Zhu, M. Snyder, Curr. Opin. Chem. Biol. 5, 40 (2001). 4. M. R. Martzen et al., Science 286, 1153 (1999). 5. H. Zhu et al., Nature Genet. 26, 283 (2000). 6. G. MacBeath, S. L. Schreiber, Science 289, 1760 (2000). 7. A. Caveman, J. Cell Sci. 113, 3543 (2000). 8. P. Arenkov et al., Anal. Biochem. 278, 123 (2000). 9. D. A. Mitchell, T. K. Marshall, R. J. Deschenes, Yeast 9, 715 (1993). The expression vector pEGH was created by inserting an RGS-HisX6 epitope tag between the GST gene and the polycloning site of pEG(KG). The yeast ORFs were cloned using the strategy described previously (5), except every step was done in a 96-well format. Plasmid DNAs confirmed by DNA sequencing were reintroduced into both yeast ( Y258) and E. coli (DH5 ). The library contains 5800 unique ORFs. 10. For details of 96-well format protein purification protocol, a full list of results from all the experiments, and the design of the positive identification algorithms, please visit our public Web site (http:// bioinfo.mbb.yale.edu/proteinchip) and supplementary material at Science Online (www.sciencemag.org/ cgi/content/full/1062191/DC1). 11. Biotinylated calmodulin (CalBiochem, USA) was added to the proteome chip at 0.02 g/ l in phosphatebuffered saline (PBS) with 0.1 mM calcium and incubated in a humidity chamber for 1 hour at room temperature. Calcium (0.1 mM) was present in buffers in all subsequent steps. The chip was washed three times with PBS at room temperature (RT, 25°C). Cy3-conjugated streptavidin ( Jackson IR, USA) (1: 5000 dilution) was added to the chip and incubated for 30 min at RT. After extensive washing, the chip was spun dry and scanned using a microarray scanner; the data was subsequently acquired with the GenePix array densitometry software (Axon, USA). 12. S. S. Hook, A. R. Means, Annu. Rev. Pharmacol. Toxicol. 41, 471 (2001). 13. M. S. Cyert, R. Kunisawa, D. Kaim, J. Thorner, Proc. Natl. Acad. Sci. U.S.A. 88, 7376 (1991). 14. D. A. Stirling, K. A. Welch, M. J. Stark, EMBO J. 13, 4329 (1994). 15. F. Bohl, C. Kruse, A. Frank, D. Ferring, R. P. Jansen, EMBO J. 19, 5514 (2000); E. Bertrand et al., Mol. Cell 2, 437 (1998). 16. D. C. Winter, E. Y. Choe, R. Li, Proc. Natl. Acad. Sci. U.S.A. 96, 7288 (1999). 17. C. Schaerer-Brodbeck, H. Riezman, Mol. Biol. Cell 11, 1113 (2000). 18. K. Homma, J. Saito, R. Ikebe, M. Ikebe, J. Biol. Chem. 275, 34766 (2000). 19. J. Menendez, J. Delgado, C. Gancedo, Yeast 14, 647 (1998). 20. G. Odorizzi, M. Babst, S. D. Emr, Trends Biochem. Sci. 25, 229 (2000); D. A. Fruman et al., Annu. Rev. Biochem. 67, 481 (1998); T. F. Martin, Annu. Rev. Cell Dev. Biol. 14, 231 (2000); S. Wera, J. C. T. Bergsma, FEMS Yeast Res. 1, 1406 (2001). 21. Liposomes were prepared using standard methods (30). Briefly, appropriate amounts of each lipid in chloroform were mixed and dried under nitrogen. The lipid mixture was resuspended in TBS buffer by vortexing. The liposomes were created by sonication. To probe the proteome chips, 60 l of the different liposomes were added onto different chips. The chips were incubated in a humidity chamber for 1 hour at RT. After washing with TBS buffer for three times, Cy3-conjugated streptavidin (1: 5000 dilution) was added to the chip and incubated for 30 min at RT. Positives were identified using a combination of the GenePix software which computes a local intensity background for each spot and a series of algorithms we developed. Details can be found at http://bioinfo.mbb.yale.edu/proteinchip and at www.sciencemag.org/cgi/content/full/1062191/ DC1. M. C. Costanzo et al., Nucleic Acids Res. 29, 75 (2001). M. Gerstein, Proteins 33, 518 (1998). K. Ansari et al., J. Biol. Chem. 274, 30052 (1999). Y. Barral, M. Parra, S. Bidlingmaier, M. Snyder, Genes Dev. 13, 176 (1999). Y. Li, T. Kane, C. Tipper, P. Spatrick, D. D. Jenness, Mol. Cell. Biol. 19, 3588 (1999). I. Arnold et al., J. Biol. Chem. 274, 36 (1999). 29. S. Chu et al., Science 282, 699 (1998). 30. A. Casamayor et al., Curr. Biol. 9, 186 (1999); R. Guerra, M. L. Bianconi, Biosci. Rep. 20, 41 (2000). 31. M. Pardo et al., Yeast 15, 459 (1999). 32. Single-letter abbreviations for the amino acid residues are as follows: A, Ala; C, Cys; D, Asp; E, Glu; F, Phe; G, Gly; H, His; I, Ile; K, Lys; L, Leu; M, Met; N, Asn; P, Pro; Q, Gln; R, Arg; S, Ser; T, Thr; V, Val; W, Trp; and Y, Tyr. X indicates any residue. 33. We thank K. Nelson and S. Dellaporta for providing invaluable help. We also thank A. Kumar, G. Michaud, and C. Costigan for providing comments on the manuscript. This research is supported by grants from NIH. H.Z., A.C., and R.J. were supported by postdoctoral fellowships from the Damon Runyon­Walter Winchell Foundation, the Spanish Ministerio de Ciencia y Tecnologia, and by an IBM Graduate Research Fellowship, respectively. 2 May 2001; accepted 13 July 2001 Published online 26 July 2001; 10.1126/science.1062191 Include this information when citing this paper.

22.

References and Notes

23. 24. 25. 26. 27. 28.

An fMRI Investigation of Emotional Engagement in Moral Judgment
Joshua D. Greene,1,2* R. Brian Sommerville,1 Leigh E. Nystrom,1,3 John M. Darley,3 Jonathan D. Cohen1,3,4
The long-standing rationalist tradition in moral psychology emphasizes the role of reason in moral judgment. A more recent trend places increased emphasis on emotion. Although both reason and emotion are likely to play important roles in moral judgment, relatively little is known about their neural correlates, the nature of their interaction, and the factors that modulate their respective behavioral influences in the context of moral judgment. In two functional magnetic resonance imaging (fMRI) studies using moral dilemmas as probes, we apply the methods of cognitive neuroscience to the study of moral judgment. We argue that moral dilemmas vary systematically in the extent to which they engage emotional processing and that these variations in emotional engagement influence moral judgment. These results may shed light on some puzzling patterns in moral judgment observed by contemporary philosophers. The present study was inspired by a family of ethical dilemmas familiar to contemporary moral philosophers (1). One such dilemma is the trolley dilemma: A runaway trolley is headed for five people who will be killed if it proceeds on its present course. The only way to save them is to hit a switch that will turn the trolley onto an alternate set of tracks where it will kill one person instead of five. Ought you to turn the trolley in order to save five people at the expense of one? Most people say yes. Now consider a similar problem, the footbridge dilemma. As before, a trolley threatens to kill five people. You are
Center for the Study of Brain, Mind, and Behavior, Department of Philosophy, 1879 Hall, 3Department of Psychology, Green Hall, Princeton University, Princeton, NJ 08544, USA. 4Department of Psychiatry, University of Pittsburgh, Pittsburgh, PA 15260, USA.
1 2

*To whom correspondence should be addressed. Email: jdgreene@princeton.edu

standing next to a large stranger on a footbridge that spans the tracks, in between the oncoming trolley and the five people. In this scenario, the only way to save the five people is to push this stranger off the bridge, onto the tracks below. He will die if you do this, but his body will stop the trolley from reaching the others. Ought you to save the five others by pushing this stranger to his death? Most people say no. Taken together, these two dilemmas create a puzzle for moral philosophers: What makes it morally acceptable to sacrifice one life to save five in the trolley dilemma but not in the footbridge dilemma? Many answers have been proposed. For example, one might suggest, in a Kantian vein, that the difference between these two cases lies in the fact that in the footbridge dilemma one literally uses a fellow human being as a means to some independent end, whereas in the trolley dilemma the unfortunate person just happens to

www.sciencemag.org SCIENCE VOL 293 14 SEPTEMBER 2001

2105

Downloaded from www.sciencemag.org on May 7, 2008

REPORTS
be in the way. This answer, however, runs into trouble with a variant of the trolley dilemma in which the track leading to the one person loops around to connect with the track leading to the five people (1). Here we will suppose that without a body on the alternate track, the trolley would, if turned that way, make its way to the other track and kill the five people as well. In this variant, as in the footbridge dilemma, you would use someone's body to stop the trolley from killing the five. Most agree, nevertheless, that it is still appropriate to turn the trolley in this case in spite of the fact that here, too, we have a case of "using." These are just one proposed solution and one counterexample, but together they illustrate the sort of dialectical difficulties that all proposed solutions to this problem have encountered. If a solution to this problem exists, it is not obvious. That is, there is no set of consistent, readily accessible moral principles that captures people's intuitions concerning what behavior is or is not appropriate in these and similar cases. This leaves psychologists with a puzzle of their own: How is it that nearly everyone manages to conclude that it is acceptable to sacrifice one life for five in the trolley dilemma but not in the footbridge dilemma, in spite of the fact that a satisfying justification for distinguishing between these two cases is remarkably difficult to find (2)? We maintain that, from a psychological point of view, the crucial difference between the trolley dilemma and the footbridge dilemma lies in the latter's tendency to engage people's emotions in a way that the former does not. The thought of pushing someone to his death is, we propose, more emotionally salient than the thought of hitting a switch that will cause a trolley to produce similar consequences, and it is this emotional response that accounts for people's tendency to treat these cases differently. This hypothesis concerning these two cases suggests a more general hypothesis concerning moral judgment: Some moral dilemmas (those relevantly similar to the footbridge dilemma) engage emotional processing to a greater extent than others (those relevantly similar to the trolley dilemma), and these differences in emotional engagement affect people's judgments. The present investigation is an attempt to test this more general hypothesis. Drawing upon recent work concerning the neural correlates of emotion (3­5), we predicted that brain areas associated with emotion would be more active during contemplation of dilemmas such as the footbridge dilemma as compared to during contemplation of dilemmas such as the trolley dilemma. In addition, we predicted a pattern of behavioral interference similar to that observed in cognitive tasks in which automatic processes can influence responses, such as the Stroop task (in which the identity of a color word can interfere with participants' ability to name the color in which it is displayed; e.g., the ability to say "green" in response to the word "red" written in green ink) (6, 7 ). In light of our proposal that people tend to have a salient, automatic emotional response to the footbridge dilemma that leads them to judge the action it proposes to be inappropriate, we would expect those (relatively rare) individuals who nevertheless judge this action to be appropriate to do so against a countervailing emotional response and to exhibit longer reaction times as a result of this emotional interference. More generally, we predicted longer reaction times for trials in which the participant's response is incongruent with the emotional response (e.g., saying "appropriate" to a dilemma such as the footbridge dilemma). We predicted the absence of such effects for dilemmas such as the trolley dilemma which, according to our theory, are less likely to elicit a strong emotional response. In each of two studies, Experiments 1 and 2, we used a battery of 60 practical dilemmas (8). These dilemmas were divided into "moral" and "non-moral" categories on the basis of the responses of pilot participants (8). (Typical examples of non-moral dilemmas posed questions about whether to travel by bus or by train given certain time constraints and about which of two coupons to use at a store.) Two independent coders evaluated each moral dilemma using three criteria designed to capture the difference between the intuitively "up close and personal" (and putatively more emotional) sort of violation exhibited by the footbridge dilemma and the more intuitively impersonal (and putatively less emotional) violation exhibited by the trolley dilemma (8, 9). Moral dilemmas meeting these criteria were assigned to the "moralpersonal" condition, the others to the "moralimpersonal" condition. Typical moral-personal dilemmas included a version of the footbridge dilemma, a case of stealing one person's organs in order to distribute them to five others, and a case of throwing people off a sinking lifeboat. Typical moral-impersonal dilemmas included a version of the trolley dilemma, a case of keeping money found in a lost wallet, and a case of voting for a policy expected to cause more deaths than its alternatives. Participants responded to each dilemma by indicating whether they judged the action it proposes to be "appropriate" or "inappropriate." In each experiment, nine participants (10) responded to each of 60 dilemmas (11) while undergoing brain scanning using f MRI (12). Figures 1 and 2 describe brain areas identified in Experiment 1 by a thresholded omnibus analysis of variance (ANOVA) performed on the functional images (13). In each case, the

Fig. 1. Effect of condition on activity in brain areas identified in Experiment 1. R, right; L, left; B, bilateral. Results for the middle frontal gyrus were not replicated in Experiment 2. The moral-personal condition was significantly different from the other two conditions in all other areas in both Experiments 1 and 2. In Experiment 1 the medial frontal and posterior cingulate gyri showed significant differences between the moral-impersonal and non-moral conditions. In Experiment 2 only the posterior cingulate gyrus was significantly different in this comparison. Brodmann's Areas and Talairach (28) coordinates (x, y, z) for each area are as follows (left to right in graph): 9/10 (1, 52, 17); 31 (­ 4, ­54, 35); 46 (45, 36, 24); 7/40 (­ 48, ­ 65, 26); 7/40 (50, ­57, 20). Fig. 2. Brain areas exhibiting differences in activity between conditions shown in three axial slices of a standard brain (28). Slice location is indicated by Talairach (28) z coordinate. Data are for the main effect of condition in Experiment 1. Colored areas reflect the thresholded F scores. Images are reversed left to right to follow radiologic convention.

2106

14 SEPTEMBER 2001 VOL 293 SCIENCE www.sciencemag.org

Downloaded from www.sciencemag.org on May 7, 2008

REPORTS
ANOVA identified all brain areas differing in activity among the moral-personal, moral-impersonal, and non-moral conditions. Planned comparisons on these areas revealed that medial portions of Brodmann's Areas (BA) 9 and 10 (medial frontal gyrus), BA 31 ( posterior cingulate gyrus), and BA 39 (angular gyrus, bilateral) were significantly more active in the moralpersonal condition than in the moral-impersonal and the non-moral conditions. Recent functional imaging studies have associated each of these areas with emotion (5, 14­16). Areas associated with working memory have been found to become less active during emotional processing as compared to periods of cognitive processing (17). BA 46 (middle frontal gyrus, right) and BA 7/40 ( parietal lobe, bilateral)-- both associated with working memory (18, 19)--were significantly less active in the moral-personal condition than in the other two conditions. In BA 39 (bilateral), BA 46, and BA 7/40 (bilateral), there was no significant difference between the moral-impersonal and the non-moral condition (20, 21). Experiment 2 served to replicate the results of Experiment 1 (22) and to provide behavioral data concerning participants' judgments and reaction times. Planned comparisons on the seven brain areas identified in Experiment 1 yielded results nearly identical to those of Experiment 1 with the following differences. In Experiment 2 there was no difference in BA 9/10 between the moral-impersonal and non-moral conditions, and no differences were found for BA 46 (23). Reaction time data from Experiment 2 are described by Fig. 3. Our theory concerning emotional interference predicted longer reaction times for emotionally incongruent responses, which occur when a participant responds "appropriate" in the moral-personal condition (e.g., judging it "appropriate" to push the man off the footbridge in the footbridge dilemma) but which do not occur in the moral-impersonal and non-moral conditions. As predicted, responses of "appropriate" (emotionally incongruent) were significantly slower than responses of "inappropriate" (emotionally congruent) within the moral-personal condition, and there was no significant difference in reaction time between responses of "appropriate" and "inappropriate" in the other two conditions. In fact, the data exhibit a trend in the opposite direction for the other two conditions (24), with responses of "inappropriate" taking slightly longer than responses of "appropriate." In each of the brain areas identified in both Experiments 1 and 2, the moral-personal condition had an effect significantly different from both the moral-impersonal and the non-moral conditions. All three areas showing increased relative activation in the moral-personal condition have been implicated in emotional processing. The behavioral data provide further evidence for the increased emotional engagement in moral-personal condition by revealing a reaction time pattern that is unique to that condition and that was predicted by our hypothesis concerning emotional interference. Moreover, the presence of this interference effect in the behavioral data strongly suggests that the increased emotional responses generated by the moral-personal dilemmas have an influence on and are not merely incidental to moral judgment (25). These data also suggest that, in terms of the psychological processes associated with their production, judgments concerning "impersonal" moral dilemmas more closely resemble judgments concerning non-moral dilemmas than they do judgments concerning "personal" moral dilemmas. The trolley and footbridge dilemmas emerged as pieces of a puzzle for moral philosophers: Why is it acceptable to sacrifice one person to save five others in the trolley dilemma but not in the footbridge dilemma? Here we consider these dilemmas as pieces of a psychological puzzle: How do people manage to conclude that it is acceptable to sacrifice one for the sake of five in one case but not in the other? We maintain that emotional response is likely to be the crucial difference between these two cases. But this is an answer to the psychological puzzle, not the philosophical one. Our conclusion, therefore, is descriptive rather than prescriptive. We do not claim to have shown any actions or judgments to be morally right or wrong. Nor have we argued that emotional response is the sole determinant of judgments concerning moral dilemmas of the kind discussed in this study. On the contrary, the behavioral influence of these emotional responses is most strongly suggested in the performance of those participants who judge in spite of their emotions. What has been demonstrated is that there are systematic variations in the engagement of emotion in moral judgment. The systematic nature of these variations is manifest in an observed correlation between (i) certain features that differ between the trolley dilemma and the footbridge dilemma and (ii) patterns of neural activity in emotion-related brain areas as well as patterns in reaction time. Methodological constraints led us to characterize these "certain features" by means of a highly regimented distinction between actions that are "personal" and "impersonal" (8). This personal-impersonal distinction has proven useful in generating the present results, but it is by no means definitive. We view this distinction as a useful "first cut," an important but preliminary step toward identifying the psychologically essential features of circumstances that engage (or fail to engage) our emotions and that ultimately shape our moral judgments--judgments concerning hypothetical examples such as the trolley and footbridge dilemmas but also concerning the more complicated moral dilemmas we face in our public and private lives. A distinction such as this may allow us to steer a middle course between the traditional rationalism and more recent emotivism that have dominated moral psychology (26 ). The present results raise but do not answer a more general question concerning the relation between the aforementioned philosophical and psychological puzzles: How will a better understanding of the mechanisms that give rise to our moral judgments alter our attitudes toward the moral judgments we make?
1. J. J. Thomson, Rights, Restitution and Risk (Harvard Univ. Press, Cambridge, 1986), pp. 94 ­116. 2. A loose but potentially illuminating analogy can be made between this and the Chomskyan question: How is that most people can speak grammatically without being able to exhaustively cite the rules of grammar? 3. A. R. Damasio, Descartes' Error (Putnam, New York, 1994). 4. R. J. Davidson, W. Irwin, Trends. Cogn Sci. 3, 11 (1999). 5. E. M. Reiman, J. Clin. Psychiatry 58 (suppl 16), 4 (1997). 6. J. R. Stroop, J. Exp. Psychol. 72, 219 (1935). 7. C. M. MacLeod, Psychol. Bull. 109, 163 (1991). 8. Testing materials (dilemmas) are available from Science Online at www.sciencemag.org/cgi/content/ full/293/5537/2105/DC1. 9. The three criteria are as follows: First, coders indicated for each dilemma whether the action in question could "reasonably be expected to lead to serious bodily harm." Second, they were asked to indicate whether this harm would be "the result of deflecting an existing threat onto a different party." Our use of this criterion, which parallels a distinction made by Thomson (1), is a an attempt to operationalize an intuitive notion of "agency." Intuitively, when a harm is produced by means of deflecting an existing threat, the agent has merely "edited" and not "authored" the resulting harm, and thus its contemplation is less emotionally engaging. Lastly, coders were asked to indicate whether the resulting harm would "befall a particular person or a member or members of a particular group of people." Here the question, in intuitive terms, is whether the victim is "on stage" in the dilemma. The moral dilemmas of which the coders said that the action in question (a) could reasonably be expected to lead to serious bodily harm (b) to a particular person or a member or members of a particular group of people (c) where this harm is not the result of deflecting an existing threat onto a different party were assigned to the "moral-

References and Notes

Fig. 3. Mean reaction time by condition and response type in Experiment 2. A mixed-effects ANOVA revealed a significant interaction between condition and response type [F(2, 8) 12.449, P 0.0005). Reaction times differed significantly between responses of "appropriate" and "inappropriate" in the moral-personal condition [t(8) 4.530, P 0.0005] but not in the other conditions (P 0.05). Error bars indicate two standard errors of the mean.

www.sciencemag.org SCIENCE VOL 293 14 SEPTEMBER 2001

2107

Downloaded from www.sciencemag.org on May 7, 2008

REPORTS
10. personal" condition; the others were assigned to the "moral-impersonal" condition. Participants were five male and four female undergraduates in Experiment 1, four male and five female in Experiment 2. All participants provided written informed consent. Dilemmas were presented in random order in a series of six blocks of ten trials each in Experiment 1, twelve blocks of five trials each in Experiment 2. Participants' responses to versions of the trolley and footbridge dilemmas were consistent with the intuitions described above (8). Stimuli (dilemmas) were presented on a visual display projected into the scanner. Each dilemma was presented as text through a series of three screens, the first two describing a scenario and the last posing a question about the appropriateness of an action one might perform in that scenario (e.g., turning the trolley). Participants were allowed to read at their own pace, pressing a button to advance from the first to the second screen and from the second to the third screen. After reading the third screen participants responded by pressing one of two buttons ("appropriate" or "inappropriate"). Participants were given a maximum of 46 s to read all three screens and respond. The intertrial interval (ITI) lasted for a minimum of 14 s (seven images) in each trial, allowing the hemodynamic response to return to baseline after each trial. Baseline activity was defined as the mean signal across the last four images of the ITI. Task-related activity was measured using a "floating window" of eight images surrounding (four before, one during, and three after) the point of response. (This window includes three post-response images in order to allow for the 4- to 6-s delay in hemodynamic response to neural activation.) This "floating window" technique combined the benefits of an eventrelated design with the flexibility required to image a complex and temporally extended psychological process that inevitably proceeds at its own pace. In Experiment 1, functional images were acquired in 20 axial slices parallel to the AC-PC (anterior commisure­posterior commisure) line [spiral pulse sequence; repetition time (TR), 2000 ms; echo time (TE), 45 ms; flip angle, 80°; field of view (FOV), 240 mm; 3.75-mm isotropic voxels] using a 1.5-T GE Signa whole-body scanner. In Experiment 2, functional images were acquired in 22 axial slices parallel to the AC-PC line (echoplanar pulse sequence; TR, 2000 ms; TE, 25 ms; flip angle, 90°; FOV, 192 mm; 3.0-mm isotropic voxels; 1-mm interslice spacing) using a 3.0-T Siemens Allegra head-dedicated scanner. Before statistical analysis, images for all participants were coregistered using a 12-parameter automatic algorithm. Images were smoothed with an 8-mm fullwidth at half maximum (FWHM) 3D Gaussian filter. In Experiment 1, the images contained in each response window were analyzed with the use of a voxelwise mixed-effects ANOVA with participant as a random effect, and dilemma-type, block, and response-relative image as fixed effects. Statistical maps of voxelwise F-ratios were thresholded for significance (P 0.0005) and cluster size ( 8 voxels). In Experiments 1 and 2, planned comparisons for significant differences between conditions (P 0.05, cluster size 8 voxels) were made for each area identified by the thresholded ANOVA in Experiment 1. R. J. Maddock, Trends Neurosci. 22, 310 (1999). S. M. Kosslyn et al., Neuroreport 7, 1569 (1996). E. M. Reiman et al., Am. J. Psychiatry 154, 918 (1997). W. C. Drevets, M. E. Raichle, Cognition Emotion 12, 353 (1998). E. E. Smith, J. Jonides, Cognit. Psychol. 33, 5 (1997). J. D. Cohen et al., Nature 386, 604 (1997). In BA 7/40 (right) a small minority of voxels (10 of 91) showed a significant difference between the moral-impersonal and non-moral conditions. Due to magnetic susceptibility artifact we were unable to image the orbitofrontal cortex, an area thought by some to play an important role in moral judgment (3). Experiments 1 and 2 were not identical (8). Experiment 2 employed some modified versions of dilemmas from Experiment 1 as well as some new dilemmas in order to avoid a confound present in the design of the behavioral aspect of Experiment 1 (24). 23. The replicated results for BAs 9/10, 31, and bilateral 7/40 were achieved at a higher significance threshold in Experiment 2 (P 0.01) than in Experiment 1. 24. A potential confound in the design of the behavioral aspect of the present study deserves attention. One might suppose that participants respond more slowly when giving an "unconventional" response, i.e., a response that differs from that of the majority. One might suppose further that the moralpersonal condition makes greater use of dilemmas for which the emotionally incongruent response is also the unconventional response (as in judging that one may push the man off the footbridge in the footbridge dilemma), thus confounding emotional incongruity with unconventionality in participants' responses. Therefore, an effect that we attribute to emotional engagement may simply be an effect of the conventionality of participants' responses. To deconfound these factors, in Experiment 2 we included additional moral-personal dilemmas for which the conventional response was emotionally incongruent rather than congruent. For example, one dilemma asked whether it is appropriate to smother one's crying baby to death in order to prevent its crying from summoning enemy soldiers who will kill oneself, the baby, and a number of others if summoned. Most participants judged this action to be appropriate in spite of their putative emotional tendencies to the contrary. As predicted by our hypothesis, reaction times in such cases were significantly longer [t (8) 4.332, P 0.0001] than the reaction times for conventional and emotionally congruent responses, as were typically made in response to the footbridge dilemma. Thus, after controlling for conventionality, reaction times in the moral-personal condition are longer for trials which, according to our theory, reflect a judgment that is emotionally incongruent rather than congruent. 25. Although our conclusion concerning the behavioral influence of the observed emotional responses does not require that the emotion-related areas identified in Experiments 1 and 2 be different from areas that show increased activity in response to more basic kinds of emotional stimuli, one might wonder to what extent they do differ from such areas. We made a preliminary attempt to answer this question 