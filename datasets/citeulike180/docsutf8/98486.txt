letters to nature
height using software available from Sontek. From each time series we calculated mean near-bed velocity independent of ¯ow direction. Mean near-bed velocity was compared between treatments using a non-parametric Mann±Whitney U-test because variances could not be transformed to satisfy parametric assumptions.
26. Hart, D. D. The adaptive signi®cance of territoriality in ®lter-feeding larval black¯ies (Diptera: Simuliidae). Oikos 46, 88±92 (1986). 27. Englund, G. Asymmetric resource competition in a ®lter-feeding stream insect (Hydropsyche siltalai: Trichoptera). Freshwat. Biol. 26, 425±432 (1991). 28. Okamura, B. Microhabitat variation and patterns of colony growth and feeding in a marine bryozoan. Ecology 73, 1502±1513 (1992). 29. Vogel, S. Life in Moving Fluids (Princeton Univ. Press, Princeton, 1994). 30. Finnigan, J. Turbulence in plant canopies. Annu. Rev. Fluid Mech. 32, 519±571 (2000).

Resource consumption
After measuring near-bed ¯ow, 278 mg of SPM stained with Rose Bengal dye was released as a single pulse into each stream19. Larvae were allowed to feed for 15 min (a duration less than gut passage times) before they were removed from their nets and frozen. We dissected larval guts later and measured the diameter and band length of stained SPM in foreguts using a dissecting microscope and ocular micrometer. Because foreguts are essentially cylindrical, the consumption of SPM by each larva was calculated as mm3 SPM by p ´ band length in foregut ´ (1/2 foregut diameter)2. Per capita consumption was compared between treatments using t-tests. Total resource consumption (the summed consumption of SPM by all larvae inhabiting a stream) was compared between treatments using a non-parametric Mann±Whitney U-test because variances could not be transformed to satisfy parametric assumptions. We used a paired t-test to compare observed resource consumption in mixed assemblages with the total expected SPM consumption2.

Acknowledgements
We thank D. Doak, D. Hart, M. Loreau, P. Morin, S. Naeem, K. Sebens, D. Tilman, J. Thomson and T. Welnitz for comments; and S. Brooks for advice on hydrodynamic measurements. This work was supported by grants from the National Science Foundation to M.A.P. and to B.J.C.

Competing interests statement
The authors declare that they have no competing ®nancial interests. Correspondence and requests for materials should be addressed to B.J.C. (e-mail: bc84@umail.umd.edu).

Bed roughness
At the end of the experiment we recorded the downstream location of every caddis¯y net and measured their maximum heights and widths. We calculated the average maximum height and density of the roughness elements, as well as their aggregation and topographical complexity. Aggregation measures the spacing between roughness elements as the mean euclidian distance between neighbouring nets. Topographical complexity measures the spatial uniformity or non-uniformity of roughness elements as the standard deviation of the parabolic area (in mm2) of catchnets. An s.d. of 0 indicates a uniform streambed (no topographical complexity), whereas a higher s.d. indicates greater streambed complexity. We compared all four aspects of bed roughness between treatments using t-tests.
Received 8 October; accepted 26 November 2001. 1. Hector, A. et al. Plant diversity and productivity experiments in European grasslands. Science 286, 1123±1127 (1999). 2. Loreau, M. & Hector, A. Partitioning selection and complementarity in biodiversity experiments. Nature 412, 72±76 (2001). 3. Mulder, C., Uliassi, D. & Doak, D. Physical stress and diversity±productivity relationships: The role of positive interactions. Proc. Natl Acad. Sci. USA 98, 6704±6708 (2001). 4. Tilman, D. et al. Diversity and productivity in a long-term grassland experiment. Science 294, 843± 845 (2001). 5. Jones, C. G., Lawton, J. H. & Shachack, M. Positive and negative effects of organisms as physical ecosystem engineers. Ecology 78, 1946±1957 (1997). 6. Luttge, U. Physiological Ecology of Tropical Plants (Springer, Berlin, 1997). 7. Naeem, S., Thompson, L. J., Lawler, S. P., Lawton, J. H. & Wood®n, R. M. Declining biodiversity can alter the performance of ecosystems. Nature 368, 734±737 (1994). 8. Cardinale, B. J., Nelson, K. & Palmer, M. A. Linking species diversity to the functioning of ecosystems: on the importance of environmental context. Oikos 91, 175±183 (2000). 9. Chapin, F. S. et al. Consequences of changing biodiversity. Nature 405, 234±242 (2000). 10. Tilman, D., Lehman, D. & Thompson, K. Plant diversity and ecosystem productivity: theoretical considerations. Proc. Natl Acad. Sci. USA 94, 1857±1861 (1997). 11. Hooper, D. & Vitousek, P. The effects of plant composition and diversity on ecosystem processes. Science 277, 1302±1305 (1997). 12. Huston, M. Hidden treatments in ecological experiments: re-evaluating the ecosystem function of biodiversity. Oecologia 110, 449±460 (1997). 13. Wardle, D. A. Is ``sampling effect'' a problem for experiments investigating biodiversity±ecosystem function relationships? Oikos 87, 403±410 (1999). 14. Fridley, J. D. The in¯uence of species diversity on ecosystem productivity: how, where, and why? Oikos 93, 514±526 (2001). 15. Tilman, D. et al. The in¯uence of functional diversity and composition on ecosystem processes. Science 277, 1300±1302 (1997). 16. Chapin, S. et al. Ecosystem consequences of changing biodiversity. BioScience 48, 45±52 (1998). 17. Palmer, M. A. et al. Biodiversity and ecosystem function in freshwater sediments. Ambio 26, 571±577 (1997). 18. Nowell, A. R. M. & Jumars, P. Flow environments of aquatic benthos. Annu. Rev. Ecol. Syst. 15, 303± 328 (1984). 19. Cardinale, B. J. & Palmer, M. A. Disturbance moderates biodiversity±ecosystem function relationships: evidence from caddis¯y assemblages in stream mesocosms. Ecology (in the press). 20. Loudon, C. & Alstad, D. N. Theoretical mechanisms of particle capture: Predictions for hydropsychid distributional ecology. Am. Nat. 135, 360±381 (1990). 21. Eckman, J. E., Nowell, A. R. M. & Jumars, P. J. Sediment destabilization by animal tubes. J. Mar. Res. 39, 361±374 (1981). 22. Johnson, A. Flow around phoronids: Consequences of a neighbor to suspension feeders. Limnol. Oceanogr. 35, 1395±1401 (1990). 23. Huettel, M. & Gust, G. Impact of bioroughness on interfacial solute exchange in permeable sediments. Mar. Ecol. Prog. Ser. 89, 253±267 (1992). 24. Butman, C. A., Frechette, M., Geyer, W. R. & Starczak, V. R. Flume experiments on food supply to the blue mussel Mytilus edulis L. as a function of boundary-layer ¯ow. Limnol. Oceanogr. 39, 1755±1768 (1994). 25. Sebens, K. P., Witting, J. & Helmuth, B. Effects of water ¯ow and branch spacing on particle capture by the reef coral Madracis mirabilis (Duchassaing and Michelotti). J. Exp. Mar. Biol. Ecol. 211, 1±28 (1997).

.................................................................
Humans integrate visual and haptic information in a statistically optimal fashion
Marc O. Ernst* & Martin S. Banks
Vision Science Program/School of Optometry, University of California, Berkeley 94720-2020, USA
..............................................................................................................................................

When a person looks at an object while exploring it with their hand, vision and touch both provide information for estimating the properties of the object. Vision frequently dominates the integrated visual±haptic percept, for example when judging size, shape or position1±3, but in some circumstances the percept is clearly affected by haptics4±7. Here we propose that a general principle, which minimizes variance in the ®nal estimate, determines the degree to which vision or haptics dominates. This principle is realized by using maximum-likelihood estimation8±15 to combine the inputs. To investigate cue combination quantitatively, we ®rst measured the variances associated with visual and haptic estimation of height. We then used these measurements to construct a maximum-likelihood integrator. This model behaved very similarly to humans in a visual±haptic task. Thus, the nervous system seems to combine visual and haptic information in a fashion that is similar to a maximum-likelihood integrator. Visual dominance occurs when the variance associated with visual estimation is lower than that associated with haptic estimation. The estimate of an environmental property by a sensory system can be represented by

Ã Si  f i S

1

where S is the physical property being estimated and f is the operation by which the nervous system does the estimation. The subscripts refer to the modality (i could also refer to different cues Ã within a modality). Each estimate, Si , is corrupted by noise. If the noises are independent and gaussian with variance j 2, and the i bayesian prior is uniform, then the maximum-likelihood estimate

È * Present address: Max Planck Institute for Biological Cybernetics, Tubingen 72076, Germany.

NATURE | VOL 415 | 24 JANUARY 2002 | www.nature.com

© 2002 Macmillan Magazines Ltd

429

letters to nature
(MLE) of the environmental property is given by 1=j2 i Ã Ã S wi Si with wi  i 1=j2 j

^

^
j

2

Thus, the MLE rule states that the optimal means of estimation (in the sense of producing the lowest-variance estimate) is to add the sensor estimates weighted by their normalized reciprocal variances8±15. If the MLE rule is used to combine visual and haptic Ã Ã estimates, SV and SH , the variance of the ®nal (visual±haptic) Ã estimate, S, is j2 j2 j2  2 V H 2 3 VH jV  jH Thus, the ®nal estimate has lower variance than either the visual or the haptic estimator. Implementation of MLE integration is shown for two hypothetical cases in Fig. 1. We examined visual±haptic integration quantitatively to determine whether human performance is optimal. Observers looked at and/or felt a raised ridge (Fig. 2) and judged its height (vertical extent). To work out the predictions of the MLE rule, we ®rst determined the variances of the visual and haptic height estimates (within-modality) by conducting discrimination experiments. In the haptic-alone experiment, observers indicated which of two sequentially presented ridges was taller from haptic information alone; in the visual-alone experiment, they did the same from visual information alone. There were four conditions in the visual experiment that differed in the amount of noise in the stimulus (see Methods). By adding noise we made the visually speci®ed height less reliable. Visual-alone and haptic-alone discrimination data are shown in Fig. 3a. The proportion of trials in which the observer indicated that the comparison stimulus (variable height) appeared taller than the standard stimulus (®xed height of 55 mm) is plotted as a function of

the height of the comparison stimulus. The dashed red line and symbols represent the haptic discrimination data, and the solid blue curves with open symbols represent the visual data for the four levels of noise. These psychometric functions were well ®t by cumulative gaussian functions. The discrimination threshold is de®ned as the difference between the point of subjective equality (PSE) and the height of the comparison stimulus when it is judged taller than the p standard stimulus 84% of the time. The 84% point corresponds to 2 times the standard deviation of the underlying estimator. The haptic discrimination threshold was roughly 0.085 times the average ridge height (which was 55 mm). As the noise increased from 0 to 200%, the visual discrimination thresholds increased from 0.04 to 0.2 times the average height. Thus, when the visual noise was 0%, the visual discrimination threshold was roughly half the haptic threshold; when the visual noise was 200%, the visual threshold was more than double the haptic threshold. In the visual±haptic experiment, observers simultaneously looked at and felt two raised ridges that were presented sequentially. In one presentation the visually and haptically speci®ed heights were equal (comparison stimulus); in the other presentation they differed (standard stimulus). The difference (D) in the speci®ed heights was 6 6, 6 3 or 0 mm (the average of SH and SV was 55 mm). For each D in the standard stimulus (randomly presented), the height of the comparison stimulus was varied randomly from trial to trial (47±63 mm). On each trial, the observer indicated which stimulus seemed taller. Figure 3b shows the proportion of trials in which the comparison stimulus was chosen as taller as a function of the height of the comparison stimulus. From these psychometric functions, we estimated the PSEÐthe comparison height appearing equal to the standard heightÐand the just-discriminable change in height (threshold). Using the within-modality data, we can predict what an observer using MLE will do when presented visual and haptic information

2 2  H / V = 1

2 2 H / V = 4

Probability

Probability densities Combined Haptic Visual VH H V ^ SH 0.5 wV* 0.5 wH* Psychometric function ^ SV

Probability densities Combined Visual Haptic VH V VH H ^ SH 0.8 wV* ^ SV 0.2 wH* Psychometric function Estimated height

Proportion `taller' Proportion `taller'

1.00 0.84 PSE 0.50

T VH

1.00 0.84 PSE 0.50

T VH

0 SH S0 = 5.5 cm SV 

0 SH S0 = 5.5 cm SV  Physical height

Figure 1 Maximum-likelihood estimation integration: two hypothetical situations. Visually and haptically speci®ed heights differ by D. Dashed gaussians in the top panels represent probability densities of the (unbiased) estimated height from visual and haptic assessment, and solid gaussians represent probability densities for the combined estimate. On the left, the visual and haptic variances are equal (j2 =j2  1) and both their H V weights are 0.5 (equation (2)). The mean of the combined probability density is therefore equal to the mean of the visual and haptic densities and the variance is reduced by half (equation (3)). If the observer bases judgements of relative height on the combined
430

probability density, the psychometric function would be a cumulative gaussian (bottom left) with a point of subjective equality (PSE) equal to the average of the visual and haptic heights of the standard stimulus. On the right, the haptic variance is four times the visual variance: j2 =j2  4. By equation (2), the visual weight (wV) is 0.8 and the haptic weight H V (wH) is 0.2. Thus, the combined probability density is shifted towards the visual estimate and its variance is 0.8 times the visual variance (equation (3)). Accordingly, the psychometric function should be shifted so that the PSE is closer to the visual height of the standard stimulus.
NATURE | VOL 415 | 24 JANUARY 2002 | www.nature.com

© 2002 Macmillan Magazines Ltd

letters to nature
simultaneously, and we compare these predictions to the performance in the visual±haptic experiment. First, we describe the analysis of the PSE data and predictions for the weights. From equation (2) and the relationship between threshold and estimator variance: wV j2 T2  H H 4 2 wH jV T 2 V where TH and TV are the haptic and visual thresholds (84% points in Fig. 3a). Incorporating the normalization assumption (wV  wH  1), the predicted weights for optimal integration are wV  T2 H T  T2 H
2 V

a

CRT

Stereo glasses

and

wH 

T2 V T  T2 H
2 V

5

The predicted visual weights are represented by the curve and shaded surround in Fig. 3c. The predicted weights vary signi®cantly with the amount of visual noise in the stimulus: the visual weights are higher when the noise level is low, and lower when the noise level is high. Assuming that the visual and haptic estimators are on Ã Ã average unbiased (SV  SV and SH  SH ), the weights can be derived experimentally: wV  PSE 2 SH =SV 2 SH  6 where PSE is the height of the comparison stimulus that matched the apparent height of the standard stimulus. The visually and haptically speci®ed heights in the standard stimulus, SV and SH, are indicated on the right ordinate. Figure 3c shows that as the noise level was increased the visual weight decreased, and the PSE shifted from SV towards SH. Because the noise level varied randomly from trial to trial, the weights must have been set within the 1-s stimulus presentation. Below, we suggest a mechanism for such dynamic weight adjustment. In summary, the predicted and observed PSEs are similar, suggesting that humans do combine visual and haptic information in a fashion similar to MLE integration. According to the MLE rule, the combined estimates should have lower variance, and therefore lower discrimination thresholds, than either the visual or haptic estimate alone (equation (3)). To derive predictions for the visual±haptic discrimination thresholds, we rewrite equation (3): T2 T2 1 1 1 T2  2 V H 2 , 2  2  2 7 VH T VH T V T H TV  TH The predicted and observed thresholds are shown in Fig. 3d. The open symbols represent the visual-alone thresholds and the dashed line represents the haptic-alone threshold. The shaded area represents the predicted visual±haptic thresholds; they are always lower than the visual-alone and haptic-alone thresholds at the corresponding noise level. The ®lled purple symbols represent the observed visual±haptic discrimination thresholds; as noise level increases, the just-noticeable difference in height becomes greater. Most notably, the predicted and observed visual±haptic discrimination thresholds are similar. As with the PSE data, this indicates that human observers may combine visual and haptic information in a manner similar to MLE integration. In summary, we found that height judgements were remarkably similar to those predicted by the MLE integrator. Thus, the nervous system seems to combine visual and haptic information in a fashion similar to the MLE rule: visual and haptic estimates are weighted according to their reciprocal variances (equation (2)). Naturally, it is important to determine whether this rule characterizes the estimation of other stimulus properties such as shape, depth, localization, roughness or compliance. The relative contributions of vision and haptics to perceiving such object properties have been studied previously. For example, subjects have grasped a square while looking at it through a distorting lens that made it appear rectangular1. The shape of the uni®ed percept was determined almost completely by vision, so the phenomenon was called `visual capture'. Numerous studies have
NATURE | VOL 415 | 24 JANUARY 2002 | www.nature.com

Opaque mirror

Forcefeedback devices

h idt W

Visual and haptic scene

Noise: 3 cm equals 100%

3-c

ep md

th s

tep

ht eig al h Visu ht eig ic h apt H

b

Right eye's image

Left eye's image

Figure 2 Apparatus and stimuli. a, Observers viewed the re¯ection of the visual stimulus, presented on a cathode ray tube (CRT) binocularly in a mirror. CrystalEyes (StereoGraphics) liquid-crystal shutter glasses were used to present binocular disparity. The surfaces of the stimuli were perpendicular to the line of sight. A head and chin rest limited head movements. The right hand was beneath the mirror and could not be seen. The haptic stimulus was presented with two PHANToM force-feedback devices, one each for the index ®nger and thumb. b, Stereograms representative of visual stimuli, which should be viewed by cross-fusing. Top row, stereogram has no noise and the horizontal bar is raised above the background. Bottom row, stereogram of bar and background contains noise, with random displacements of dots parallel to the line of sight.
431

© 2002 Macmillan Magazines Ltd

With noise

Without noise

letters to nature
replicated visual capture in shape and size perception3,16,17, depth perception18 and localization2,19±21. But visual capture does not occur in the perception of surface roughness6,22; instead, perceived roughness is affected nearly equally by haptics and vision. Does a dynamic cue-combination rule, such as the one described here, determine the degree to which vision or haptics dominates? The statistically optimal means of combining visual and haptic informationÐthe MLE ruleÐpredicts that visual capture should occur whenever the visual estimate of a property has much less variance than that of the haptic estimate. Haptic capture should be observed when the reverse occurs. We observed behaviour like visual capture when the visual stimulus was noise-free, and behaviour similar to haptic capture when the visual stimulus was quite noisy (Fig. 3c). In visual±haptic tasks, the MLE integrator described here always uses information from both sensory systems, so the combined percept will always re¯ect both sources of information. Different behaviour may be observed when the discrepancy between two information sources is large. With large discrepancies between information sources, the nervous system may exhibit robust behaviour10 in which a discrepant source is discounted9,23. In robust estimation, the weights associated with different information sources are determined by more than the variances of the sensory estimators; they are also determined by the discrepancy between their estimates. In our experiments, the differences between the visually and haptically speci®ed stimuli were never greater than 11%, and the visual±haptic data always exhibited an in¯uence of both sensory systems. If the differences had been larger, we might
a
Proportion of trials perceived as 'taller' 1.00 Haptic 0.75
Visual 0% 67% 133% 200% Noise level

have observed discounting of one sense. It would be interesting to know whether such vetoing occurs when observers become aware of the con¯ict between visual and haptic inputs. If the nervous system implements MLE integration, the weights must be proportional to the reciprocal variances of the probability densities associated with the visual and haptic estimates of the environmental property in question (equation (2) and Fig. 1). Of course, the variances change from one object property to the next (such as size, shape or roughness) and from one situation to another (for example, visual variance increases as the lighting is degraded). Does the nervous system need to calculate or learn the variances associated with the visual and haptic estimators for each property and situation to implement MLE integration? Although explicit calculation or learning may occur24, there are plausible schemes in which explicit calculation of variances or weights is unnecessary. Consider, for example, a population of visual and haptic neurons, each sensitive to a range of heights. Each neuron has a preferred height but also responds to other heights (that is, each neuron has a tuning function). If the visual input speci®es the height clearly (that is, high contrast, noise-free, and so on), then the visual neurons preferring that height respond vigorously and those preferring other heights respond less, and the distribution of response across the population of visual neurons has a well de®ned peak. Assume that the distribution across the population of haptic neurons has a less well de®ned peak. Multiplication of these two distributions (pointby-point multiplication where the two populations are in registration according to the stimulus property being estimated)25 yields a
b
Proportion of trials perceived as 'taller' 1.00 Visual­haptic discrimination (normalized across )
Noise level

Within-modality discrimination

Visual­haptic 0% 67% 133% 0.75 200%

0.50

0.50

0.25 Standard 0 50 55 60 Comparison height (mm) Weights (PSEs) 1.0 0
Visual­haptic Predicted Empirical 'Visual capture'

0.25

n=4

0 45

55 SH SV Normalized comparison height (mm) Discrimination thresholds

65

c

SV

d
0.24 0.20 Threshold 0.16 0.12 0.08 0.04

0.8 0.2 Haptic weight Visual weight 0.6 0.4 0.4 0.6 0.2 0.8 0 1.0

Haptic (empirical) Visual (empirical) Visual­haptic (predicted) Visual­haptic (empirical)

PSE SH

'Haptic capture'

0

67 133 Noise level (%)

200

0

0

67 133 Noise level (%)

200

Figure 3 Predictions and experimental data. a, Within-modality discrimination. Proportion of trials in which a comparison was perceived as taller than the standard stimulus is plotted against the height of the comparison stimulus. Data were averaged for observers. Height of the standard stimulus was 55 mm. Haptic discrimination data are represented by red crosses and the dashed curve (best-®tting cumulative gaussian); visual discrimination data are represented by blue curves, which correspond to four noise levels. b, Visual±haptic discrimination. The average height of visual±haptic standard stimulus was 55 mm; the height difference, D, varied from -6 to +6 mm. To plot the data on the same coordinates, the psychometric functions for each D were shifted laterally by w VD/2 (w V is obtained from the regression of PSE against D). Purple curves represent the different visual noise levels. c, Weights and PSEs. Abscissa represents the noise level, left
432

ordinate represents visual weight (w V; haptic weight is 1 - w V) and right ordinate represents the PSEs relative to S V and S H. Purple symbols represent observed visual weights obtained from regression analysis of PSEs (equation 6) across D. Shaded area represents predicted weights expected from within-modality discrimination (a; equation (5)); its height represents predicted errors given the standard errors of the within-modality discrimination. d, Combined and within-modality discrimination thresholds. Justnoticeable differences in height are plotted against noise level. Thresholds are taken from psychometric functions in a and b. Dashed red line represents haptic-alone threshold; open blue symbols represent visual-alone thresholds; ®lled purple symbols represent combined visual±haptic thresholds. Shaded area represents predicted visual±haptic thresholds (equation (7)).
NATURE | VOL 415 | 24 JANUARY 2002 | www.nature.com

© 2002 Macmillan Magazines Ltd

letters to nature
peak response closer to the visual than the haptic peak, as with MLE integration. If degrading the visual input causes the response distribution of the visual neurons to spread, then multiplication of the visual and haptic distributions yields a peak closer to the haptic peak, again as in MLE integration. Thus, the estimator variances (and therefore the weights) do not have to be calculated explicitly: the behaviour of an MLE integrator might be achieved through interactions among populations of visual and haptic neurons. M
6. Lederman, S. J. & Abbott, S. G. Texture perception: Studies of intersensory organization using a discrepancy paradigm, and visual versus tactual psychophysics. J. Exp. Psychol. Hum. Percept. Perform. 7, 902±915 (1981). 7. Heller, M. A. Haptic dominance in form perception with blurred vision. Perception 12, 607±613 (1983). 8. Clark, J. J. & Yuille, A. L. Data Fusion for Sensory Information Processing Systems (Kluwer Academic, Boston, 1990). È 9. Blake, A., Bulthoff, H. H. & Sheinberg, D. Shape from texture: Ideal observer and human psychophysics. Vision Res. 33, 1723±1737 (1993). 10. Landy, M. S., Maloney, L. T., Johnston, E. B. & Young, M. Measurement and modeling of depth cue combination: In defense of weak fusion. Vision Res. 35, 389±412 (1995). 11. Gharamani, Z., Wolpert, D. M. & Jordan, M. I. in Self-organization, Computational Maps, and Motor Control (eds Morasso, P. G. & Sanguineti, V.) 117±147 (Elsevier, Amsterdam, 1997). 12. Knill, D. C. Discrimination of planar surface slant from texture: Human and ideal observers compared. Vision Res. 38, 1683±1697 (1998). 13. Backus, B. T. & Banks, M. S. Estimator reliability and distance scaling in stereoscopic slant perception. Perception 28, 417±442 (1999). 14. van Beers, R. J., Sittig, A. C. & Denier van der Gon, J. J. Integration of proprioceptive and visual position information: An experimentally supported model. J. Neurophysiol. 81, 1355±1364 (1999). 15. Schrater, P. R. & Kersten, D. How optimal depth cue integration depends on the task. Int. J. Comp. Vis. 40, 71±89 (2000). 16. Gibson, J. J. Adaptation, after-effect, and contrast in the perception of curved lines. J. Exp. Psychol. 16, 1±31 (1933). 17. Festinger, L., Burnham, C. A., Ono, H. & Bamber, D. Efference and the conscious experience of perception. J. Exp. Psychol. 74 (4), 1±36 (1967). 18. Singer, G. & Day, R. H. Visual capture of haptically judged depth. Percept. Psychophys. 5, 315±316 (1969). 19. Tastevin, J. En partant de l'experience d'Aristote. L'Encephale 1, 57±84 (1937). 20. Mon-Williams, M., Wann, J. P., Jenkinson, M. & Rushton, K. Synaesthesia in the normal limb. Proc. R. Soc. Lond. B 264, 1007±1010 (1997). 21. Pavani, F., Spence, C. & Driver, J. Visual capture of touch: out-of-the-body experiences with rubber gloves. Psycholog. Sci. 11, 353±359 (2000). 22. Heller, M. A. Visual and tactual texture perception: Intersensory cooperation. Percept. Psychophys. 31, 339±344 (1982). 23. Banks, M. S. & Backus, B. T. Extra-retinal and perspective cues cause the small range of the induced effect. Vision Res. 38, 187±194 (1998). È 24. Ernst, M. O., Banks, M. S. & Bulthoff, H. H. Touch can change visual slant perception. Nature Neurosci. 3, 69±73 (2000). Ä 25. Pena, J. L. & Konishi, M. Auditory spatial receptive ®elds created by multiplication. Science 292, 249± 252 (2001).

Methods
Stimuli
The stimulus was a horizontal bar raised 30 mm above a plane; the bar and plane were perpendicular to the line of sight (Fig. 2a). The width of the bar was 150 mm; its height varied but the average was S0 = 55 mm. Observers viewed the bar binocularly and/or grasped it with the index ®nger and thumb in order to estimate its height (Fig. 2a). Its vertical position was varied randomly from trial to trial. The haptic stimulus was generated using two PHANToM (SensAble Technologies) force-feedback devices (Fig. 2a), one each for the index ®nger and thumb. Finger and thumb movements had all six degrees of freedom in the 20-cm3 workspace. The threedimensional positions of the tips of the ®nger and thumb were monitored, and appropriate forces were applied when the tips reached the positions of the simulated haptic objects. PHANToMs compellingly simulate haptic properties such as the size, shape and stiffness of the bar. The apparatus was calibrated to align the visual and haptic stimuli spatially. The visual stimulus was a random-dot stereogram simulating the background plane and bar (Fig. 2). The dots subtended 8 arcmin at the 50-cm viewing distance. Dot density was roughly 9 dots per degree2. New dots were displayed with each presentation. The positions of the ®nger and thumb (tracked by the PHANToMs) were indicated by small threedimensional markers; the markers were visible until the bar was touched. Noise was added to the visual display to vary its reliability. The noise was a random displacement of the dot depths in the stereogram (direction parallel to line of sight). The displacements were drawn from a random uniform distribution whose range was 0, 67, 133 or 200% of the 3cm depth step between the bar and plane. The displacement of the dots is shown in Fig. 2. No noise was added to the haptic display. We wanted the presentation times for the visual and haptic stimuli to be identical. In the vision-alone discrimination experiment, the standard and comparison stimuli were displayed for 1 s each. In the haptic-alone discrimination experiment, the haptic stimulus began when the thumb and ®nger both contacted the bar and ended after 1 s. In the visual± haptic trials, the visually speci®ed bar did not appear until the bar was touched by both ®ngers simultaneously and the visual and haptic stimuli were extinguished after 1 s.

Acknowledgements
We thank M. Landy for comments on the manuscript; and H. Ernst, X. Moncada, C. Alderson and S. Kashiwada for participating as observers. This research was supported by research grants from Air Force Of®ce of Scienti®c Research and the National Institutes of Health, and by an equipment grant from Silicon Graphics.

Procedure
Within-modality discrimination was measured in a two-interval, forced-choice scheme. Each trial consisted of the sequential (visual or haptic) presentation of two bars. In the standard interval, the bar was always 55 mm tall and in the comparison interval, it was shorter or taller than 55 mm. The standard and comparison stimuli were randomly assigned to the ®rst or second interval. The observer indicated the interval containing the apparently taller stimulus. The comparison height was varied according to the method of constant stimuli. We plotted psychometric functions, that 