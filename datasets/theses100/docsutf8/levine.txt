The Structured Employment Interview: An Examination of Construct and Criterion Validity

A thesis submitted in partial fulfillment of the requirements for the degree of Master of Applied Psychology at University of Waikato by Anne B. Levine

___________________________

University of Waikato 2006

ii Abstract This study extends the literature on interview validity by attempting to create a structured employment interview with both construct- and criterion-related validity. For this study, a situational interview was developed with the specific purpose of enhancing the interview's construct validity while retaining the interview's predictive power. To enhance the construct validity, two guidelines were applied to the creation of the interview based on previous research in interview and assessment center literature--(1) limit the number of applicant characteristics to be rated to 3; and (2) ensure that the dimensions to be measured are conceptually distinct. Based on these two guidelines, three constructs were chosen for assessment of real estate sales agents--extraversion, proactive personality and customer orientation. The critical incident technique was used to develop six interview items. To test the construct validity of the interview, the six items were correlated with other measures, specifically, self-report questionnaires and managers' ratings, of extraversion, proactivity and customer orientation. Correlations were weak, at best (rs ranged from -.06 to .25). To test the predictive validity of the interview, the six items were correlated with both objective and subjective measures of performance. Predictive validities were stronger, ranging from .23 to .30. These findings are consistent with previous research on employment interviews which have found that although the predictive validity of the interview is strong, the construct validity is very weak, leaving researchers to wonder what it is that the interview is actually measuring. Possible explanations for these findings are offered, and the implications of these findings are discussed.

iii Acknowledgements There are many people who deserve recognition for their help with this project. First, and foremost, my eternally patient advisor Mike--thank you for your continuous support and encouragement. Thanks also to the architect of this study and my advisor from afar, Paul. This study could not have been done without the help and cooperation of an incredible organization of real estate agents--I am extremely grateful to all of you. Special thanks to John for organizing EVERYTHING. You should probably get part billing on the title page. Finally, thanks to my best friend Drew for listening to my stressed-out babble for 15 months and for constantly reminding me that if I would just do it, it would be done.

iv Contents Abstract Acknowledgements Contents List of Tables List of Appendices Chapter I Introduction Background The present study Constructs related to real estate sales Situational interviews Summary Method Participants and procedure Situational interview Self-report measures Managers' ratings of constructs Performance measures Results Descriptive statistics Interview correlations Performance measure correlations Discussion Hypotheses relating to construct validity Hypotheses relating to criterion validity Limitations Implications for research and practice Conclusion/Summary ii iii iv v vi 1 3 6 8 12 13 15 15 15 18 19 20 21 21 23 26 29 31 34 37 41 42 44 Interview items and response scales Manager rating scales 52 56

Chapter II

Chapter III

Chapter IV

References Appendix A Appendix B

v List of Tables Tables 1. Descriptive statistics of interview scores 2. Descriptive statistics of self-report scores 3. Descriptive statistics of managers' construct ratings 4. Descriptive statistics of performance measures 5. Correlations between interview items 6. Correlations between interview items, self-report measures and managers' construct ratings 7. Correlations between interview items and performance measures 8. Correlations between self-report measures, managers' construct ratings and performance measures Page 21 22 23 23 24 25 27 27

vi List of Appendices Appendix A. Interview items and response scales B. Manager rating scales Page 52 56

1 Chapter I: Introduction As one of the most frequently used personnel selection methods, employment interviews have become a main focus for researchers in the field of Industrial and Organizational (I/O) psychology. Throughout most of the 20th century, researchers consistently provided evidence of the low validity of the employment interview-- especially the unstructured interview (Arvey, Miller, Gould, & Burch, 1987). However, since the 1980s, researchers have turned their focus to certain characteristics of the interview (e.g. interview content, degree of structure) and have gradually altered the negative perception of the interview. Increasingly more research has been done to increase its predictive power (Salgado & Moscoso, 2002), and in the past 15 years it has been well established that the structured employment interview has relatively high criterion-related validity (e.g. Campion, Palmer, & Campion, 1997; Huffcutt & Arthur, 1994; McDaniel, Whetzel, Schmidt, & Maurer, 1994). Now that it has been shown that structured interviews can be good predictors of job performance, some researchers have taken steps towards examining the constructs captured in those interviews. As Salgado and Moscoso (2002) pointed out, the reasons why the employment interview predicts job performance remain to be explained--in other words, what exactly is the interview measuring? With this question in mind, a number of studies have been carried out to evaluate what constructs are actually being assessed (e.g. Harris, 1999; Huffcutt, Conway, Roth, & Stone, 2001a; Salgado & Moscoso, 2002). Many of these studies were metaanalyses, and due to the surprising lack of primary studies in this area, results have been meager. In addition, the foundations of these meta-analytic studies were

2 fundamentally flawed. Most researchers examined what the interviews were intended to measure--not what they actually measured. For example, studies by Huffcutt et al. (2001a) and Harris (1999) attempted to create taxonomies of possible constructs that could be assessed in employment interviews. These two studies examined previous interview research and recorded the dimensions rated in that research. They developed taxonomies including cognitive ability, personality dimensions, job knowledge, interests, person-organization fit and physical attributes. The problem with this research is that although the previous studies claimed to measure certain constructs, they reported no results of analysis to support those claims. Few studies have reported correlations between interview items and pre-established measures of the constructs those items were meant to capture. Huffcutt et al. (2001a) were only able to find correlations between interviews and established psychological measures for cognitive ability, and stated that the analysis of other constructs would have to be left for future research, as the correlations were simply not available. In this vein, construct validity has been extremely difficult to establish. The purpose of the present study was to create an interview specifically designed to maximize its construct validity and to evaluate whether it is possible to create an interview that has good construct validity and retains strong predictive power. In the following sections I will review previous construct-oriented studies, relevant assessment center research, sales selection literature and studies of situational interviews.

3 Background Construct Validity of Employment Interviews As mentioned in the previous section, interviews are designed to assess a variety of work-related characteristics; however, very few researchers have actually investigated whether or not interviews truly assess those characteristics. Based on the findings of those few studies, the major issue to arise concerning construct validity and the employment interview is the interview's apparent lack of dimensionality. In other words, interviews are often developed to assess a number of different interviewee characteristics; however, a number of research studies (discussed below) have found that interviews did not measure nearly as many characteristics as they were assumed to. A few recent studies have examined the construct validity of interviews using the multitrait-multimethod (MTMM) approach (Campbell & Fiske, 1959). The MTMM approach allows researchers to examine the correlations between different constructs as well as different measures of those constructs. The aforementioned studies used the MTMM matrix to examine the correlations between different items in different interviews in order to determine the convergent and discriminant validity of those interviews. Results were discouraging. Conway and Peneno (1999) examined the convergent and discriminant validity of two interviews used for the selection of university residence hall advisors. Items in both interviews were meant to assess five dimensions: being a role model, programming, helping skills, staff relations, and community development. An MTMM analysis showed that the convergent validity--r = .50 (average correlation among items intended to measure the same dimension across interviews) was only slightly higher than the discriminant validity--r = .48 (average correlation among items intended to measure

4 different dimensions within interviews). Other studies with even more unfavorable results found convergent validities that were lower than discriminant validities (Huffcutt, Weekley, Wiesner, Degroot, & Jones, 2001b; Van Iddekinge, Raymark, Eidson, & Attenweiler, 2004). Van Iddekinge et al. (2004) performed an MTMM analysis of interview items across two interviews and found a convergent validity (mean correlation across interviewers and within constructs) of r = .19 and a discriminant validity (mean correlation within interviewers and across constructs) of r = .32. In other words, scores on interview items did not differentiate between different dimensions--items were more likely to relate to items measuring different dimensions in the same interview than they were to items in other interviews that were meant to measure the same dimension. To further explore this dimensionality problem, some researchers have performed factor analyses to determine the number of factors being assessed in employment interviews. While most interviewers and developers of interviews believed they were tapping into a wide variety of applicant characteristics, factor analyses have revealed that these interviews were actually uni-dimensional (Arvey et al., 1987; Pulakos & Schmidt, 1995). In other words, instead of measuring the abundance of constructs it was supposed to, the interview was only tapping into one distinguishable factor. Unfortunately, it is unclear precisely what this single dimension might be. Arvey et al. (1987) created a 15-item interview for hiring sales clerks that was intended to assess four characteristics identified in a job analysis as important for the success of salespeople. Factor analysis of those items (based on a sample of 756 interviewees) revealed only one distinct factor with an eigenvalue greater than one. In another example, Pulakos and Schmitt (1995) created two

5 separate interviews designed to assess 8 different characteristics. Factor analyses of these interviews revealed only one clear factor for each interview with eigenvalues greater than one. These problems with construct validity are also found in the assessment center (AC) literature. Like the structured employment interview, the AC has enjoyed good criterion-related validity (Gaugler, Rosenthal, Thornton, & Bentson, 1987; Schmidt & Hunter, 1998). However, also like the interview, the evidence for construct validity in ACs has been less clear (Schleicher, Day, Mayes, & Riggio, 2002). Numerous researchers have reported evidence of a serious lack of construct validity in assessment centers (Bycio, Alvares, & Hahn, 1987; Lance, Lambert, Gewin, Lievens, & Conway, 2004; Lievens, 2002; Robertson, Gratton, & Sharpley, 1987; Sackett & Dreher, 1982). However, researchers in the AC field have suggested a few possible solutions to the problems leading to this construct validity issue (discussed below) and these solutions may also apply to the employment interview.

Techniques to Increase Dimension Variance One of the problems that is most frequently blamed for these construct validity findings in ACs is assessor inaccuracy resulting from poor AC design (Lievens, 2002). This `poor AC design' refers to aspects such as: the number of constructs to be measured, the distinctiveness of the constructs to be measured and the expertise of the assessor. To demonstrate this, studies have shown that once the design of the AC was altered to facilitate assessor rating processes, the construct validity was found to improve (Lievens & Conway, 2001; Woehr & Arthur, 2003). One way the design was altered was by limiting the number of dimensions to be

6 rated--the rationale being that assessors have limited information-processing capabilities and, therefore, have difficulty differentiating between a large number of performance dimensions (Lievens & Conway, 2001; Woehr & Arthur, 2003). In a study by Gaugler and Thornton (1989), assessors were responsible for rating either 3, 6, or 9 dimensions. The researchers found that the assessors who were asked to rate 3 dimensions provided more accurate ratings than those assessors asked to rate 6 or 9 dimensions. Woehr and Arthur (2003) further demonstrated the use of this strategy when they found in their meta-analysis that limiting the number of dimensions assessed led to higher convergent validity in ACs. This method of limiting the number of dimensions to be assessed translates to the interview literature as well. Ulrich and Trumbo found in 1965 that limiting the number of traits to be assessed by interviewers increased the validity of their ratings. Another design modification used to simplify the task of the assessor is to ask the assessors to rate dimensions that are conceptually distinct. In other words, the dimensions included in the AC (or the interview) should not correlate too highly with one another. This prevents assessors from confusing dimensions and also prevents overlap of the behaviors associated with dimensions. Kleinmann, Exler, Kuptsch, and KÃ¶ller (1995) established that this step in designing ACs is generally effective at improving the quality of assessor ratings.

The Present Study The purpose of the present research was to develop a structured employment interview with both construct- and criterion-related validity. Historically, structured employment interview studies have focused primarily on criterion-related validity,

7 without attempting to maximize construct validity (Campion, Pursell, & Brown, 1988; Cortina, Goldstein, Payne, Davison, & Gilliland, 2000; Dougherty, Ebert, & Callender, 1986). However, more recently it was realized that understanding the constructs involved in employment interviews is potentially important as it may allow us to design interviews to achieve specific outcomes, such as high incremental validity and minimal impact on minority groups (Huffcutt et al, 2001a). It would also grant interviewers the ability and confidence to target specifically desired characteristics. By applying guidelines suggested in both interview and assessment center literature, I believe an interview can be created that will be multi-dimensional and have good construct- and criterion-related validity. I hypothesized that by applying the following guidelines to the creation of a structured interview, the interview would exhibit strong construct validity as well as retaining predictive strength: 1) limit the number of applicant characteristics to be rated to 3 2) ensure that the dimensions to be measured are conceptually distinct Construct validity would be examined by correlating interview scores with self-report questionnaires and manager ratings--all measuring the same 3 constructs. Interview scores would also be correlated with objective and subjective performance measures in order to examine the interview's predictive validity. For this study, I chose to create an interview for hiring salespeople. As Vinchur, Schippmann, Switzer, & Roth (1998) pointed out, the sales job is deserving of special attention because of its importance and prevalence. According to the Bureau of Labor Statistics (2006), there were 16,433,000 people employed in sales jobs in the United States in 2005. This is an 11% increase from 1996. Also, effective

8 selling is critical to the success of an economy, and sales is an occupation in which any improvement in selection can have a major impact on the bottom line of a company (Vinchur et al., 1998). salespeople. For this study, I focused specifically on real estate

Constructs Related to Real Estate Sales In order to choose which constructs to include in this study, previous research in sales selection was examined. A variety of characteristics have been linked to successful sales performance in selection studies. For example, characteristics include cognitive ability, personality dimensions, biodata, and motivation (Arvey et al., 1987; Ford, Walker, Churchill, & Hartley, 1987; Thoresen, Bradley, Bliese, & Thoresen, 2004; Vinchur et al., 1998). In addition to previous research, I also consulted the Occupational Information Network (O*Net) website. This site provides occupational information (e.g worker characteristics, occupational requirements) based on job analyses for a number of different occupations (Peterson, Mumford, Borman, Jeanneret, Fleishman, Levin, Campion, Mayfield, Morgeson, Pearlman, Gowing, Lancaster, Silver, & Dye, 2001). This was an important site to consult as choosing constructs and interview items based on job analyses increases the reliability, predictive validity, and fairness of interviews (Campion et al., 1988; Feild & Gatewood, 1989; Latham & Skarlicki, 1995). The O*Net website illustrated the knowledge, skills and abilities (KSAs) and tasks necessary for being a successful sales agent. This information combined with the sales literature helped to narrow down the list of constructs. Also, by applying the aforementioned criteria (limiting the number of dimensions to be rated, and ensuring that constructs are conceptually

9 distinct), I was able to complete the process of choosing constructs. In the end, three distinct constructs were decided on: extraversion, proactive personality, and customer orientation. In the sales selection literature, these constructs were all linked to performance criteria and were not found to correlate highly with each other--this latter point is the main reason why these constructs were chosen above others.

Extraversion Extraversion is a characteristic that is generally associated with success in sales. Extraverts are characterized as gregarious, energetic, friendly, positive, and outgoing--all traits that are recognized as important for successful salespeople to exhibit (Thoresen et al., 2004). O*Net describes real estate sales as a `social occupation' which requires a lot of interaction with people; therefore, displaying signs of extraversion (i.e. friendliness and being outgoing) is a desired trait for salespeople. Arvey et al. (1987) states that salespeople will be more successful if they are energetic, friendly and outgoing--again, all of which are aspects of extraversion. This finding was further supported by Barrick and Mount (1991) who found a significant predictor-criterion relationship for salespeople of .15 between extraversion and performance. Also, in a meta-analytic study of the predictors of sales success, Vinchur et al. (1998) found extraversion to be a valid predictor of both supervisory ratings of sales performance and actual sales volume. Therefore, I hypothesized the following: Hypothesis 1: Extraversion scores on the interview (Items 1 and 2) will be positively related to self-report measures and managers' ratings of extraversion.

10 Hypothesis 2: Extraversion scores on the interview will be positively related to performance.

Proactive Personality The typical proactive personality is one who is unconstrained by situational forces and who effects environmental change. Proactive personalities excel at identifying opportunities and acting on them; they show initiative and persevere until they bring about the change they desire (Bateman & Crant, 1993). They are also known to enjoy facing and overcoming obstacles--a must in an occupation such as real estate sales which is steeped with rejection. Vinchur et al. (1998) recognized rejection as one of the aspects of sales that makes it unique. They point out that as opposed to other jobs, salespeople have to deal with much greater degrees of rejection and autonomy; therefore, they must be self-starters, relying on their own initiative and drive to get the job done. Similarly, O*Net also described the job requirements of real estate sales agents to include a willingness to take on responsibilities and challenges, and persistence in the face of obstacles. In a study examining the predictive validity of the proactive personality scale for real estate sales agents, Crant (1995) found that it was a good predictor of sales performance; it explained an additional 8% of variance beyond that explained by other factors, such as experience and general mental ability. Therefore, I hypothesized the following: Hypothesis 3: Proactive personality scores on the interview (Items 3 and 4) will be positively related to self-report measures and managers' ratings of proactivity.

11 Hypothesis 4: Proactive personality scores on the interview will be positively related to performance.

Customer Orientation Customer-oriented salespeople try to help customers make purchase decisions that will satisfy customer needs. They engage in behaviors aimed at increasing customer satisfaction and creating long-term relationships with customers (as opposed to targeting the immediate sale) (Saxe & Weitz, 1982). The customer orientation scale was tested by Saxe and Weitz (1982) on 180 real estate sales agents. The results indicate that real estate agents can practice customer-oriented selling without losing sales for appearing too "soft" (Pettijohn, Pettijohn, & Parker, 1998). On the contrary, studies found that customer-oriented selling positively affected sales performance (Brown, Mowen, Donavan, & Licata, 2002; Humphreys & Williams, 1996) and appeared to help build long-term relationships--a must for real estate salespeople in a small country like New Zealand (Schultz & Good, 2000; Schwepker, 2003). Therefore, I hypothesized the following: Hypothesis 5: Customer orientation scores on the interview (Items 5 and 6) will be positively related to self-report measures and managers' ratings of customer orientation. Hypothesis 6: Customer orientation scores on the interview will be positively related to performance.

12 Situational Interviews The situational interview (SI) is one of the most popular forms of structured interviews (Harris, 1999). A meta-analysis by Huffcutt, Roth and McDaniel (1996) found that the SI was the most common type of structured interview used in interview research literature. The SI asks interviewees what they would say or do in hypothetical situations (Latham, Saari, Pursell, & Campion, 1980). Questions are developed with the purpose of exploring interviewees' intentions for future behavior. A sample SI question is as follows: "Your spouse and two teenage children are sick in bed with a cold. There are no relatives or friends available to look in on them. Your shift starts in 3 hours. What would you do in this situation?" (Latham et al., 1980, p. 424). This question would then be scored on a scale from 1 to 5 (1 being a poor response and 5 being ideal). This style of interview has been successful in predicting performance (Arvey & Campion, 1982; Latham et al., 1980). A number of studies, however, have reported another type of interview--behavior description interview (BDI)--as being a slightly better predictor of performance (Pulakos & Schmitt, 1995; Taylor & Small, 2002). BDI questions are similar to SI questions except instead of asking what the interviewee would do, the BDI asks what they did do. In other words, the BDI examines past behavior, while the SI examines intentions for future behavior. Despite the above findings, the present study used SI questions. This type of interview was chosen for one main reason--SI questions were more suitable for the sample. Real estate agents often have little or no sales experience when first entering

13 the field. For this reason, BDI questions would not be appropriate, as applicants would not have any past experiences to refer back to.

Summary The findings from researchers examining the construct validity of employment interviews have been disappointing, at best. However, by using some of the design guidelines implemented by AC developers struggling with the same construct validity problem, this study endeavored to create an interview that exhibited both construct- and criterion-related validity. I have applied the following criteria to the creation of the interview: limiting the number of constructs to be measured--in this case, limiting the constructs to be assessed to three, and ensuring that the constructs to be measured are conceptually distinct--extraversion, proactive personality, and customer-orientation, by definition, are conceptually different and should have little or no correlation with each other. I hypothesized that by applying the aforementioned criteria, the resulting interview will exhibit strong construct validity by showing positive relationships with other measures of extraversion, proactive personality and customer orientation. Specifically, I hypothesized the following: Hypothesis 1: Extraversion scores on the interview (Items 1 and 2) will be positively related to self-report measures and managers' ratings of extraversion. Hypothesis 2: Extraversion scores on the interview will be positively related to performance.

14 Hypothesis 3: Proactive personality scores on the interview (Items 3 and 4) will be positively related to self-report measures and managers' ratings of proactivity. Hypothesis 4: Proactive personality scores on the interview will be positively related to performance. Hypothesis 5: Customer orientation scores on the interview (Items 5 and 6) will be positively related to self-report measures and managers' ratings of customer orientation. Hypothesis 6: Customer orientation scores on the interview will be positively related to performance.

15 Chapter II: Method Participants and Procedure The data in this study were collected from 84 incumbent salespeople employed by a large real estate organization located in New Zealand. The mean age of participants was 46.47 years (SD = 11.7), and participants reported an average job tenure of 5.52 years (SD = 6.62). A slight majority of participants (54.8%) were women, and 45.2% were men. A large majority of the sample (86.9%) specialized in residential sales, 10.7% specialized in rural sales, and 2.4% specialized in commercial sales. The participants were drawn from 13 office branches; the number of agents participating at each branch ranged from 2 to 13. I attended staff meetings at the 13 offices to explain the purpose of the study, as well as to hand out information sheets that further described elements of the study. Agents indicated their interest by scheduling an interview time on the sign-up sheet provided. Participants were then interviewed and asked to complete a questionnaire. Both the interview and questionnaire are described below. Demographic information were also collected, concerning the participants' age, sex, job tenure, and specialization of real estate. The participants were assured of the confidentiality of their responses; interviews were conducted in private offices and all materials were returned directly to me. Measures collected from office managers were posted to the offices following my visit and returned, by post, directly to me.

Situational Interview Interview development. The situational interview used in this study was developed using a derivative of the critical incident technique. However, instead of

16 asking Subject Matter Experts (SMEs) to describe, in general, situations that result in good sales, they were asked specifically about the three desired constructs. SMEs were three real estate franchise owners/managers who had experience in hiring and supervising real estate sales agents. They were asked to provide both positive and negative critical incidents relating to extraversion, proactivity and customer orientation. For example, SMEs were asked to think of an incident in which a salesperson was particularly extraverted and it led to a good sales outcome. Twenty incidents were identified in which the above constructs were critical to a sales situation. Upon studying these incidents and weeding out those that were undesirable (e.g situations in which the desirable answer was too obvious), the number of incidents was narrowed down to six. I then worked with the managers to turn the incidents into questions and to develop response scales for each question. Managers were asked to independently benchmark responses along a 5-point scale (1 = least desired response, 3 = average response, 5 = optimal response); a group discussion ensued to reach consensus on the answers to be used as benchmarks. An example of a critical incident (for proactive personality) that was turned into an interview question is as follows:

This salesperson had a home open for inspection. He was just about to close up the house--he had another open home in 15 minutes--when a couple showed up to see the house. The agent told them that they were too late and he had to close up the house and leave. The couple ended up buying a house down the road from a competitor.

17 This incident was rewritten in the form of the following question:

You have an open home from 1 to 1.45. No one comes to see the house. As you're closing up at 1.45 a very interested buyer shows up. You have another open home at 2 (in 15 minutes). What would you do in this situation?

The managers felt that the more steps taken to work with these buyers, the better the score should be. Therefore, this question had the following benchmarks: (5) I would collect all their details right away; I'd allow them to quickly look around while I finished closing up; I would try to set up a later appointment to show them around properly; I would try to get a colleague to open my next home so that I could spend more time with these buyers right now (3) I would allow them to quickly look around and I would try to set up a later appointment to show them around properly (1) I would allow them to quickly look around. The entire interview, including response scales, is contained in Appendix A. Interview implementation. In conducting the interview, I read each question aloud and an MP3 device recorded participants' responses. Questions were repeated upon request. Interviews took between 5 and 15 minutes depending on the participant. To assess the reliability of my ratings of participants' responses, I examined the percentage agreement between me and two other raters. My two thesis advisors each independently scored 10% of the participants' responses in order to compare our ratings. The inter-rater percentage agreements were 83%, 83% and 85%. Cohen's kappa coefficients (the percentage agreements corrected for chance agreement) were

18 .77, .79 and .76. These results suggest that the initial process of rating participants was sufficiently consistent. Any disagreements were discussed until a consensus was reached.

Self-report Measures Extraversion. Extraversion was assessed using the 10-item scale from the International Personality Item Pool (IPIP) developed by Goldberg (1999). Five of the items were reverse scored as indicated in the IPIP. Goldberg's international and widely-used public domain measure has been shown to predict job performance in numerous organizational field studies (e.g. Liao & Chuang, 2004; Ployhart, Lim, & Chan, 2001). All responses were scored on a 7-point scale with response options ranging from 1 (strongly disagree) to 7 (strongly agree). This format represents a change to the original IPIP format, whi